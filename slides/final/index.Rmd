---
title: "Amplification Pipelines"
subtitle: "The Role of Feedback Loops in Recommender System Bias"
author: "Candidate: Caio Truzzi Lente<br/>Advisor: Prof. Dr. Roberto Hirata Jr."
date: "DCC-IME-USP | XXXX-YY-ZZ"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: "css/xaringan-themer.css"
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r, include=FALSE, warning=FALSE, message=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(comment = "#>", fig.align = "center")
```

# Motivation

- Social networks are ubiquitous: socializing, reading news, expressing
ourselves

- The public wants to know what role their platforms might have in radicalizing
users, specially younger ones

  - Mainly anecdotal evidence (e.g. Facebook depression experiments, YouTube's
  bizarre videos aimed at kids, etc.)

- Journalists and specialists alike argue that social media's algorithms are
tuned to peddle conspiracy theories, extremist views, and false information

- The debate around the role of recommender systems in social media
radicalization is still too recent and based in anecdotes

- More quality research is vital to inform both the public and opinion makers
about if and how much recommendation algorithms influence social media users

---
# Methods

- Recommender systems: providing users with personalized product or service
recommendations

  - Trade secrets, but known to gather enormous amounts of data about the user's
  interaction with the website

  - Algorithms might have **explicit biases**: YouTube's system, for example,
  explicitly favors more recent videos

  - Algorithm might develop **implicit biases**: Instagram's system, for
  example, learned its user's differentiated homophily and favored male profiles

- Goal: understand the mechanisms through which recommender systems can end up
learning or developing biases (which might lead to radicalization)

  - Understand how and how fast recommender systems develop biases and whether
  this cas create **amplification pipelines**

---
# Literature review

- F. Ricci, L. Rokach, and B. Shapira, "Recommender Systems Handbook"

- Z. Zhao et al., "Recommending what video to watch next: a multitask ranking
system"

- A.-A. Stoica, C. Riederer, and A. Chaintreau, "Algorithmic Glass Ceiling in
Social Networks: The effects of social recommendations on network diversity"

- M. H. Ribeiro, R. Ottoni, R. West, V. A. F. Almeida, and W. Meira, "Auditing
radicalization pathways on YouTube"

- K. Munger, and J. Phillips, "Right-Wing YouTube: A Supply and Demand
Perspective"

- R. Jiang et al., "Degenerate feedback loops in recommender systems"

- M. Ledwich, and A. Zaitsev, "Algorithmic Extremism: Examining YouTube's Rabbit
Hole of Radicalization"

---
# Proposal

- **Static analysis**: doesn't take into account the evolution of the system
after multiple rounds of training and learning from new data

  - Hypothesis: even a simple recommendation algorithm can demonstrate some sort
  of bias towards a subset of of items

  - Given an algorithm that is user agnostic, would the resulting recommender
  system still favor any items?

- **Dynamic analysis**: takes into account the dynamics of the system, i.e., the
algorithm learning for the users' feedbacks to its recommendations

  - Hypothesis: if the users reinforce the beliefs of the algorithm it will
  degenerate and only recommend a subset of items

  - How fast does a degenerate feedback loop develop, ignoring personal
  preferences and distinctions between films?

---
# Static analysis

- Excluding user information is important because they might transfer their own
biases to the model

- "Recommendation profiles": a summary of how many times an arbitrary item is
recommended overall

  - Trivial model: a simple sampler that returns n movies at random

  - Vanilla model: cosine similarity applied to vector representations of the
  items

  - Cutoff models: uses cutoff points after which words would not be included in
  the vector representations

  - Similarity models: uses other distance metrics (cosine distance, Euclidean
  distance and Manhattan distance)

  - Vanilla model with synthetic metadata: the sparsity of the vector
  representations are controlled by how many elements should be non-zero

---
# Static analysis: results

---
# Dynamic analysis

- Lightweight TensorFlow model that is trained five times, always receiving
positive feedback from the simulated users

- Better understand the recommendation profiles by modeling it with standard
statistical models

  - Exploratory analysis: recommendation entropy, recommendation profile over
  time, item log-popularity over time

  - Poisson regression: uses R's `glm()`, simulated envelope uses the `hnp`
  package

  - Negative binomial regression: uses `MASS`'s `glm.nb()`, simulated envelope
  uses the `hnp` package

  - Mixed-effects Poisson regression: uses the `glmmTMB` package, simulated
  envelope uses the `DHARMa` package

  - Mixed-effects negative binomial regression: same as previous mode

---
# Dynamic analysis: results

---
# Conclusion

---
# Future works
