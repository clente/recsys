%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%% INSERINDO COMENTÁRIOS EM ARQUIVOS .bib %%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% 1. Como em outros arquivos LaTeX, comentários são iniciados por "%" e,
%    portanto, é preciso usar "\%" para imprimir o caractere "%". Esquecer
%    disso pode gerar erros difíceis de encontrar!
%
% 2. Não é possível inserir comentários dentro de uma entrada, apenas fora.
%
% 3. Não é possível incluir o caractere arroba em um comentário.
%
% 4. Se quiser desabilitar temporariamente um campo ("comentar" o campo),
%    troque seu nome para algum nome inválido, como "author-disable".
%    Se quiser fazer alguma observação permanente dentro de uma entrada,
%    você também pode usar algum nome de campo inválido, como "lembrete",
%    ou usar o campo "annotation", que normalmente é ignorado.
%
% 5. Se quiser desabilitar temporariamente uma entrada inteira ("comentar" a
%    entrada), não basta colocar "%" nas linhas correspondentes por causa do
%    caractere arroba; também é preciso remover a arroba.
%
% 6. Na verdade, as regras não são bem essas, mas segui-las é uma boa ideia:
%    https://tex.stackexchange.com/a/262282


% Esta entrada está comentada, ou seja, não tem efeito: se houvesse uma
% referência a ela no texto, a referência ficaria inválida. Observe que,
% para isso, o caractere arroba foi apagado!
%Book{JW82,
% author    = {Richard A. Johnson and Dean W. Wichern},
% title     = {Applied Multivariate Statistical Analysis},
% publisher = {Prentice-Hall},
% year      = {1983}
%}

% ter um banco de dados com todos os papers que são de seu
% interesse e, em um dado texto, citar apenas alguns deles.


@inproceedings{gilbert_predicting_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Predicting tie strength with social media},
	isbn = {978-1-60558-246-7},
	url = {https://doi.org/10.1145/1518701.1518736},
	doi = {10.1145/1518701.1518736},
	abstract = {Social media treats all users the same: trusted friend or total stranger, with little or nothing in between. In reality, relationships fall everywhere along this spectrum, a topic social science has investigated for decades under the theme of tie strength. Our work bridges this gap between theory and practice. In this paper, we present a predictive model that maps social media data to tie strength. The model builds on a dataset of over 2,000 social media ties and performs quite well, distinguishing between strong and weak ties with over 85\% accuracy. We complement these quantitative findings with interviews that unpack the relationships we could not predict. The paper concludes by illustrating how modeling tie strength can improve social media design elements, including privacy controls, message routing, friend introductions and information prioritization.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Gilbert, Eric and Karahalios, Karrie},
	month = apr,
	year = {2009},
	keywords = {Social Networks},
	pages = {211--220},
}

@article{wu_personalized_2021,
	title = {Personalized {News} {Recommendation}: {A} {Survey}},
	shorttitle = {Personalized {News} {Recommendation}},
	url = {http://arxiv.org/abs/2106.08934},
	abstract = {Personalized news recommendation is an important technique to help users find their interested news information and alleviate their information overload. It has been extensively studied over decades and has achieved notable success in improving users' news reading experience. However, there are still many unsolved problems and challenges that need to be further studied. To help researchers master the advances in personalized news recommendation over the past years, in this paper we present a comprehensive overview of personalized news recommendation. Instead of following the conventional taxonomy of news recommendation methods, in this paper we propose a novel perspective to understand personalized news recommendation based on its core problems and the associated techniques and challenges. We first review the techniques for tackling each core problem in a personalized news recommender system and the challenges they face. Next, we introduce the public datasets and evaluation metrics used for personalized news recommendation. We then discuss the key points on improving the responsibility of personalized news recommender systems. Finally, we raise several research directions that are worth investigating in future. This paper can provide up-to-date and comprehensive views to help readers understand the personalized news recommendation field. We hope this paper can facilitate research on personalized news recommendation and as well as related fields in natural language processing and data mining.},
	urldate = {2021-06-20},
	journal = {arXiv:2106.08934 [cs]},
	author = {Wu, Chuhan and Wu, Fangzhao and Huang, Yongfeng},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.08934},
	keywords = {Recommender Systems, Survey},
}

@article{gao_fair_2021,
	title = {{FAIR}: {Fairness}-{Aware} {Information} {Retrieval} {Evaluation}},
	shorttitle = {{FAIR}},
	url = {http://arxiv.org/abs/2106.08527},
	abstract = {With the emerging needs of creating fairness-aware solutions for search and recommendation systems, a daunting challenge exists of evaluating such solutions. While many of the traditional information retrieval (IR) metrics can capture the relevance, diversity and novelty for the utility with respect to users, they are not suitable for inferring whether the presented results are fair from the perspective of responsible information exposure. On the other hand, various fairness metrics have been proposed but they do not account for the user utility or do not measure it adequately. To address this problem, we propose a new metric called Fairness-Aware IR (FAIR). By unifying standard IR metrics and fairness measures into an integrated metric, this metric offers a new perspective for evaluating fairness-aware ranking results. Based on this metric, we developed an effective ranking algorithm that jointly optimized user utility and fairness. The experimental results showed that our FAIR metric could highlight results with good user utility and fair information exposure. We showed how FAIR related to existing metrics and demonstrated the effectiveness of our FAIR-based algorithm. We believe our work opens up a new direction of pursuing a computationally feasible metric for evaluating and implementing the fairness-aware IR systems.},
	urldate = {2021-06-20},
	journal = {arXiv:2106.08527 [cs]},
	author = {Gao, Ruoyuan and Ge, Yingqiang and Shah, Chirag},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.08527},
	keywords = {Bias, Recommender Systems},
}

@article{slowik_algorithmic_2021,
	title = {Algorithmic {Bias} and {Data} {Bias}: {Understanding} the {Relation} between {Distributionally} {Robust} {Optimization} and {Data} {Curation}},
	shorttitle = {Algorithmic {Bias} and {Data} {Bias}},
	url = {http://arxiv.org/abs/2106.09467},
	abstract = {Machine learning systems based on minimizing average error have been shown to perform inconsistently across notable subsets of the data, which is not exposed by a low average error for the entire dataset. In consequential social and economic applications, where data represent people, this can lead to discrimination of underrepresented gender and ethnic groups. Given the importance of bias mitigation in machine learning, the topic leads to contentious debates on how to ensure fairness in practice (data bias versus algorithmic bias). Distributionally Robust Optimization (DRO) seemingly addresses this problem by minimizing the worst expected risk across subpopulations. We establish theoretical results that clarify the relation between DRO and the optimization of the same loss averaged on an adequately weighted training dataset. The results cover finite and infinite number of training distributions, as well as convex and non-convex loss functions. We show that neither DRO nor curating the training set should be construed as a complete solution for bias mitigation: in the same way that there is no universally robust training set, there is no universal way to setup a DRO problem and ensure a socially acceptable set of results. We then leverage these insights to provide a mininal set of practical recommendations for addressing bias with DRO. Finally, we discuss ramifications of our results in other related applications of DRO, using an example of adversarial robustness. Our results show that there is merit to both the algorithm-focused and the data-focused side of the bias debate, as long as arguments in favor of these positions are precisely qualified and backed by relevant mathematics known today.},
	urldate = {2021-06-20},
	journal = {arXiv:2106.09467 [cs, stat]},
	author = {Słowik, Agnieszka and Bottou, Léon},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.09467},
	keywords = {Bias, Dataset},
}

@article{ferraro_what_2021,
	title = {What is fair? {Exploring} the artists' perspective on the fairness of music streaming platforms},
	shorttitle = {What is fair?},
	url = {http://arxiv.org/abs/2106.02415},
	abstract = {Music streaming platforms are currently among the main sources of music consumption, and the embedded recommender systems significantly influence what the users consume. There is an increasing interest to ensure that those platforms and systems are fair. Yet, we first need to understand what fairness means in such a context. Although artists are the main content providers for music platforms, there is a research gap concerning the artists' perspective. To fill this gap, we conducted interviews with music artists to understand how they are affected by current platforms and what improvements they deem necessary. Using a Qualitative Content Analysis, we identify the aspects that the artists consider relevant for fair platforms. In this paper, we discuss the following aspects derived from the interviews: fragmented presentation, reaching an audience, transparency, influencing users' listening behavior, popularity bias, artists' repertoire size, quotas for local music, gender balance, and new music. For some topics, our findings do not indicate a clear direction about the best way how music platforms should act and function; for other topics, though, there is a clear consensus among our interviewees: for these, the artists have a clear idea of the actions that should be taken so that music platforms will be fair also for the artists.},
	urldate = {2021-06-20},
	journal = {arXiv:2106.02415 [cs]},
	author = {Ferraro, Andres and Serra, Xavier and Bauer, Christine},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.02415},
	keywords = {Bias, Networks},
}

@article{li_new_2021,
	title = {New {Insights} into {Metric} {Optimization} for {Ranking}-based {Recommendation}},
	url = {http://arxiv.org/abs/2106.02545},
	doi = {10.1145/3404835.3462973},
	abstract = {Direct optimization of IR metrics has often been adopted as an approach to devise and develop ranking-based recommender systems. Most methods following this approach aim at optimizing the same metric being used for evaluation, under the assumption that this will lead to the best performance. A number of studies of this practice bring this assumption, however, into question. In this paper, we dig deeper into this issue in order to learn more about the effects of the choice of the metric to optimize on the performance of a ranking-based recommender system. We present an extensive experimental study conducted on different datasets in both pairwise and listwise learning-to-rank scenarios, to compare the relative merit of four popular IR metrics, namely RR, AP, nDCG and RBP, when used for optimization and assessment of recommender systems in various combinations. For the first three, we follow the practice of loss function formulation available in literature. For the fourth one, we propose novel loss functions inspired by RBP for both the pairwise and listwise scenario. Our results confirm that the best performance is indeed not necessarily achieved when optimizing the same metric being used for evaluation. In fact, we find that RBP-inspired losses perform at least as well as other metrics in a consistent way, and offer clear benefits in several cases. Interesting to see is that RBP-inspired losses, while improving the recommendation performance for all uses, may lead to an individual performance gain that is correlated with the activity level of a user in interacting with items. The more active the users, the more they benefit. Overall, our results challenge the assumption behind the current research practice of optimizing and evaluating the same metric, and point to RBP-based optimization instead as a promising alternative when learning to rank in the recommendation context.},
	urldate = {2021-06-20},
	journal = {arXiv:2106.02545 [cs]},
	author = {Li, Roger Zhe and Urbano, Julián and Hanjalic, Alan},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.02545},
	keywords = {Recommender Systems},
}

@article{li_user-oriented_2021,
	title = {User-oriented {Fairness} in {Recommendation}},
	url = {http://arxiv.org/abs/2104.10671},
	doi = {10.1145/3442381.3449866},
	abstract = {As a highly data-driven application, recommender systems could be affected by data bias, resulting in unfair results for different data groups, which could be a reason that affects the system performance. Therefore, it is important to identify and solve the unfairness issues in recommendation scenarios. In this paper, we address the unfairness problem in recommender systems from the user perspective. We group users into advantaged and disadvantaged groups according to their level of activity, and conduct experiments to show that current recommender systems will behave unfairly between two groups of users. Specifically, the advantaged users (active) who only account for a small proportion in data enjoy much higher recommendation quality than those disadvantaged users (inactive). Such bias can also affect the overall performance since the disadvantaged users are the majority. To solve this problem, we provide a re-ranking approach to mitigate this unfairness problem by adding constraints over evaluation metrics. The experiments we conducted on several real-world datasets with various recommendation algorithms show that our approach can not only improve group fairness of users in recommender systems, but also achieve better overall recommendation performance.},
	urldate = {2021-06-20},
	journal = {Proceedings of the Web Conference 2021},
	author = {Li, Yunqi and Chen, Hanxiong and Fu, Zuohui and Ge, Yingqiang and Zhang, Yongfeng},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.10671},
	keywords = {Bias, Recommender Systems},
	pages = {624--632},
}

@article{zeng_fair_2021,
	title = {Fair {Representation} {Learning} for {Heterogeneous} {Information} {Networks}},
	url = {http://arxiv.org/abs/2104.08769},
	abstract = {Recently, much attention has been paid to the societal impact of AI, especially concerns regarding its fairness. A growing body of research has identified unfair AI systems and proposed methods to debias them, yet many challenges remain. Representation learning for Heterogeneous Information Networks (HINs), a fundamental building block used in complex network mining, has socially consequential applications such as automated career counseling, but there have been few attempts to ensure that it will not encode or amplify harmful biases, e.g. sexism in the job market. To address this gap, in this paper we propose a comprehensive set of de-biasing methods for fair HINs representation learning, including sampling-based, projection-based, and graph neural networks (GNNs)-based techniques. We systematically study the behavior of these algorithms, especially their capability in balancing the trade-off between fairness and prediction accuracy. We evaluate the performance of the proposed methods in an automated career counseling application where we mitigate gender bias in career recommendation. Based on the evaluation results on two datasets, we identify the most effective fair HINs representation learning techniques under different conditions.},
	urldate = {2021-06-20},
	journal = {arXiv:2104.08769 [cs]},
	author = {Zeng, Ziqian and Islam, Rashidul and Keya, Kamrun Naher and Foulds, James and Song, Yangqiu and Pan, Shimei},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.08769},
	keywords = {Bias, Networks},
}

@article{virani_lessons_2021,
	title = {Lessons {Learned} {Addressing} {Dataset} {Bias} in {Model}-{Based} {Candidate} {Generation} at {Twitter}},
	url = {http://arxiv.org/abs/2105.09293},
	abstract = {Traditionally, heuristic methods are used to generate candidates for large scale recommender systems. Model-based candidate generation promises multiple potential advantages, primarily that we can explicitly optimize the same objective as the downstream ranking model. However, large scale model-based candidate generation approaches suffer from dataset bias problems caused by the infeasibility of obtaining representative data on very irrelevant candidates. Popular techniques to correct dataset bias, such as inverse propensity scoring, do not work well in the context of candidate generation. We first explore the dynamics of the dataset bias problem and then demonstrate how to use random sampling techniques to mitigate it. Finally, in a novel application of fine-tuning, we show performance gains when applying our candidate generation system to Twitter's home timeline.},
	urldate = {2021-06-20},
	journal = {arXiv:2105.09293 [cs]},
	author = {Virani, Alim and Baxter, Jay and Shiebler, Dan and Gautier, Philip and Verma, Shivam and Xia, Yan and Sharma, Apoorv and Binnani, Sumit and Chen, Linlin and Yu, Chenguang},
	month = may,
	year = {2021},
	note = {arXiv: 2105.09293},
	keywords = {Bias, Recommender Systems, Dataset},
}

@article{li_be_2021,
	title = {Be {Causal}: {De}-biasing {Social} {Network} {Confounding} in {Recommendation}},
	shorttitle = {Be {Causal}},
	url = {http://arxiv.org/abs/2105.07775},
	abstract = {In recommendation systems, the existence of the missing-not-at-random (MNAR) problem results in the selection bias issue, degrading the recommendation performance ultimately. A common practice to address MNAR is to treat missing entries from the so-called "exposure" perspective, i.e., modeling how an item is exposed (provided) to a user. Most of the existing approaches use heuristic models or re-weighting strategy on observed ratings to mimic the missing-at-random setting. However, little research has been done to reveal how the ratings are missing from a causal perspective. To bridge the gap, we propose an unbiased and robust method called DENC (De-bias Network Confounding in Recommendation) inspired by confounder analysis in causal inference. In general, DENC provides a causal analysis on MNAR from both the inherent factors (e.g., latent user or item factors) and auxiliary network's perspective. Particularly, the proposed exposure model in DENC can control the social network confounder meanwhile preserves the observed exposure information. We also develop a deconfounding model through the balanced representation learning to retain the primary user and item features, which enables DENC generalize well on the rating prediction. Extensive experiments on three datasets validate that our proposed model outperforms the state-of-the-art baselines.},
	urldate = {2021-06-20},
	journal = {arXiv:2105.07775 [cs]},
	author = {Li, Qian and Wang, Xiangmeng and Xu, Guandong},
	month = may,
	year = {2021},
	note = {arXiv: 2105.07775},
	keywords = {Bias, Recommender Systems, Machine Learning},
}

@article{wang_deconfounded_2021,
	title = {Deconfounded {Recommendation} for {Alleviating} {Bias} {Amplification}},
	url = {http://arxiv.org/abs/2105.10648},
	doi = {10.1145/3447548.3467249},
	abstract = {Recommender systems usually amplify the biases in the data. The model learned from historical interactions with imbalanced item distribution will amplify the imbalance by over-recommending items from the major groups. Addressing this issue is essential for a healthy ecosystem of recommendation in the long run. Existing works apply bias control to the ranking targets (e.g., calibration, fairness, and diversity), but ignore the true reason for bias amplification and trade-off the recommendation accuracy. In this work, we scrutinize the cause-effect factors for bias amplification, identifying the main reason lies in the confounder effect of imbalanced item distribution on user representation and prediction score. The existence of such confounder pushes us to go beyond merely modeling the conditional probability and embrace the causal modeling for recommendation. Towards this end, we propose a Deconfounded Recommender System (DecRS), which models the causal effect of user representation on the prediction score. The key to eliminating the impact of the confounder lies in backdoor adjustment, which is however difficult to do due to the infinite sample space of the confounder. For this challenge, we contribute an approximation operator for backdoor adjustment which can be easily plugged into most recommender models. Lastly, we devise an inference strategy to dynamically regulate backdoor adjustment according to user status. We instantiate DecRS on two representative models FM and NFM, and conduct extensive experiments over two benchmarks to validate the superiority of our proposed DecRS.},
	urldate = {2021-06-20},
	journal = {arXiv:2105.10648 [cs]},
	author = {Wang, Wenjie and Feng, Fuli and He, Xiangnan and Wang, Xiang and Chua, Tat-Seng},
	month = may,
	year = {2021},
	note = {arXiv: 2105.10648},
	keywords = {Bias, Recommender Systems},
}

@article{gupta_correcting_2021,
	title = {Correcting {Exposure} {Bias} for {Link} {Recommendation}},
	url = {http://arxiv.org/abs/2106.07041},
	abstract = {Link prediction methods are frequently applied in recommender systems, e.g., to suggest citations for academic papers or friends in social networks. However, exposure bias can arise when users are systematically underexposed to certain relevant items. For example, in citation networks, authors might be more likely to encounter papers from their own field and thus cite them preferentially. This bias can propagate through naively trained link predictors, leading to both biased evaluation and high generalization error (as assessed by true relevance). Moreover, this bias can be exacerbated by feedback loops. We propose estimators that leverage known exposure probabilities to mitigate this bias and consequent feedback loops. Next, we provide a loss function for learning the exposure probabilities from data. Finally, experiments on semi-synthetic data based on real-world citation networks, show that our methods reliably identify (truly) relevant citations. Additionally, our methods lead to greater diversity in the recommended papers' fields of study. The code is available at https://github.com/shantanu95/exposure-bias-link-rec.},
	urldate = {2021-06-20},
	journal = {arXiv:2106.07041 [cs]},
	author = {Gupta, Shantanu and Wang, Hao and Lipton, Zachary C. and Wang, Yuyang},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.07041},
	keywords = {Bias, Recommender Systems},
}

@article{wang_bias_2021,
	title = {Bias: {Friend} or {Foe}? {User} {Acceptance} of {Gender} {Stereotypes} in {Automated} {Career} {Recommendations}},
	shorttitle = {Bias},
	url = {http://arxiv.org/abs/2106.07112},
	abstract = {Currently, there is a surge of interest in fair Artificial Intelligence (AI) and Machine Learning (ML) research which aims to mitigate discriminatory bias in AI algorithms, e.g. along lines of gender, age, and race. While most research in this domain focuses on developing fair AI algorithms, in this work, we show that a fair AI algorithm on its own may be insufficient to achieve its intended results in the real world. Using career recommendation as a case study, we build a fair AI career recommender by employing gender debiasing machine learning techniques. Our offline evaluation showed that the debiased recommender makes fairer career recommendations without sacrificing its accuracy. Nevertheless, an online user study of more than 200 college students revealed that participants on average prefer the original biased system over the debiased system. Specifically, we found that perceived gender disparity is a determining factor for the acceptance of a recommendation. In other words, our results demonstrate we cannot fully address the gender bias issue in AI recommendations without addressing the gender bias in humans.},
	urldate = {2021-06-20},
	journal = {arXiv:2106.07112 [cs]},
	author = {Wang, Clarice and Wang, Kathryn and Bian, Andrew and Islam, Rashidul and Keya, Kamrun Naher and Foulde, James and Pan, Shimei},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.07112},
	keywords = {Bias, Recommender Systems},
}

@article{zhou_contrastive_2021,
	title = {Contrastive {Learning} for {Debiased} {Candidate} {Generation} in {Large}-{Scale} {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2005.12964},
	abstract = {Deep candidate generation (DCG) that narrows down the collection of relevant items from billions to hundreds via representation learning has become prevalent in industrial recommender systems. Standard approaches approximate maximum likelihood estimation (MLE) through sampling for better scalability and address the problem of DCG in a way similar to language modeling. However, live recommender systems face severe exposure bias and have a vocabulary several orders of magnitude larger than that of natural language, implying that MLE will preserve and even exacerbate the exposure bias in the long run in order to faithfully fit the observed samples. In this paper, we theoretically prove that a popular choice of contrastive loss is equivalent to reducing the exposure bias via inverse propensity weighting, which provides a new perspective for understanding the effectiveness of contrastive learning. Based on the theoretical discovery, we design CLRec, a contrastive learning method to improve DCG in terms of fairness, effectiveness and efficiency in recommender systems with extremely large candidate size. We further improve upon CLRec and propose Multi-CLRec, for accurate multi-intention aware bias reduction. Our methods have been successfully deployed in Taobao, where at least four-month online A/B tests and offline analyses demonstrate its substantial improvements, including a dramatic reduction in the Matthew effect.},
	urldate = {2021-06-20},
	journal = {arXiv:2005.12964 [cs, stat]},
	author = {Zhou, Chang and Ma, Jianxin and Zhang, Jianwei and Zhou, Jingren and Yang, Hongxia},
	month = jun,
	year = {2021},
	note = {arXiv: 2005.12964},
	keywords = {Bias, Recommender Systems},
}

@article{buyl_debayes_2021,
	title = {{DeBayes}: a {Bayesian} {Method} for {Debiasing} {Network} {Embeddings}},
	shorttitle = {{DeBayes}},
	url = {http://arxiv.org/abs/2002.11442},
	abstract = {As machine learning algorithms are increasingly deployed for high-impact automated decision making, ethical and increasingly also legal standards demand that they treat all individuals fairly, without discrimination based on their age, gender, race or other sensitive traits. In recent years much progress has been made on ensuring fairness and reducing bias in standard machine learning settings. Yet, for network embedding, with applications in vulnerable domains ranging from social network analysis to recommender systems, current options remain limited both in number and performance. We thus propose DeBayes: a conceptually elegant Bayesian method that is capable of learning debiased embeddings by using a biased prior. Our experiments show that these representations can then be used to perform link prediction that is significantly more fair in terms of popular metrics such as demographic parity and equalized opportunity.},
	urldate = {2021-06-20},
	journal = {arXiv:2002.11442 [cs, stat]},
	author = {Buyl, Maarten and De Bie, Tijl},
	month = apr,
	year = {2021},
	note = {arXiv: 2002.11442},
	keywords = {Bias, Networks},
}

@article{abdollahpouri_multi-sided_2020,
	title = {Multi-sided {Exposure} {Bias} in {Recommendation}},
	url = {http://arxiv.org/abs/2006.15772},
	abstract = {Academic research in recommender systems has been greatly focusing on the accuracy-related measures of recommendations. Even when non-accuracy measures such as popularity bias, diversity, and novelty are studied, it is often solely from the users' perspective. However, many real-world recommenders are often multi-stakeholder environments in which the needs and interests of several stakeholders should be addressed in the recommendation process. In this paper, we focus on the popularity bias problem which is a well-known property of many recommendation algorithms where few popular items are over-recommended while the majority of other items do not get proportional attention and address its impact on different stakeholders. Using several recommendation algorithms and two publicly available datasets in music and movie domains, we empirically show the inherent popularity bias of the algorithms and how this bias impacts different stakeholders such as users and suppliers of the items. We also propose metrics to measure the exposure bias of recommendation algorithms from the perspective of different stakeholders.},
	urldate = {2021-06-20},
	journal = {arXiv:2006.15772 [cs]},
	author = {Abdollahpouri, Himan and Mansoury, Masoud},
	month = jul,
	year = {2020},
	note = {arXiv: 2006.15772},
	keywords = {Bias, Recommender Systems},
}

@article{fu_fairness-aware_2020,
	title = {Fairness-{Aware} {Explainable} {Recommendation} over {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2006.02046},
	abstract = {There has been growing attention on fairness considerations recently, especially in the context of intelligent decision making systems. Explainable recommendation systems, in particular, may suffer from both explanation bias and performance disparity. In this paper, we analyze different groups of users according to their level of activity, and find that bias exists in recommendation performance between different groups. We show that inactive users may be more susceptible to receiving unsatisfactory recommendations, due to insufficient training data for the inactive users, and that their recommendations may be biased by the training records of more active users, due to the nature of collaborative filtering, which leads to an unfair treatment by the system. We propose a fairness constrained approach via heuristic re-ranking to mitigate this unfairness problem in the context of explainable recommendation over knowledge graphs. We experiment on several real-world datasets with state-of-the-art knowledge graph-based explainable recommendation algorithms. The promising results show that our algorithm is not only able to provide high-quality explainable recommendations, but also reduces the recommendation unfairness in several respects.},
	urldate = {2021-06-20},
	journal = {arXiv:2006.02046 [cs]},
	author = {Fu, Zuohui and Xian, Yikun and Gao, Ruoyuan and Zhao, Jieyu and Huang, Qiaoying and Ge, Yingqiang and Xu, Shuyuan and Geng, Shijie and Shah, Chirag and Zhang, Yongfeng and de Melo, Gerard},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.02046},
	keywords = {Bias, Model, Recommender Systems},
}

@article{bobadilla_deepfair_2021,
	title = {{DeepFair}: {Deep} {Learning} for {Improving} {Fairness} in {Recommender} {Systems}},
	volume = {6},
	issn = {1989-1660},
	shorttitle = {{DeepFair}},
	url = {http://arxiv.org/abs/2006.05255},
	doi = {10.9781/ijimai.2020.11.001},
	abstract = {The lack of bias management in Recommender Systems leads to minority groups receiving unfair recommendations. Moreover, the trade-off between equity and precision makes it difficult to obtain recommendations that meet both criteria. Here we propose a Deep Learning based Collaborative Filtering algorithm that provides recommendations with an optimum balance between fairness and accuracy without knowing demographic information about the users. Experimental results show that it is possible to make fair recommendations without losing a significant proportion of accuracy.},
	number = {6},
	urldate = {2021-06-20},
	journal = {International Journal of Interactive Multimedia and Artificial Intelligence},
	author = {Bobadilla, Jesús and Lara-Cabrera, Raúl and González-Prieto, Ángel and Ortega, Fernando},
	year = {2021},
	note = {arXiv: 2006.05255},
	keywords = {Bias, Recommender Systems, Deep Learning},
	pages = {86},
}

@article{lal_fairness-aware_2020,
	title = {Fairness-{Aware} {Online} {Personalization}},
	url = {http://arxiv.org/abs/2007.15270},
	abstract = {Decision making in crucial applications such as lending, hiring, and college admissions has witnessed increasing use of algorithmic models and techniques as a result of a confluence of factors such as ubiquitous connectivity, ability to collect, aggregate, and process large amounts of fine-grained data using cloud computing, and ease of access to applying sophisticated machine learning models. Quite often, such applications are powered by search and recommendation systems, which in turn make use of personalized ranking algorithms. At the same time, there is increasing awareness about the ethical and legal challenges posed by the use of such data-driven systems. Researchers and practitioners from different disciplines have recently highlighted the potential for such systems to discriminate against certain population groups, due to biases in the datasets utilized for learning their underlying recommendation models. We present a study of fairness in online personalization settings involving the ranking of individuals. Starting from a fair warm-start machine-learned model, we first demonstrate that online personalization can cause the model to learn to act in an unfair manner if the user is biased in his/her responses. For this purpose, we construct a stylized model for generating training data with potentially biased features as well as potentially biased labels and quantify the extent of bias that is learned by the model when the user responds in a biased manner as in many real-world scenarios. We then formulate the problem of learning personalized models under fairness constraints and present a regularization based approach for mitigating biases in machine learning. We demonstrate the efficacy of our approach through extensive simulations with different parameter settings. Code: https://github.com/groshanlal/Fairness-Aware-Online-Personalization},
	urldate = {2021-06-20},
	journal = {arXiv:2007.15270 [cs, stat]},
	author = {Lal, G. Roshan and Geyik, Sahin Cem and Kenthapadi, Krishnaram},
	month = sep,
	year = {2020},
	note = {arXiv: 2007.15270},
	keywords = {Bias, Personalization},
}

@article{mansoury_feedback_2020,
	title = {Feedback {Loop} and {Bias} {Amplification} in {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2007.13019},
	abstract = {Recommendation algorithms are known to suffer from popularity bias; a few popular items are recommended frequently while the majority of other items are ignored. These recommendations are then consumed by the users, their reaction will be logged and added to the system: what is generally known as a feedback loop. In this paper, we propose a method for simulating the users interaction with the recommenders in an offline setting and study the impact of feedback loop on the popularity bias amplification of several recommendation algorithms. We then show how this bias amplification leads to several other problems such as declining the aggregate diversity, shifting the representation of users' taste over time and also homogenization of the users experience. In particular, we show that the impact of feedback loop is generally stronger for the users who belong to the minority group.},
	urldate = {2021-06-20},
	journal = {arXiv:2007.13019 [cs]},
	author = {Mansoury, Masoud and Abdollahpouri, Himan and Pechenizkiy, Mykola and Mobasher, Bamshad and Burke, Robin},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.13019},
	keywords = {Bias, Recommender Systems},
	file = {Full Text:/Users/clente/Zotero/storage/VY7EP8GH/Mansoury et al. - 2020 - Feedback Loop and Bias Amplification in Recommende.pdf:application/pdf},
}

@article{abdollahpouri_connection_2020,
	title = {The {Connection} {Between} {Popularity} {Bias}, {Calibration}, and {Fairness} in {Recommendation}},
	url = {http://arxiv.org/abs/2008.09273},
	abstract = {Recently there has been a growing interest in fairness-aware recommender systems including fairness in providing consistent performance across different users or groups of users. A recommender system could be considered unfair if the recommendations do not fairly represent the tastes of a certain group of users while other groups receive recommendations that are consistent with their preferences. In this paper, we use a metric called miscalibration for measuring how a recommendation algorithm is responsive to users' true preferences and we consider how various algorithms may result in different degrees of miscalibration for different users. In particular, we conjecture that popularity bias which is a well-known phenomenon in recommendation is one important factor leading to miscalibration in recommendation. Our experimental results using two real-world datasets show that there is a connection between how different user groups are affected by algorithmic popularity bias and their level of interest in popular items. Moreover, we show that the more a group is affected by the algorithmic popularity bias, the more their recommendations are miscalibrated.},
	urldate = {2021-06-20},
	journal = {arXiv:2008.09273 [cs]},
	author = {Abdollahpouri, Himan and Mansoury, Masoud and Burke, Robin and Mobasher, Bamshad},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.09273},
	keywords = {Bias, Recommender Systems},
}

@article{chen_bias_2020,
	title = {Bias and {Debias} in {Recommender} {System}: {A} {Survey} and {Future} {Directions}},
	shorttitle = {Bias and {Debias} in {Recommender} {System}},
	url = {http://arxiv.org/abs/2010.03240},
	abstract = {While recent years have witnessed a rapid growth of research papers on recommender system (RS), most of the papers focus on inventing machine learning models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, etc. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. When reviewing the papers that consider biases in RS, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. The terminology "bias" is widely used in the literature, but its definition is usually vague and even inconsistent across papers. This motivates us to provide a systematic survey of existing work on RS biases. In this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. We then provide a taxonomy to position and organize the existing work on recommendation debiasing. Finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic.},
	urldate = {2021-06-20},
	journal = {arXiv:2010.03240 [cs]},
	author = {Chen, Jiawei and Dong, Hande and Wang, Xiang and Feng, Fuli and Wang, Meng and He, Xiangnan},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.03240},
	keywords = {Bias, Recommender Systems, Survey},
}

@article{caton_fairness_2020,
	title = {Fairness in {Machine} {Learning}: {A} {Survey}},
	shorttitle = {Fairness in {Machine} {Learning}},
	url = {http://arxiv.org/abs/2010.04053},
	abstract = {As Machine Learning technologies become increasingly used in contexts that affect citizens, companies as well as researchers need to be confident that their application of these methods will not have unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote fairness, yet the area is complex and hard to penetrate for newcomers to the domain. This article seeks to provide an overview of the different schools of thought and approaches to mitigating (social) biases and increase fairness in the Machine Learning literature. It organises approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, unsupervised learning, and natural language processing is also provided along with a selection of currently available open source libraries. The article concludes by summarising open challenges articulated as four dilemmas for fairness research.},
	urldate = {2021-06-20},
	journal = {arXiv:2010.04053 [cs, stat]},
	author = {Caton, Simon and Haas, Christian},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.04053},
	keywords = {Bias, Survey, Machine Learning},
	file = {Full Text:/Users/clente/Zotero/storage/U9JMGNLC/Caton and Haas - 2020 - Fairness in Machine Learning A Survey.pdf:application/pdf},
}

@article{hirakura_model_2020,
	title = {A {Model} of {Polarization} on {Social} {Media} {Caused} by {Empathy} and {Repulsion}},
	url = {http://arxiv.org/abs/2011.08141},
	abstract = {In recent years, the ease with which social media can be accessed has led to the unexpected problem of a shrinkage in information sources. This phenomenon is caused by a system that facilitates the connection of people with similar ideas and recommendation systems. Bias in the selection of information sources promotes polarization that divides people into multiple groups with opposing views and creates conflicts between opposing groups. This paper elucidates the mechanism of polarization by proposing a model of opinion formation in social media that considers users' reactions of empathy and repulsion. Based on the idea that opinion neutrality is only relative, this model offers a novel technology for dealing with polarization.},
	urldate = {2021-06-20},
	journal = {arXiv:2011.08141 [physics]},
	author = {Hirakura, Naoki and Aida, Masaki and Kawashima, Konosuke},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.08141},
	keywords = {Model, Polarization},
}

@article{mondal_two-sided_2020,
	title = {Two-{Sided} {Fairness} in {Non}-{Personalised} {Recommendations}},
	url = {http://arxiv.org/abs/2011.05287},
	abstract = {Recommender systems are one of the most widely used services on several online platforms to suggest potential items to the end-users. These services often use different machine learning techniques for which fairness is a concerning factor, especially when the downstream services have the ability to cause social ramifications. Thus, focusing on the non-personalised (global) recommendations in news media platforms (e.g., top-k trending topics on Twitter, top-k news on a news platform, etc.), we discuss on two specific fairness concerns together (traditionally studied separately)---user fairness and organisational fairness. While user fairness captures the idea of representing the choices of all the individual users in the case of global recommendations, organisational fairness tries to ensure politically/ideologically balanced recommendation sets. This makes user fairness a user-side requirement and organisational fairness a platform-side requirement. For user fairness, we test with methods from social choice theory, i.e., various voting rules known to better represent user choices in their results. Even in our application of voting rules to the recommendation setup, we observe high user satisfaction scores. Now for organisational fairness, we propose a bias metric which measures the aggregate ideological bias of a recommended set of items (articles). Analysing the results obtained from voting rule-based recommendation, we find that while the well-known voting rules are better from the user side, they show high bias values and clearly not suitable for organisational requirements of the platforms. Thus, there is a need to build an encompassing mechanism by cohesively bridging ideas of user fairness and organisational fairness. In this abstract paper, we intend to frame the elementary ideas along with the clear motivation behind the requirement of such a mechanism.},
	urldate = {2021-06-20},
	journal = {arXiv:2011.05287 [cs]},
	author = {Mondal, Aadi Swadipto and Bal, Rakesh and Sinha, Sayan and Patro, Gourab K.},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.05287},
	keywords = {Bias, Recommender Systems, Personalization},
}

@article{yao_measuring_2021,
	title = {Measuring {Recommender} {System} {Effects} with {Simulated} {Users}},
	url = {http://arxiv.org/abs/2101.04526},
	abstract = {Imagine a food recommender system -- how would we check if it is {\textbackslash}emph\{causing\} and fostering unhealthy eating habits or merely reflecting users' interests? How much of a user's experience over time with a recommender is caused by the recommender system's choices and biases, and how much is based on the user's preferences and biases? Popularity bias and filter bubbles are two of the most well-studied recommender system biases, but most of the prior research has focused on understanding the system behavior in a single recommendation step. How do these biases interplay with user behavior, and what types of user experiences are created from repeated interactions? In this work, we offer a simulation framework for measuring the impact of a recommender system under different types of user behavior. Using this simulation framework, we can (a) isolate the effect of the recommender system from the user preferences, and (b) examine how the system performs not just on average for an "average user" but also the extreme experiences under atypical user behavior. As part of the simulation framework, we propose a set of evaluation metrics over the simulations to understand the recommender system's behavior. Finally, we present two empirical case studies -- one on traditional collaborative filtering in MovieLens and one on a large-scale production recommender system -- to understand how popularity bias manifests over time.},
	urldate = {2021-06-20},
	journal = {arXiv:2101.04526 [cs]},
	author = {Yao, Sirui and Halpern, Yoni and Thain, Nithum and Wang, Xuezhi and Lee, Kang and Prost, Flavien and Chi, Ed H. and Chen, Jilin and Beutel, Alex},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.04526},
	keywords = {Model, Recommender Systems},
	file = {Yao et al. - 2021 - Measuring Recommender System Effects with Simulate.pdf:/Users/clente/Zotero/storage/7DT28Q5K/Yao et al. - 2021 - Measuring Recommender System Effects with Simulate.pdf:application/pdf},
}

@inproceedings{qin_attribute-based_2020,
	address = {New York, NY, USA},
	series = {{KDD} '20},
	title = {Attribute-based {Propensity} for {Unbiased} {Learning} in {Recommender} {Systems}: {Algorithm} and {Case} {Studies}},
	isbn = {978-1-4503-7998-4},
	shorttitle = {Attribute-based {Propensity} for {Unbiased} {Learning} in {Recommender} {Systems}},
	url = {https://doi.org/10.1145/3394486.3403285},
	doi = {10.1145/3394486.3403285},
	abstract = {Many modern recommender systems train their models based on a large amount of implicit user feedback data. Due to the inherent bias in this data (e.g., position bias), learning from it directly can lead to suboptimal models. Recently, unbiased learning was proposed to address such problems by leveraging counterfactual techniques like inverse propensity weighting (IPW). In these methods, propensity scores estimation is usually limited to item's display position in a single user interface (UI). In this paper, we generalize the traditional position bias model to an attribute-based propensity framework. Our methods estimate propensity scores based on offline data and allow propensity estimation across a broad range of implicit feedback scenarios, e.g., feedback beyond recommender system UI. We demonstrate this by applying this framework to three real-world large-scale recommender systems in Google Drive that serve millions of users. For each system, we conduct both offline and online evaluation. Our results show that the proposed framework is able to significantly improve upon strong production baselines across a diverse range of recommendation item types (documents, people-document pairs, and queries), UI layouts (horizontal, vertical, and grid layouts), and underlying learning algorithms (gradient boosted decision trees and neural networks), all without the need to intervene and degrade the user experience. The proposed models have been deployed in the production systems with ease since no serving infrastructure change is needed.},
	urldate = {2021-06-20},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Qin, Zhen and Chen, Suming J. and Metzler, Donald and Noh, Yongwoo and Qin, Jingzheng and Wang, Xuanhui},
	month = aug,
	year = {2020},
	keywords = {Bias, Recommender Systems},
	pages = {2359--2367},
}

@article{edizel_fairecsys_2020,
	title = {{FaiRecSys}: mitigating algorithmic bias in recommender systems},
	volume = {9},
	issn = {2364-4168},
	shorttitle = {{FaiRecSys}},
	url = {https://doi.org/10.1007/s41060-019-00181-5},
	doi = {10.1007/s41060-019-00181-5},
	abstract = {Recommendation and personalization are useful technologies which influence more and more our daily decisions. However, as we show empirically in this paper, the bias that exists in the real world and which is reflected in the training data can be modeled and amplified by recommender systems and in the end returned as biased recommendations to the users. This feedback process creates a self-perpetuating loop which progressively strengthens the filter bubbles we live in. Biased recommendations can also reinforce stereotypes such as those based on gender or ethnicity, possibly resulting in disparate impact. In this paper we address the problem of algorithmic bias in recommender systems. In particular, we highlight the connection between predictability of sensitive features and bias in the results of recommendations and we then offer a theoretically founded bound on recommendation bias based on that connection. We continue to formalize a fairness constraint and the price that one has to pay, in terms of alterations in the recommendation matrix, in order to achieve fair recommendations. Finally, we propose FaiRecSys—an algorithm that mitigates algorithmic bias by post-processing the recommendation matrix with minimum impact on the utility of recommendations provided to the end-users.},
	language = {en},
	number = {2},
	urldate = {2021-06-20},
	journal = {International Journal of Data Science and Analytics},
	author = {Edizel, Bora and Bonchi, Francesco and Hajian, Sara and Panisson, André and Tassa, Tamir},
	month = mar,
	year = {2020},
	keywords = {Bias, Recommender Systems},
	pages = {197--213},
}

@article{gharahighehi_fair_2021,
	title = {Fair {Multi}-{Stakeholder} {News} {Recommender} {System} with {Hypergraph} ranking},
	url = {http://arxiv.org/abs/2012.00387},
	abstract = {Recommender systems are typically designed to fulfill end user needs. However, in some domains the users are not the only stakeholders in the system. For instance, in a news aggregator website users, authors, magazines as well as the platform itself are potential stakeholders. Most of the collaborative filtering recommender systems suffer from popularity bias. Therefore, if the recommender system only considers users' preferences, presumably it over-represents popular providers and under-represents less popular providers. To address this issue one should consider other stakeholders in the generated ranked lists. In this paper we demonstrate that hypergraph learning has the natural capability of handling a multi-stakeholder recommendation task. A hypergraph can model high order relations between different types of objects and therefore is naturally inclined to generate recommendation lists considering multiple stakeholders. We form the recommendations in time-wise rounds and learn to adapt the weights of stakeholders to increase the coverage of low-covered stakeholders over time. The results show that the proposed approach counters popularity bias and produces fairer recommendations with respect to authors in two news datasets, at a low cost in precision.},
	urldate = {2021-06-20},
	journal = {arXiv:2012.00387 [cs]},
	author = {Gharahighehi, Alireza and Vens, Celine and Pliakos, Konstantinos},
	month = feb,
	year = {2021},
	note = {arXiv: 2012.00387},
	keywords = {Bias, Recommender Systems},
}

@article{wang_user_2020,
	title = {A {User} {Study} on a {De}-biased {Career} {Recommender} {System}},
	copyright = {This item is likely protected under Title 17 of the U.S. Copyright Law. Unless on a Creative Commons license, for uses protected by Copyright Law, contact the copyright holder or the author.},
	url = {https://mdsoar.org/handle/11603/18827},
	doi = {10.13016/m2ku23-ywy8},
	abstract = {AI is increasingly being used in making consequential decisions such as determining whether someone is granted parole or not (Angwin et al., 2016). Unfortunately, there have been a wide range of recent discoveries of biased AI systems that are
prejudiced against certain groups of people (Dastin, 2018; Noble, 2018; Angwin et al., 2016). In this research, we focus on developing new techniques that mitigate gender biases in automated career recommendation systems. Since biases are typically inherent in AI systems trained on data influenced by our society, an AI recommender must be ”de-biased” to avoid reinforcing harmful stereotypes (e.g., recommending computer programming to boys and nursing to girls) (Bolukbasi et al., 2016;
Yao and Huang, 2017). Although it is technically possible to remove biases from an AI system, it is unclear whether intended users prefer such a system. We conduct a user study to investigate this},
	language = {en\_US},
	urldate = {2021-06-20},
	author = {Wang, Clarice and Wang, Kathryn and Bian, Andrew and Islam, Rashidul and Keya, Kamrun Naher and Foulds, James R. and Pan, Shimei},
	month = jun,
	year = {2020},
	note = {Accepted: 2020-06-05T16:29:09Z},
	keywords = {Bias, Recommender Systems},
}

@article{jiang_degenerate_2019,
	title = {Degenerate feedback loops in recommender systems},
	issn = {undefined},
	url = {https://www.mendeley.com/catalogue/c07bc3f3-281c-3ccb-b9b9-48a7fc7f2ece/},
	doi = {10.1145/3306618.3314288},
	abstract = {(2019) Jiang et al. AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. Machine learning is used extensively in recommender systems deployed in products. The decisio...},
	language = {en-GB},
	urldate = {2021-04-20},
	journal = {AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
	author = {Jiang, Ray and Chiappa, Silvia and Lattimore, Tor and György, András and Kohli, Pushmeet},
	year = {2019},
	pages = {383--390},
	file = {Submitted Version:/Users/clente/Zotero/storage/7HURSLXR/Jiang et al. - 2019 - Degenerate feedback loops in recommender systems.pdf:application/pdf},
}

@article{wisniewski_fairmodels_2021,
	title = {fairmodels: {A} {Flexible} {Tool} {For} {Bias} {Detection}, {Visualization}, {And} {Mitigation}},
	shorttitle = {fairmodels},
	url = {http://arxiv.org/abs/2104.00507},
	abstract = {Machine learning decision systems are getting omnipresent in our lives. From dating apps to rating loan seekers, algorithms affect both our well-being and future. Typically, however, these systems are not infallible. Moreover, complex predictive models are really eager to learn social biases present in historical data that can lead to increasing discrimination. If we want to create models responsibly then we need tools for in-depth validation of models also from the perspective of potential discrimination. This article introduces an R package fairmodels that helps to validate fairness and eliminate bias in classification models in an easy and flexible fashion. The fairmodels package offers a model-agnostic approach to bias detection, visualization and mitigation. The implemented set of functions and fairness metrics enables model fairness validation from different perspectives. The package includes a series of methods for bias mitigation that aim to diminish the discrimination in the model. The package is designed not only to examine a single model, but also to facilitate comparisons between multiple models.},
	urldate = {2021-04-12},
	journal = {arXiv:2104.00507 [cs, stat]},
	author = {Wiśniewski, Jakub and Biecek, Przemysław},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.00507},
	keywords = {Bias, Model, Opinion Polarization},
	file = {Wiśniewski and Biecek - 2021 - fairmodels A Flexible Tool For Bias Detection, Vi.pdf:/Users/clente/Zotero/storage/V3UV3MAZ/Wiśniewski and Biecek - 2021 - fairmodels A Flexible Tool For Bias Detection, Vi.pdf:application/pdf},
}

@article{perra_modelling_2019,
	title = {Modelling opinion dynamics in the age of algorithmic personalisation},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-019-43830-2},
	doi = {10.1038/s41598-019-43830-2},
	abstract = {Modern technology has drastically changed the way we interact and consume information. For example, online social platforms allow for seamless communication exchanges at an unprecedented scale. However, we are still bounded by cognitive and temporal constraints. Our attention is limited and extremely valuable. Algorithmic personalisation has become a standard approach to tackle the information overload problem. As result, the exposure to our friends’ opinions and our perception about important issues might be distorted. However, the effects of algorithmic gatekeeping on our hyper-connected society are poorly understood. Here, we devise an opinion dynamics model where individuals are connected through a social network and adopt opinions as function of the view points they are exposed to. We apply various filtering algorithms that select the opinions shown to each user (i) at random (ii) considering time ordering or (iii) its current opinion. Furthermore, we investigate the interplay between such mechanisms and crucial features of real networks. We found that algorithmic filtering might influence opinions’ share and distributions, especially in case information is biased towards the current opinion of each user. These effects are reinforced in networks featuring topological and spatial correlations where echo chambers and polarisation emerge. Conversely, heterogeneity in connectivity patterns reduces such tendency. We consider also a scenario where one opinion, through nudging, is centrally pushed to all users. Interestingly, even minimal nudging is able to change the status quo moving it towards the desired view point. Our findings suggest that simple filtering algorithms might be powerful tools to regulate opinion dynamics taking place on social networks.},
	language = {en},
	number = {1},
	urldate = {2021-03-26},
	journal = {Scientific Reports},
	author = {Perra, Nicola and Rocha, Luis E. C.},
	month = may,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Opinion Dynamics, Recommender Systems},
	pages = {7261},
}

@misc{noauthor_tensorflow_nodate,
	title = {{TensorFlow} {Recommenders}},
	url = {https://www.tensorflow.org/recommenders},
	abstract = {A library for building recommender system models.},
	language = {en},
	urldate = {2021-03-01},
	journal = {TensorFlow},
}

@misc{ziegler_book-crossing_2004,
	title = {Book-{Crossing} {Dataset}},
	url = {http://www2.informatik.uni-freiburg.de/~cziegler/BX/},
	urldate = {2021-03-01},
	author = {Ziegler, Cai-Nicolas},
	month = sep,
	year = {2004},
	keywords = {Recommender Systems, Dataset},
}

@misc{banik_movies_2017,
	title = {The {Movies} {Dataset}},
	url = {https://kaggle.com/rounakbanik/the-movies-dataset},
	abstract = {Metadata on over 45,000 movies. 26 million ratings from over 270,000 users.},
	language = {en},
	urldate = {2021-03-01},
	author = {Banik, Rounak},
	month = nov,
	year = {2017},
	keywords = {Recommender Systems, Dataset},
}

@inproceedings{sarwar_item-based_2001,
	address = {New York, NY, USA},
	series = {{WWW} '01},
	title = {Item-based collaborative filtering recommendation algorithms},
	isbn = {978-1-58113-348-6},
	url = {https://doi.org/10.1145/371920.372071},
	doi = {10.1145/371920.372071},
	urldate = {2021-02-28},
	booktitle = {Proceedings of the 10th international conference on {World} {Wide} {Web}},
	publisher = {Association for Computing Machinery},
	author = {Sarwar, Badrul and Karypis, George and Konstan, Joseph and Riedl, John},
	month = apr,
	year = {2001},
	keywords = {Recommender Systems, Similarity},
	pages = {285--295},
}

@book{seraphin_youth_2017,
	title = {Youth and violent extremism on social media: mapping the research},
	isbn = {978-92-3-100245-8},
	shorttitle = {Youth and violent extremism on social media},
	language = {en},
	publisher = {UNESCO Publishing},
	author = {Séraphin, Alava and Divina, Frau-Meigs and Ghayda, Hassan},
	month = dec,
	year = {2017},
	note = {Google-Books-ID: PTRCDwAAQBAJ},
}

@incollection{ricci_introduction_2011,
	address = {Boston, MA},
	title = {Introduction to {Recommender} {Systems} {Handbook}},
	isbn = {978-0-387-85820-3},
	url = {https://doi.org/10.1007/978-0-387-85820-3_1},
	abstract = {Recommender Systems (RSs) are software tools and techniques providing suggestions for items to be of use to a user. In this introductory chapter we briefly discuss basic RS ideas and concepts. Our main goal is to delineate, in a coherent and structured way, the chapters included in this handbook and to help the reader navigate the extremely rich and detailed content that the handbook offers.},
	language = {en},
	urldate = {2021-02-28},
	booktitle = {Recommender {Systems} {Handbook}},
	publisher = {Springer US},
	author = {Ricci, Francesco and Rokach, Lior and Shapira, Bracha},
	editor = {Ricci, Francesco and Rokach, Lior and Shapira, Bracha and Kantor, Paul B.},
	year = {2011},
	doi = {10.1007/978-0-387-85820-3_1},
	pages = {1--35},
}

@article{goldberg_using_1992,
	title = {Using collaborative filtering to weave an information tapestry},
	volume = {35},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/138859.138867},
	doi = {10.1145/138859.138867},
	number = {12},
	urldate = {2021-02-28},
	journal = {Communications of the ACM},
	author = {Goldberg, David and Nichols, David and Oki, Brian M. and Terry, Douglas},
	month = dec,
	year = {1992},
	keywords = {Recommender Systems},
	pages = {61--70},
}

@article{harper_movielens_2015,
	title = {The {MovieLens} {Datasets}: {History} and {Context}},
	volume = {5},
	issn = {2160-6455},
	shorttitle = {The {MovieLens} {Datasets}},
	url = {https://doi.org/10.1145/2827872},
	doi = {10.1145/2827872},
	abstract = {The MovieLens datasets are widely used in education, research, and industry. They are downloaded hundreds of thousands of times each year, reflecting their use in popular press programming books, traditional and online courses, and software. These datasets are a product of member activity in the MovieLens movie recommendation system, an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research.},
	number = {4},
	urldate = {2021-02-19},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Harper, F. Maxwell and Konstan, Joseph A.},
	month = dec,
	year = {2015},
	keywords = {Recommender Systems, Dataset},
	pages = {19:1--19:19},
}

@article{schmidt_polarization_2018,
	title = {Polarization of the vaccination debate on {Facebook}},
	volume = {36},
	issn = {0264-410X},
	url = {https://www.sciencedirect.com/science/article/pii/S0264410X18306601},
	doi = {10.1016/j.vaccine.2018.05.040},
	abstract = {Background
Vaccine hesitancy has been recognized as a major global health threat. Having access to any type of information in social media has been suggested as a potential influence on the growth of anti-vaccination groups. Recent studies w.r.t. other topics than vaccination show that access to a wide amount of content through the Internet without intermediaries resolved into major segregation of the users in polarized groups. Users select information adhering to theirs system of beliefs and tend to ignore dissenting information.
Objectives
The goal was to assess whether users’ attitudes are polarized on the topic of vaccination on Facebook and how this polarization develops over time.
Methods
We perform a thorough quantitative analysis by studying the interaction of 2.6 M users with 298,018 Facebook posts over a time span of seven years and 5 months. We applied community detection algorithms to automatically detect the emergence of communities accounting for the users’ activity on the pages. Also, we quantified the cohesiveness of these communities over time.
Results
Our findings show that the consumption of content about vaccines is dominated by the echo chamber effect and that polarization increased over the years. Well-segregated communities emerge from the users’ consumption habits i.e., the majority of users consume information in favor or against vaccines, not both.
Conclusion
The existence of echo chambers may explain why social-media campaigns that provide accurate information have limited reach and be effective only in sub-groups, even fomenting further opinion polarization. The introduction of dissenting information into a sub-group is disregarded and can produce a backfire effect, thus reinforcing the pre-existing opinions within the sub-group. Public health professionals should try to understand the contents of these echo chambers, for example by getting passively involved in such groups. Only then it will be possible to find effective ways of countering anti-vaccination thinking.},
	language = {en},
	number = {25},
	urldate = {2021-02-05},
	journal = {Vaccine},
	author = {Schmidt, Ana Lucía and Zollo, Fabiana and Scala, Antonio and Betsch, Cornelia and Quattrociocchi, Walter},
	month = jun,
	year = {2018},
	keywords = {Social Networks, Opinion Polarization},
	pages = {3606--3612},
}

@incollection{garimella_political_2018,
	address = {Republic and Canton of Geneva, CHE},
	title = {Political {Discourse} on {Social} {Media}: {Echo} {Chambers}, {Gatekeepers}, and the {Price} of {Bipartisanship}},
	isbn = {978-1-4503-5639-8},
	shorttitle = {Political {Discourse} on {Social} {Media}},
	url = {https://doi.org/10.1145/3178876.3186139},
	abstract = {Echo chambers, i.e., situations where one is exposed only to opinions that agree with their own, are an increasing concern for the political discourse in many democratic countries. This paper studies the phenomenon of political echo chambers on social media. We identify the two components in the phenomenon: the opinion that is shared, and the »chamber» (i.e., the social network) that allows the opinion to »echo» (i.e., be re-shared in the network) -- and examine closely at how these two components interact. We define a production and consumption measure for social-media users, which captures the political leaning of the content shared and received by them. By comparing the two, we find that Twitter users are, to a large degree, exposed to political opinions that agree with their own. We also find that users who try to bridge the echo chambers, by sharing content with diverse leaning, have to pay a »price of bipartisanship» in terms of their network centrality and content appreciation. In addition, we study the role of »gatekeepers,» users who consume content with diverse leaning but produce partisan content (with a single-sided leaning), in the formation of echo chambers. Finally, we apply these findings to the task of predicting partisans and gatekeepers from social and content features. While partisan users turn out relatively easy to identify, gatekeepers prove to be more challenging.},
	urldate = {2021-02-05},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Garimella, Kiran and De Francisci Morales, Gianmarco and Gionis, Aristides and Mathioudakis, Michael},
	month = apr,
	year = {2018},
	keywords = {Filter Bubble, Politics},
	pages = {913--922},
}

@article{nikolov_quantifying_2019,
	title = {Quantifying {Biases} in {Online} {Information} {Exposure}},
	volume = {70},
	copyright = {© 2018 ASIS\&T},
	issn = {2330-1643},
	url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.24121},
	doi = {https://doi.org/10.1002/asi.24121},
	abstract = {Our consumption of online information is mediated by filtering, ranking, and recommendation algorithms that introduce unintentional biases as they attempt to deliver relevant and engaging content. It has been suggested that our reliance on online technologies such as search engines and social media may limit exposure to diverse points of view and make us vulnerable to manipulation by disinformation. In this article, we mine a massive data set of web traffic to quantify two kinds of bias: (i) homogeneity bias, which is the tendency to consume content from a narrow set of information sources, and (ii) popularity bias, which is the selective exposure to content from top sites. Our analysis reveals different bias levels across several widely used web platforms. Search exposes users to a diverse set of sources, while social media traffic tends to exhibit high popularity and homogeneity bias. When we focus our analysis on traffic to news sites, we find higher levels of popularity bias, with smaller differences across applications. Overall, our results quantify the extent to which our choices of online systems confine us inside “social bubbles.”},
	language = {en},
	number = {3},
	urldate = {2021-02-05},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Nikolov, Dimitar and Lalmas, Mounia and Flammini, Alessandro and Menczer, Filippo},
	year = {2019},
	note = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24121},
	keywords = {Bias, Opinion Polarization},
	pages = {218--229},
}

@article{meng_opinion_2018,
	title = {Opinion formation and distribution in a bounded-confidence model on various networks},
	volume = {97},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.97.022312},
	doi = {10.1103/PhysRevE.97.022312},
	abstract = {In the social, behavioral, and economic sciences, it is important to predict which individual opinions eventually dominate in a large population, whether there will be a consensus, and how long it takes for a consensus to form. Such ideas have been studied heavily both in physics and in other disciplines, and the answers depend strongly both on how one models opinions and on the network structure on which opinions evolve. One model that was created to study consensus formation quantitatively is the Deffuant model, in which the opinion distribution of a population evolves via sequential random pairwise encounters. To consider heterogeneity of interactions in a population along with social influence, we study the Deffuant model on various network structures (deterministic synthetic networks, random synthetic networks, and social networks constructed from Facebook data). We numerically simulate the Deffuant model and conduct regression analyses to investigate the dependence of the time to reach steady states on various model parameters, including a confidence bound for opinion updates, the number of participating entities, and their willingness to compromise. We find that network structure and parameter values both have important effects on the convergence time and the number of steady-state opinion groups. For some network architectures, we observe that the relationship between the convergence time and model parameters undergoes a transition at a critical value of the confidence bound. For some networks, the steady-state opinion distribution also changes from consensus to multiple opinion groups at this critical value.},
	number = {2},
	urldate = {2021-02-05},
	journal = {Physical Review E},
	author = {Meng, X. Flora and Van Gorder, Robert A. and Porter, Mason A.},
	month = feb,
	year = {2018},
	note = {Publisher: American Physical Society},
	keywords = {Opinion Dynamics, Bounded Confidence},
	pages = {022312},
}

@article{moller_not_2018,
	title = {Do not blame it on the algorithm: an empirical assessment of multiple recommender systems and their impact on content diversity},
	volume = {21},
	issn = {1369-118X},
	shorttitle = {Do not blame it on the algorithm},
	url = {https://doi.org/10.1080/1369118X.2018.1444076},
	doi = {10.1080/1369118X.2018.1444076},
	abstract = {In the debate about filter bubbles caused by algorithmic news recommendation, the conceptualization of the two core concepts in this debate, diversity and algorithms, has received little attention in social scientific research. This paper examines the effect of multiple recommender systems on different diversity dimensions. To this end, it maps different values that diversity can serve, and a respective set of criteria that characterizes a diverse information offer in this particular conception of diversity. We make use of a data set of simulated article recommendations based on actual content of one of the major Dutch broadsheet newspapers and its users (N=21,973 articles, N=500 users). We find that all of the recommendation logics under study proved to lead to a rather diverse set of recommendations that are on par with human editors and that basing recommendations on user histories can substantially increase topic diversity within a recommendation set.},
	number = {7},
	urldate = {2021-02-05},
	journal = {Information, Communication \& Society},
	author = {Möller, Judith and Trilling, Damian and Helberger, Natali and Es, Bram van},
	month = jul,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1369118X.2018.1444076},
	keywords = {Bias, Recommender Systems},
	pages = {959--977},
	file = {Full Text:/Users/clente/Zotero/storage/2H7G4MGD/Möller et al. - 2018 - Do not blame it on the algorithm an empirical ass.pdf:application/pdf},
}

@article{van_de_rijt_self-correcting_2019,
	title = {Self-{Correcting} {Dynamics} in {Social} {Influence} {Processes}},
	volume = {124},
	issn = {0002-9602},
	url = {https://www.journals.uchicago.edu/doi/10.1086/702899},
	doi = {10.1086/702899},
	abstract = {Social influence may lead individuals to choose what is popular over what is best. Whenever this happens, it further increases the popularity advantage of the inferior choice, compelling subsequent decision makers to follow suit. The author argues that despite this positive feedback effect, discordances between popularity and quality will usually self-correct. Reanalyzing past experimental studies in which social information initially heavily favored inferior options, the author shows that in each experiment superior alternatives gained in popularity. This article also reports on a new experiment in which a larger number of subject choices allowed trials to be run to convergence and shows that in each trial the superior alternative eventually achieved popular dominance. To explain the persistent dominance of bestsellers, celebrities, and memes of seemingly questionable quality in everyday life in terms of social influence processes, one must identify conditions that render positive feedback so strong that self-correcting dynamics are prevented.},
	number = {5},
	urldate = {2021-02-05},
	journal = {American Journal of Sociology},
	author = {van de Rijt, Arnout},
	month = mar,
	year = {2019},
	note = {Publisher: The University of Chicago Press},
	keywords = {Dynamic Systems},
	pages = {1468--1495},
}

@book{strogatz_nonlinear_2018,
	title = {Nonlinear {Dynamics} and {Chaos} with {Student} {Solutions} {Manual}: {With} {Applications} to {Physics}, {Biology}, {Chemistry}, and {Engineering}, {Second} {Edition}},
	isbn = {978-0-429-68015-1},
	shorttitle = {Nonlinear {Dynamics} and {Chaos} with {Student} {Solutions} {Manual}},
	abstract = {This textbook is aimed at newcomers to nonlinear dynamics and chaos, especially students taking a first course in the subject. The presentation stresses analytical methods, concrete examples, and geometric intuition. The theory is developed systematically, starting with first-order differential equations and their bifurcations, followed by phase plane analysis, limit cycles and their bifurcations, and culminating with the Lorenz equations, chaos, iterated maps, period doubling, renormalization, fractals, and strange attractors.},
	language = {en},
	publisher = {CRC Press},
	author = {Strogatz, Steven H.},
	month = sep,
	year = {2018},
	note = {Google-Books-ID: wUBvDwAAQBAJ},
	keywords = {Dynamic Systems},
	file = {Strogatz - 2018 - Nonlinear Dynamics and Chaos with Student Solution.pdf:/Users/clente/Zotero/storage/WAJM63GS/Strogatz - 2018 - Nonlinear Dynamics and Chaos with Student Solution.pdf:application/pdf},
}

@book{dangelmayr_mathematical_2005,
	title = {Mathematical {Modeling}: {A} {Comprehensive} {Introduction}},
	language = {en},
	author = {Dangelmayr, Gerhard and Kirby, Michael},
	year = {2005},
	keywords = {Model, Dynamic Systems},
	file = {Dangelmayr and Kirby - MATHEMATICAL MODELING A Comprehensive Introduction.pdf:/Users/clente/Zotero/storage/N5LFBIGR/Dangelmayr and Kirby - MATHEMATICAL MODELING A Comprehensive Introduction.pdf:application/pdf},
}

@article{matakos_maximizing_2020,
	title = {Maximizing the {Diversity} of {Exposure} in a {Social} {Network}},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2020.3038711},
	abstract = {Social-media platforms have created new ways for citizens to stay informed and participate in public debates. However, to enable a healthy environment for information sharing, social deliberation, and opinion formation, citizens need to be exposed to sufficiently diverse viewpoints that challenge their assumptions, instead of being trapped inside filter bubbles. In this paper, we propose a novel approach to maximize the diversity of exposure in a social network. We formulate the problem in the context of information propagation, as a task of recommending a small number of news articles to selected users. We take into account content and user leanings, and the probability of further sharing an article. Our model allows us to capture the balance between maximizing the spread of information and ensuring the exposure of users to diverse viewpoints. The resulting problem can be cast as maximizing a monotone and submodular function subject to a matroid constraint on the allocation of articles to users. It is a challenging generalization of the influence-maximization problem. Yet, we are able to devise scalable approximation algorithms by introducing a novel extension to the notion of random reverse-reachable sets. We experimentally demonstrate the efficiency and scalability of our algorithm on several real-world datasets.},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Matakos, A. and Aslay, C. and Galbrun, E. and Gionis, A.},
	year = {2020},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Social Networks, Filter Bubble, Polarization},
	pages = {1--1},
	file = {Matakos et al. - 2020 - Maximizing the Diversity of Exposure in a Social N.pdf:/Users/clente/Zotero/storage/8C4LR5HF/Matakos et al. - 2020 - Maximizing the Diversity of Exposure in a Social N.pdf:application/pdf},
}

@misc{daniels_how_2021,
	title = {How {Tech} \& {Media} {Enabled} a {White} {Supremacist} {Coup}},
	url = {https://points.datasociety.net/how-tech-media-enabled-a-white-supremacist-coup-84fb75af5850},
	abstract = {The algorithmic internet acts as an accelerant for white supremacy.},
	language = {en},
	urldate = {2021-01-15},
	journal = {Medium},
	author = {Daniels, Jessie},
	month = jan,
	year = {2021},
	keywords = {Recommender Systems, Politics, Extremism},
}

@article{tonjes_coherence_2021,
	title = {Coherence resonance in influencer networks},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-20441-4},
	doi = {10.1038/s41467-020-20441-4},
	abstract = {Complex networks are abundant in nature and many share an important structural property: they contain a few nodes that are abnormally highly connected (hubs). Some of these hubs are called influencers because they couple strongly to the network and play fundamental dynamical and structural roles. Strikingly, despite the abundance of networks with influencers, little is known about their response to stochastic forcing. Here, for oscillatory dynamics on influencer networks, we show that subjecting influencers to an optimal intensity of noise can result in enhanced network synchronization. This new network dynamical effect, which we call coherence resonance in influencer networks, emerges from a synergy between network structure and stochasticity and is highly nonlinear, vanishing when the noise is too weak or too strong. Our results reveal that the influencer backbone can sharply increase the dynamical response in complex systems of coupled oscillators.},
	language = {en},
	number = {1},
	urldate = {2021-01-14},
	journal = {Nature Communications},
	author = {Tönjes, Ralf and Fiore, Carlos E. and Pereira, Tiago},
	month = jan,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Dynamic Systems},
	pages = {72},
}

@article{roth_tubes_2020,
	title = {Tubes and bubbles topological confinement of {YouTube} recommendations},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0231703},
	doi = {10.1371/journal.pone.0231703},
	abstract = {The role of recommendation algorithms in online user confinement is at the heart of a fast-growing literature. Recent empirical studies generally suggest that filter bubbles may principally be observed in the case of explicit recommendation (based on user-declared preferences) rather than implicit recommendation (based on user activity). We focus on YouTube which has become a major online content provider but where confinement has until now been little-studied in a systematic manner. We aim to contribute to the above literature by showing whether recommendation on YouTube exhibits phenomena typical of filter bubbles, tending to lower the diversity of consumed content. Starting from a diverse number of seed videos, we first describe the properties of the sets of suggested videos in order to design a sound exploration protocol able to capture latent recommendation graphs recursively induced by these suggestions. These graphs form the background of potential user navigations along non-personalized recommendations. From there, be it in topological, topical or temporal terms, we show that the landscape of what we call mean-field YouTube recommendations is often prone to confinement dynamics. Moreover, the most confined recommendation graphs i.e., potential bubbles, seem to be organized around sets of videos that garner the highest audience and thus plausibly viewing time.},
	language = {en},
	number = {4},
	urldate = {2021-01-11},
	journal = {PLOS ONE},
	author = {Roth, Camille and Mazières, Antoine and Menezes, Telmo},
	month = apr,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Social Networks, Recommender Systems},
	pages = {e0231703},
	file = {Roth et al. - 2020 - Tubes and bubbles topological confinement of YouTu.pdf:/Users/clente/Zotero/storage/3CP75ICV/Roth et al. - 2020 - Tubes and bubbles topological confinement of YouTu.pdf:application/pdf},
}

@article{ribeiro_youniverse_2020,
	title = {{YouNiverse}: {Large}-{Scale} {Channel} and {Video} {Metadata} from {English}-{Speaking} {YouTube}},
	shorttitle = {{YouNiverse}},
	url = {http://arxiv.org/abs/2012.10378},
	abstract = {YouTube plays a key role in entertaining and informing people around the globe. However, studying the platform is difficult due to the lack of randomly sampled data and of systematic ways to query the platform's colossal catalog. In this paper, we present YouNiverse, a large collection of channel and video metadata from English-language YouTube. YouNiverse comprises metadata from over 136k channels and 72.9M videos published between May 2005 and October 2019, as well as channel-level time-series data with weekly subscriber and view counts. Leveraging channel ranks from socialblade.com, an online service that provides information about YouTube, we are able to assess and enhance the representativeness of the sample of channels. YouNiverse, publicly available at https://doi.org/10.5281/zenodo.4327607, will empower the community to do research with and about YouTube.},
	urldate = {2021-01-07},
	journal = {arXiv:2012.10378 [cs]},
	author = {Ribeiro, Manoel Horta and West, Robert},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.10378},
	keywords = {Recommender Systems, Dataset},
}

@misc{noauthor_congratulations_2019,
	title = {Congratulations, {YouTube}... {Now} {Show} {Your} {Work}},
	url = {https://foundation.mozilla.org/en/blog/congratulations-youtube-now-show-your-work/},
	abstract = {Earlier this week, YouTube finally acknowledged their recommendation engine suggests harmful content. It’s a small step in the right direction, but YouTube still has a long history of dismissing independent researchers. We created a timeline to prove it.},
	language = {en},
	urldate = {2021-01-07},
	journal = {Mozilla Foundation},
	month = dec,
	year = {2019},
	note = {Section: Advocacy},
	keywords = {Social Networks, Recommender Systems},
}

@article{khan_search_2020,
	title = {In search of a strategy against misinformation},
	volume = {27},
	issn = {1528-4972},
	url = {https://doi.org/10.1145/3416051},
	doi = {10.1145/3416051},
	number = {1},
	urldate = {2021-01-07},
	journal = {XRDS: Crossroads, The ACM Magazine for Students},
	author = {Khan, Numair},
	month = sep,
	year = {2020},
	keywords = {Politics},
	pages = {8--9},
}

@book{seraphin_youth_2017-1,
	title = {Youth and violent extremism on social media: mapping the research},
	isbn = {978-92-3-100245-8},
	shorttitle = {Youth and violent extremism on social media},
	language = {en},
	publisher = {UNESCO Publishing},
	author = {Séraphin, Alava and Divina, Frau-Meigs and Ghayda, Hassan},
	month = dec,
	year = {2017},
	note = {Google-Books-ID: PTRCDwAAQBAJ},
	keywords = {Social Networks, Opinion Polarization, Extremism},
}

@article{dubois_echo_2018,
	title = {The echo chamber is overstated: the moderating effect of political interest and diverse media},
	volume = {21},
	issn = {1369-118X},
	shorttitle = {The echo chamber is overstated},
	url = {https://doi.org/10.1080/1369118X.2018.1428656},
	doi = {10.1080/1369118X.2018.1428656},
	abstract = {In a high-choice media environment, there are fears that individuals will select media and content that reinforce their existing beliefs and lead to segregation based on interest and/or partisanship. This could lead to partisan echo chambers among those who are politically interested and could contribute to a growing gap in knowledge between those who are politically interested and those who are not. However, the high-choice environment also allows individuals, including those who are politically interested, to consume a wide variety of media, which could lead them to more diverse content and perspectives. This study examines the relationship between political interest as well as media diversity and being caught in an echo chamber (measured by five different variables). Using a nationally representative survey of adult internet users in the United Kingdom (N = 2000), we find that those who are interested in politics and those with diverse media diets tend to avoid echo chambers. This work challenges the impact of echo chambers and tempers fears of partisan segregation since only a small segment of the population are likely to find themselves in an echo chamber. We argue that single media studies and studies which use narrow definitions and measurements of being in an echo chamber are flawed because they do not test the theory in the realistic context of a multiple media environment.},
	number = {5},
	urldate = {2021-01-03},
	journal = {Information, Communication \& Society},
	author = {Dubois, Elizabeth and Blank, Grant},
	month = may,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1369118X.2018.1428656},
	keywords = {Filter Bubble},
	pages = {729--745},
}

@article{lu_recommender_2015,
	title = {Recommender system application developments: {A} survey},
	volume = {74},
	issn = {0167-9236},
	shorttitle = {Recommender system application developments},
	url = {http://www.sciencedirect.com/science/article/pii/S0167923615000627},
	doi = {10.1016/j.dss.2015.03.008},
	abstract = {A recommender system aims to provide users with personalized online product or service recommendations to handle the increasing online information overload problem and improve customer relationship management. Various recommender system techniques have been proposed since the mid-1990s, and many sorts of recommender system software have been developed recently for a variety of applications. Researchers and managers recognize that recommender systems offer great opportunities and challenges for business, government, education, and other domains, with more recent successful developments of recommender systems for real-world applications becoming apparent. It is thus vital that a high quality, instructive review of current trends should be conducted, not only of the theoretical research results but more importantly of the practical developments in recommender systems. This paper therefore reviews up-to-date application developments of recommender systems, clusters their applications into eight main categories: e-government, e-business, e-commerce/e-shopping, e-library, e-learning, e-tourism, e-resource services and e-group activities, and summarizes the related recommendation techniques used in each category. It systematically examines the reported recommender systems through four dimensions: recommendation methods (such as CF), recommender systems software (such as BizSeeker), real-world application domains (such as e-business) and application platforms (such as mobile-based platforms). Some significant new topics are identified and listed as new directions. By providing a state-of-the-art knowledge, this survey will directly support researchers and practical professionals in their understanding of developments in recommender system applications.},
	language = {en},
	urldate = {2020-12-14},
	journal = {Decision Support Systems},
	author = {Lu, Jie and Wu, Dianshuang and Mao, Mingsong and Wang, Wei and Zhang, Guangquan},
	month = jun,
	year = {2015},
	keywords = {Recommender Systems, Survey},
	pages = {12--32},
}

@article{resnick_recommender_1997,
	title = {Recommender systems},
	volume = {40},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/245108.245121},
	doi = {10.1145/245108.245121},
	number = {3},
	urldate = {2020-12-13},
	journal = {Communications of the ACM},
	author = {Resnick, Paul and Varian, Hal R.},
	month = mar,
	year = {1997},
	keywords = {Recommender Systems},
	pages = {56--58},
}

@article{mathias_bounded_2016,
	title = {Bounded confidence model with fixed uncertainties and extremists: {The} opinions can keep fluctuating indefinitely},
	volume = {19},
	issn = {14607425},
	shorttitle = {Bounded confidence model with fixed uncertainties and extremists},
	url = {https://www.mendeley.com/catalogue/ff491521-7e11-3e35-ab17-7e12873171f4/?articleTrace=AAABsLvSpk_kqVGozWOGJ5WpJwCx30CJDaqYZzdg-nxLrxMmJILbfhIAArjn8vumLDv_CWf-KFAey3piQ_HDvjWvmLRU36OVN0kEItp4LGGBBTXVd8LD-Ampt_zkESDeVF_yeOpHnkAfrpYZXJZn-RILUI7jqBvXH6JkYT6YakcPb1EV35xvcmNb-HRpc3Dq17lutZGq48Y-yZB2op_HJmPFpl9y8TT_0XORY7Ml3q8CxLerFqN702D1hXHS1dBN17eYl4PlnxjWXEoXiHaMj5ZhiUF2_-8-os_X5xNgX2n5pbEUQDUYhgu10j1GaDGcXYSJyPV3TSATPGItx0p_Hw0uahwymNgC2x8Gh48sbmwsC4Z6lpvsDpJxMDwV6NNKuEQwCq_SlaaTX6CrLmF6k7Y8bSA50XUDnCz-6-idXvhYzZEOqqLcoyzcsTef7OGch08dt_kt-_txNe-TQqwmfC0JfuMMBaH7UpkCPF5n-NT3_rvixYcWaht5EfQNXtLTXuwNn-R9i8SZOUtD7gASTbH-rcrZmDLUkc18OgKkafj-iY3QduWyhDT42O8ZfAWr66P5dNMMEZOjy1IejeQKKpQ_1640V5gP&dgcid=raven_md_suggest_email},
	doi = {10.18564/jasss.2967},
	abstract = {(2016) Mathias et al. JASSS. The bounded confidence model and its variants applied to moderate and extremist agents exhibit three types of attractors: central clusters, double extreme and single ex...},
	language = {en-GB},
	number = {1},
	urldate = {2020-12-11},
	journal = {JASSS},
	author = {Mathias, Jean Denis and Huet, Sylvie and Deffuant, Guillaume},
	year = {2016},
	note = {Number: 1},
	keywords = {Opinion Dynamics, Bounded Confidence, Extremism},
	pages = {undefined--undefined},
}

@article{perra_modelling_2019-1,
	title = {Modelling opinion dynamics in the age of algorithmic personalisation},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-019-43830-2},
	doi = {10.1038/s41598-019-43830-2},
	abstract = {Modern technology has drastically changed the way we interact and consume information. For example, online social platforms allow for seamless communication exchanges at an unprecedented scale. However, we are still bounded by cognitive and temporal constraints. Our attention is limited and extremely valuable. Algorithmic personalisation has become a standard approach to tackle the information overload problem. As result, the exposure to our friends’ opinions and our perception about important issues might be distorted. However, the effects of algorithmic gatekeeping on our hyper-connected society are poorly understood. Here, we devise an opinion dynamics model where individuals are connected through a social network and adopt opinions as function of the view points they are exposed to. We apply various filtering algorithms that select the opinions shown to each user (i) at random (ii) considering time ordering or (iii) its current opinion. Furthermore, we investigate the interplay between such mechanisms and crucial features of real networks. We found that algorithmic filtering might influence opinions’ share and distributions, especially in case information is biased towards the current opinion of each user. These effects are reinforced in networks featuring topological and spatial correlations where echo chambers and polarisation emerge. Conversely, heterogeneity in connectivity patterns reduces such tendency. We consider also a scenario where one opinion, through nudging, is centrally pushed to all users. Interestingly, even minimal nudging is able to change the status quo moving it towards the desired view point. Our findings suggest that simple filtering algorithms might be powerful tools to regulate opinion dynamics taking place on social networks.},
	language = {en},
	number = {1},
	urldate = {2020-12-04},
	journal = {Scientific Reports},
	author = {Perra, Nicola and Rocha, Luis E. C.},
	month = may,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Social Networks, Opinion Dynamics, Polarization, Personalization},
	pages = {7261},
	file = {Perra and Rocha - 2019 - Modelling opinion dynamics in the age of algorithm.pdf:/Users/clente/Zotero/storage/3TWURPWX/Perra and Rocha - 2019 - Modelling opinion dynamics in the age of algorithm.pdf:application/pdf},
}

@article{pennycook_lazy_2019,
	series = {The {Cognitive} {Science} of {Political} {Thought}},
	title = {Lazy, not biased: {Susceptibility} to partisan fake news is better explained by lack of reasoning than by motivated reasoning},
	volume = {188},
	issn = {0010-0277},
	shorttitle = {Lazy, not biased},
	url = {http://www.sciencedirect.com/science/article/pii/S001002771830163X},
	doi = {10.1016/j.cognition.2018.06.011},
	abstract = {Why do people believe blatantly inaccurate news headlines (“fake news”)? Do we use our reasoning abilities to convince ourselves that statements that align with our ideology are true, or does reasoning allow us to effectively differentiate fake from real regardless of political ideology? Here we test these competing accounts in two studies (total N = 3446 Mechanical Turk workers) by using the Cognitive Reflection Test (CRT) as a measure of the propensity to engage in analytical reasoning. We find that CRT performance is negatively correlated with the perceived accuracy of fake news, and positively correlated with the ability to discern fake news from real news – even for headlines that align with individuals’ political ideology. Moreover, overall discernment was actually better for ideologically aligned headlines than for misaligned headlines. Finally, a headline-level analysis finds that CRT is negatively correlated with perceived accuracy of relatively implausible (primarily fake) headlines, and positively correlated with perceived accuracy of relatively plausible (primarily real) headlines. In contrast, the correlation between CRT and perceived accuracy is unrelated to how closely the headline aligns with the participant’s ideology. Thus, we conclude that analytic thinking is used to assess the plausibility of headlines, regardless of whether the stories are consistent or inconsistent with one’s political ideology. Our findings therefore suggest that susceptibility to fake news is driven more by lazy thinking than it is by partisan bias per se – a finding that opens potential avenues for fighting fake news.},
	language = {en},
	urldate = {2020-12-04},
	journal = {Cognition},
	author = {Pennycook, Gordon and Rand, David G.},
	month = jul,
	year = {2019},
	keywords = {Polarization},
	pages = {39--50},
}

@article{munger_right-wing_2020,
	title = {Right-{Wing} {YouTube}: {A} {Supply} and {Demand} {Perspective}},
	issn = {1940-1612},
	shorttitle = {Right-{Wing} {YouTube}},
	url = {https://doi.org/10.1177/1940161220964767},
	doi = {10.1177/1940161220964767},
	abstract = {YouTube is the most used social network in the United States and the only major platform that is more popular among right-leaning users. We propose the “Supply and Demand” framework for analyzing politics on YouTube, with an eye toward understanding dynamics among right-wing video producers and consumers. We discuss a number of novel technological affordances of YouTube as a platform and as a collection of videos, and how each might drive supply of or demand for extreme content. We then provide large-scale longitudinal descriptive information about the supply of and demand for conservative political content on YouTube. We demonstrate that viewership of far-right videos peaked in 2017.},
	language = {en},
	urldate = {2020-12-02},
	journal = {The International Journal of Press/Politics},
	author = {Munger, Kevin and Phillips, Joseph},
	month = oct,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	keywords = {Social Networks, Recommender Systems, Extremism},
	pages = {1940161220964767},
	file = {Munger and Phillips - 2020 - Right-Wing YouTube A Supply and Demand Perspectiv.pdf:/Users/clente/Zotero/storage/5JN97LGL/Munger and Phillips - 2020 - Right-Wing YouTube A Supply and Demand Perspectiv.pdf:application/pdf},
}

@article{alfano_technologically_2020,
	title = {Technologically scaffolded atypical cognition: the case of {YouTube}’s recommender system},
	issn = {1573-0964},
	shorttitle = {Technologically scaffolded atypical cognition},
	url = {https://doi.org/10.1007/s11229-020-02724-x},
	doi = {10.1007/s11229-020-02724-x},
	abstract = {YouTube has been implicated in the transformation of users into extremists and conspiracy theorists. The alleged mechanism for this radicalizing process is YouTube’s recommender system, which is optimized to amplify and promote clips that users are likely to watch through to the end. YouTube optimizes for watch-through for economic reasons: people who watch a video through to the end are likely to then watch the next recommended video as well, which means that more advertisements can be served to them. This is a seemingly innocuous design choice, but it has a troubling side-effect. Critics of YouTube have alleged that the recommender system tends to recommend extremist content and conspiracy theories, as such videos are especially likely to capture and keep users’ attention. To date, the problem of radicalization via the YouTube recommender system has been a matter of speculation. The current study represents the first systematic, pre-registered attempt to establish whether and to what extent the recommender system tends to promote such content. We begin by contextualizing our study in the framework of technological seduction. Next, we explain our methodology. After that, we present our results, which are consistent with the radicalization hypothesis. Finally, we discuss our findings, as well as directions for future research and recommendations for users, industry, and policy-makers.},
	language = {en},
	urldate = {2020-12-02},
	journal = {Synthese},
	author = {Alfano, Mark and Fard, Amir Ebrahimi and Carter, J. Adam and Clutton, Peter and Klein, Colin},
	month = jun,
	year = {2020},
	keywords = {Recommender Systems},
	file = {Alfano et al. - 2020 - Technologically scaffolded atypical cognition the.pdf:/Users/clente/Zotero/storage/MDYYEJNN/Alfano et al. - 2020 - Technologically scaffolded atypical cognition the.pdf:application/pdf},
}

@article{cho_search_2020,
	title = {Do {Search} {Algorithms} {Endanger} {Democracy}? {An} {Experimental} {Investigation} of {Algorithm} {Effects} on {Political} {Polarization}},
	volume = {64},
	issn = {0883-8151},
	shorttitle = {Do {Search} {Algorithms} {Endanger} {Democracy}?},
	url = {https://doi.org/10.1080/08838151.2020.1757365},
	doi = {10.1080/08838151.2020.1757365},
	abstract = {This study examines algorithm effects on user opinion, utilizing a real-world recommender algorithm of a highly popular video-sharing platform, YouTube. We experimentally manipulate user search/watch history by our custom programming. A controlled laboratory experiment is then conducted to examine whether exposure to algorithmically recommended content reinforces and polarizes political opinions. Results suggest that political self-reinforcement, as indicated by the political emotion-ideology alignment, and affective polarization are heightened by political videos – selected by the YouTube recommender algorithm – based on participants’ own search preferences. Suggestions for how to reduce algorithm-induced political polarization and implications of algorithmic personalization for democracy are discussed.},
	number = {2},
	urldate = {2020-12-02},
	journal = {Journal of Broadcasting \& Electronic Media},
	author = {Cho, Jaeho and Ahmed, Saifuddin and Hilbert, Martin and Liu, Billy and Luu, Jonathan},
	month = may,
	year = {2020},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08838151.2020.1757365},
	keywords = {Recommender Systems, Polarization, Extremism, Personalization},
	pages = {150--172},
	file = {Cho et al. - 2020 - Do Search Algorithms Endanger Democracy An Experi.pdf:/Users/clente/Zotero/storage/VHTHHCC5/Cho et al. - 2020 - Do Search Algorithms Endanger Democracy An Experi.pdf:application/pdf},
}

@article{faddoul_longitudinal_2020,
	title = {A {Longitudinal} {Analysis} of {YouTube}'s {Promotion} of {Conspiracy} {Videos}},
	url = {http://arxiv.org/abs/2003.03318},
	abstract = {Conspiracy theories have flourished on social media, raising concerns that such content is fueling the spread of disinformation, supporting extremist ideologies, and in some cases, leading to violence. Under increased scrutiny and pressure from legislators and the public, YouTube announced efforts to change their recommendation algorithms so that the most egregious conspiracy videos are demoted and demonetized. To verify this claim, we have developed a classifier for automatically determining if a video is conspiratorial (e.g., the moon landing was faked, the pyramids of Giza were built by aliens, end of the world prophecies, etc.). We coupled this classifier with an emulation of YouTube's watch-next algorithm on more than a thousand popular informational channels to obtain a year-long picture of the videos actively promoted by YouTube. We also obtained trends of the so-called filter-bubble effect for conspiracy theories.},
	urldate = {2020-12-02},
	journal = {arXiv:2003.03318 [cs]},
	author = {Faddoul, Marc and Chaslot, Guillaume and Farid, Hany},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.03318},
	keywords = {Social Networks, Recommender Systems, Polarization},
	file = {Faddoul et al. - 2020 - A Longitudinal Analysis of YouTube's Promotion of .pdf:/Users/clente/Zotero/storage/3WZ2L3RZ/Faddoul et al. - 2020 - A Longitudinal Analysis of YouTube's Promotion of .pdf:application/pdf},
}

@article{hosseinmardi_evaluating_2020,
	title = {Evaluating the scale, growth, and origins of right-wing echo chambers on {YouTube}},
	url = {http://arxiv.org/abs/2011.12843},
	abstract = {Although it is understudied relative to other social media platforms, YouTube is arguably the largest and most engaging online media consumption platform in the world. Recently, YouTube's outsize influence has sparked concerns that its recommendation algorithm systematically directs users to radical right-wing content. Here we investigate these concerns with large scale longitudinal data of individuals' browsing behavior spanning January 2016 through December 2019. Consistent with previous work, we find that political news content accounts for a relatively small fraction (11\%) of consumption on YouTube, and is dominated by mainstream and largely centrist sources. However, we also find evidence for a small but growing "echo chamber" of far-right content consumption. Users in this community show higher engagement and greater "stickiness" than users who consume any other category of content. Moreover, YouTube accounts for an increasing fraction of these users' overall online news consumption. Finally, while the size, intensity, and growth of this echo chamber present real concerns, we find no evidence that they are caused by YouTube recommendations. Rather, consumption of radical content on YouTube appears to reflect broader patterns of news consumption across the web. Our results emphasize the importance of measuring consumption directly rather than inferring it from recommendations.},
	urldate = {2020-11-30},
	journal = {arXiv:2011.12843 [cs]},
	author = {Hosseinmardi, Homa and Ghasemian, Amir and Clauset, Aaron and Rothschild, David M. and Mobius, Markus and Watts, Duncan J.},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.12843},
	keywords = {Social Networks, Opinion Polarization, Extremism},
	file = {Hosseinmardi et al. - 2020 - Evaluating the scale, growth, and origins of right.pdf:/Users/clente/Zotero/storage/9UXC7AW5/Hosseinmardi et al. - 2020 - Evaluating the scale, growth, and origins of right.pdf:application/pdf},
}

@article{obar_social_2015,
	series = {{SPECIAL} {ISSUE} {ON} {THE} {GOVERNANCE} {OF} {SOCIAL} {MEDIA}},
	title = {Social media definition and the governance challenge: {An} introduction to the special issue},
	volume = {39},
	issn = {0308-5961},
	shorttitle = {Social media definition and the governance challenge},
	url = {http://www.sciencedirect.com/science/article/pii/S0308596115001172},
	doi = {10.1016/j.telpol.2015.07.014},
	language = {en},
	number = {9},
	urldate = {2020-11-30},
	journal = {Telecommunications Policy},
	author = {Obar, Jonathan A. and Wildman, Steve},
	month = oct,
	year = {2015},
	keywords = {Social Networks},
	pages = {745--750},
}

@article{sinha_deconvolving_2017,
	title = {Deconvolving {Feedback} {Loops} in {Recommender} {Systems}},
	url = {http://arxiv.org/abs/1703.01049},
	abstract = {Collaborative filtering is a popular technique to infer users' preferences on new content based on the collective information of all users preferences. Recommender systems then use this information to make personalized suggestions to users. When users accept these recommendations it creates a feedback loop in the recommender system, and these loops iteratively influence the collaborative filtering algorithm's predictions over time. We investigate whether it is possible to identify items affected by these feedback loops. We state sufficient assumptions to deconvolve the feedback loops while keeping the inverse solution tractable. We furthermore develop a metric to unravel the recommender system's influence on the entire user-item rating matrix. We use this metric on synthetic and real-world datasets to (1) identify the extent to which the recommender system affects the final rating matrix, (2) rank frequently recommended items, and (3) distinguish whether a user's rated item was recommended or an intrinsic preference. Our results indicate that it is possible to recover the ratings matrix of intrinsic user preferences using a single snapshot of the ratings matrix without any temporal information.},
	urldate = {2020-11-08},
	journal = {arXiv:1703.01049 [cs]},
	author = {Sinha, Ayan and Gleich, David F. and Ramani, Karthik},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.01049},
	keywords = {Bias, Recommender Systems},
	file = {Full Text:/Users/clente/Zotero/storage/9KPZPIQA/Sinha et al. - 2017 - Deconvolving Feedback Loops in Recommender Systems.pdf:application/pdf},
}

@article{jacobs_adaptive_1991,
	title = {Adaptive {Mixtures} of {Local} {Experts}},
	volume = {3},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1991.3.1.79},
	doi = {10.1162/neco.1991.3.1.79},
	abstract = {We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised network, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.},
	number = {1},
	urldate = {2020-11-08},
	journal = {Neural Computation},
	author = {Jacobs, Robert A. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},
	month = feb,
	year = {1991},
	note = {Publisher: MIT Press},
	keywords = {Recommender Systems},
	pages = {79--87},
}

@inproceedings{cheng_wide_2016,
	address = {New York, NY, USA},
	series = {{DLRS} 2016},
	title = {Wide \& {Deep} {Learning} for {Recommender} {Systems}},
	isbn = {978-1-4503-4795-2},
	url = {https://doi.org/10.1145/2988450.2988454},
	doi = {10.1145/2988450.2988454},
	abstract = {Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide \& Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide \& Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.},
	urldate = {2020-11-08},
	booktitle = {Proceedings of the 1st {Workshop} on {Deep} {Learning} for {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
	month = sep,
	year = {2016},
	keywords = {Recommender Systems},
	pages = {7--10},
}

@inproceedings{covington_deep_2016,
	address = {New York, NY, USA},
	series = {{RecSys} '16},
	title = {Deep {Neural} {Networks} for {YouTube} {Recommendations}},
	isbn = {978-1-4503-4035-9},
	url = {https://doi.org/10.1145/2959100.2959190},
	doi = {10.1145/2959100.2959190},
	abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact.},
	urldate = {2020-11-08},
	booktitle = {Proceedings of the 10th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Covington, Paul and Adams, Jay and Sargin, Emre},
	month = sep,
	year = {2016},
	keywords = {Social Networks, Recommender Systems},
	pages = {191--198},
	file = {Covington et al. - 2016 - Deep Neural Networks for YouTube Recommendations.pdf:/Users/clente/Zotero/storage/784UFPX3/Covington et al. - 2016 - Deep Neural Networks for YouTube Recommendations.pdf:application/pdf},
}

@article{bell_lessons_2007,
	title = {Lessons from the {Netflix} prize challenge},
	volume = {9},
	issn = {1931-0145},
	url = {https://doi.org/10.1145/1345448.1345465},
	doi = {10.1145/1345448.1345465},
	abstract = {This article outlines the overall strategy and summarizes a few key innovations of the team that won the first Netflix progress prize.},
	number = {2},
	urldate = {2020-11-08},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Bell, Robert M. and Koren, Yehuda},
	month = dec,
	year = {2007},
	keywords = {Recommender Systems},
	pages = {75--79},
}

@inproceedings{ma_modeling_2018,
	address = {New York, NY, USA},
	series = {{KDD} '18},
	title = {Modeling {Task} {Relationships} in {Multi}-task {Learning} with {Multi}-gate {Mixture}-of-{Experts}},
	isbn = {978-1-4503-5552-0},
	url = {https://doi.org/10.1145/3219819.3220007},
	doi = {10.1145/3219819.3220007},
	abstract = {Neural-based multi-task learning has been successfully used in many real-world large-scale applications such as recommendation systems. For example, in movie recommendations, beyond providing users movies which they tend to purchase and watch, the system might also optimize for users liking the movies afterwards. With multi-task learning, we aim to build a single model that learns these multiple goals and tasks simultaneously. However, the prediction quality of commonly used multi-task models is often sensitive to the relationships between tasks. It is therefore important to study the modeling tradeoffs between task-specific objectives and inter-task relationships. In this work, we propose a novel multi-task learning approach, Multi-gate Mixture-of-Experts (MMoE), which explicitly learns to model task relationships from data. We adapt the Mixture-of-Experts (MoE) structure to multi-task learning by sharing the expert submodels across all tasks, while also having a gating network trained to optimize each task. To validate our approach on data with different levels of task relatedness, we first apply it to a synthetic dataset where we control the task relatedness. We show that the proposed approach performs better than baseline methods when the tasks are less related. We also show that the MMoE structure results in an additional trainability benefit, depending on different levels of randomness in the training data and model initialization. Furthermore, we demonstrate the performance improvements by MMoE on real tasks including a binary classification benchmark, and a large-scale content recommendation system at Google.},
	urldate = {2020-11-08},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Chen, Jilin and Hong, Lichan and Chi, Ed H.},
	month = jul,
	year = {2018},
	pages = {1930--1939},
}

@article{schmitt_counter-messages_2018,
	title = {Counter-messages as {Prevention} or {Promotion} of {Extremism}?! {The} {Potential} {Role} of {YouTube} {Recommendation} {Algorithms}},
	volume = {68},
	issn = {0021-9916},
	shorttitle = {Counter-messages as {Prevention} or {Promotion} of {Extremism}?},
	url = {https://academic.oup.com/joc/article/68/4/780/5042003},
	doi = {10.1093/joc/jqy029},
	abstract = {Abstract.  In order to serve as an antidote to extremist messages, counter-messages (CM) are placed in the same online environment as extremist content. Often,},
	language = {en},
	number = {4},
	urldate = {2020-11-06},
	journal = {Journal of Communication},
	author = {Schmitt, Josephine B. and Rieger, Diana and Rutkowski, Olivia and Ernst, Julian},
	month = aug,
	year = {2018},
	note = {Publisher: Oxford Academic},
	keywords = {Social Networks, Recommender Systems},
	pages = {780--808},
}

@inproceedings{ottoni_analyzing_2018,
	address = {New York, NY, USA},
	series = {{WebSci} '18},
	title = {Analyzing {Right}-wing {YouTube} {Channels}: {Hate}, {Violence} and {Discrimination}},
	isbn = {978-1-4503-5563-6},
	shorttitle = {Analyzing {Right}-wing {YouTube} {Channels}},
	url = {https://doi.org/10.1145/3201064.3201081},
	doi = {10.1145/3201064.3201081},
	abstract = {As of 2018, YouTube, the major online video sharing website, hosts multiple channels promoting right-wing content. In this paper, we observe issues related to hate, violence and discriminatory bias in a dataset containing more than 7,000 videos and 17 million comments. We investigate similarities and differences between users' comments and video content in a selection of right-wing channels and compare it to a baseline set using a three-layered approach, in which we analyze (a) lexicon, (b) topics and (c) implicit biases present in the texts. Among other results, our analyses show that right-wing channels tend to (a) contain a higher degree of words from "negative'' semantic fields, (b) raise more topics related to war and terrorism, and (c) demonstrate more discriminatory bias against Muslims (in videos) and towards LGBT people (in comments). Our findings shed light not only into the collective conduct of the YouTube community promoting and consuming right-wing content, but also into the general behavior of YouTube users.},
	urldate = {2020-11-05},
	booktitle = {Proceedings of the 10th {ACM} {Conference} on {Web} {Science}},
	publisher = {Association for Computing Machinery},
	author = {Ottoni, Raphael and Cunha, Evandro and Magno, Gabriel and Bernardina, Pedro and Meira Jr., Wagner and Almeida, Virgílio},
	month = may,
	year = {2018},
	keywords = {Social Networks, Opinion Polarization, Extremism},
	pages = {323--332},
	file = {Ottoni et al. - 2018 - Analyzing Right-wing YouTube Channels Hate, Viole.pdf:/Users/clente/Zotero/storage/7JV6S4N3/Ottoni et al. - 2018 - Analyzing Right-wing YouTube Channels Hate, Viole.pdf:application/pdf},
}

@article{nyhan_hazards_2013,
	title = {The hazards of correcting myths about health care reform},
	volume = {51},
	issn = {1537-1948},
	url = {https://pubmed.ncbi.nlm.nih.gov/23211778/},
	doi = {10.1097/MLR.0b013e318279486b},
	abstract = {CONTEXT: Misperceptions are a major problem in debates about health care reform and other controversial health issues.
METHODS: We conducted an experiment to determine if more aggressive media fact-checking could correct the false belief that the Affordable Care Act would create "death panels." Participants from an opt-in Internet panel were randomly assigned to either a control group in which they read an article on Sarah Palin's claims about "death panels" or an intervention group in which the article also contained corrective information refuting Palin.
FINDINGS: The correction reduced belief in death panels and strong opposition to the reform bill among those who view Palin unfavorably and those who view her favorably but have low political knowledge. However, it backfired among politically knowledgeable Palin supporters, who were more likely to believe in death panels and to strongly oppose reform if they received the correction.
CONCLUSIONS: These results underscore the difficulty of reducing misperceptions about health care reform among individuals with the motivation and sophistication to reject corrective information.},
	language = {eng},
	number = {2},
	journal = {Medical Care},
	author = {Nyhan, Brendan and Reifler, Jason and Ubel, Peter A.},
	month = feb,
	year = {2013},
	pmid = {23211778},
	keywords = {Opinion Polarization, Backfire Effect},
	pages = {127--132},
}

@inproceedings{dillahunt_detecting_2015,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '15},
	title = {Detecting and {Visualizing} {Filter} {Bubbles} in {Google} and {Bing}},
	isbn = {978-1-4503-3146-3},
	url = {https://doi.org/10.1145/2702613.2732850},
	doi = {10.1145/2702613.2732850},
	abstract = {Despite the pervasiveness of search engines, most users know little about the implications of search engine algorithms and are unaware of how they work. People using web search engines assume that search results are unbiased and neutral. Filter bubbles, or personalized results, could lead to polarizing effects across populations, which could create divisions in society. This preliminary work explores whether the filter bubble can be measured and described and is an initial investigation towards the larger goal of identifying how non-search experts might understand how the filter bubble impacts their search results.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Dillahunt, Tawanna R. and Brooks, Christopher A. and Gulati, Samarth},
	month = apr,
	year = {2015},
	keywords = {Filter Bubble, Personalization, Community Detection},
	pages = {1851--1856},
}

@article{baumgartner_pushshift_2020,
	title = {The {Pushshift} {Reddit} {Dataset}},
	volume = {14},
	copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2334-0770},
	url = {https://www.aaai.org/ojs/index.php/ICWSM/article/view/7347},
	abstract = {Social media data has become crucial to the advancement of scientific understanding. However, even though it has become ubiquitous, just collecting large-scale social media data involves a high degree of engineering skill set and computational resources. In fact, research is often times gated by data engineering problems that must be overcome before analysis can proceed. This has resulted recognition of datasets as meaningful research contributions in and of themselves.Reddit, the so called “front page of the Internet,” in particular has been the subject of numerous scientific studies. Although Reddit is relatively open to data acquisition compared to social media platforms like Facebook and Twitter, the technical barriers to acquisition still remain. Thus, Reddit's millions of subreddits, hundreds of millions of users, and billions of comments are at the same time relatively accessible, but time consuming to collect and analyze systematically.In this paper, we present the Pushshift Reddit dataset. Pushshift is a social media data collection, analysis, and archiving platform that since 2015 has collected Reddit data and made it available to researchers. Pushshift's Reddit dataset is updated in real-time, and includes historical data back to Reddit's inception. In addition to monthly dumps, Pushshift provides computational tools to aid in searching, aggregating, and performing exploratory analysis on the entirety of the dataset. The Pushshift Reddit dataset makes it possible for social media researchers to reduce time spent in the data collection, cleaning, and storage phases of their projects.},
	language = {en},
	urldate = {2020-11-06},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Baumgartner, Jason and Zannettou, Savvas and Keegan, Brian and Squire, Megan and Blackburn, Jeremy},
	month = may,
	year = {2020},
	keywords = {Social Networks, Dataset},
	pages = {830--839},
}

@inproceedings{sureka_mining_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Mining {YouTube} to {Discover} {Extremist} {Videos}, {Users} and {Hidden} {Communities}},
	isbn = {978-3-642-17187-1},
	doi = {10.1007/978-3-642-17187-1_2},
	abstract = {We describe a semi-automated system to assist law enforcement and intelligence agencies dealing with cyber-crime related to promotion of hate and radicalization on the Internet. The focus of this work is on mining YouTube to discover hate videos, users and virtual hidden communities. Finding precise information on YouTube is a challenging task because of the huge size of the YouTube repository and a large subscriber base. We present a solution based on data mining and social network analysis (using a variety of relationships such as friends, subscriptions, favorites and related videos) to aid an analyst in discovering insightful and actionable information. Furthermore, we performed a systematic study of the features and properties of the data and hidden social networks which has implications in understanding extremism on Internet. We take a case study based approach and perform empirical validation of the proposed hypothesis. Our approach succeeded in finding hate videos which were validated manually.},
	language = {en},
	booktitle = {Information {Retrieval} {Technology}},
	publisher = {Springer},
	author = {Sureka, Ashish and Kumaraguru, Ponnurangam and Goyal, Atul and Chhabra, Sidharth},
	editor = {Cheng, Pu-Jen and Kan, Min-Yen and Lam, Wai and Nakov, Preslav},
	year = {2010},
	keywords = {Social Networks, Opinion Polarization, Extremism, Community Detection},
	pages = {13--24},
}

@inproceedings{agarwal_topic-specific_2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Topic-{Specific} {YouTube} {Crawling} to {Detect} {Online} {Radicalization}},
	isbn = {978-3-319-16313-0},
	doi = {10.1007/978-3-319-16313-0_10},
	abstract = {Online video sharing platforms such as YouTube contains several videos and users promoting hate and extremism. Due to low barrier to publication and anonymity, YouTube is misused as a platform by some users and communities to post negative videos disseminating hatred against a particular religion, country or person. We formulate the problem of identification of such malicious videos as a search problem and present a focused-crawler based approach consisting of various components performing several tasks: search strategy or algorithm, node similarity computation metric, learning from exemplary profiles serving as training data, stopping criterion, node classifier and queue manager. We implement two versions of the focused crawler: best-first search and shark search. We conduct a series of experiments by varying the seed, number of n-grams in the language model based comparer, similarity threshold for the classifier and present the results of the experiments using standard Information Retrieval metrics such as precision, recall and F-measure. The accuracy of the proposed solution on the sample dataset is 69\% and 74\% for the best-first and shark search respectively. We perform characterization study (by manual and visual inspection) of the anti-India hate and extremism promoting videos retrieved by the focused crawler based on terms present in the title of the videos, YouTube category, average length of videos, content focus and target audience. We present the result of applying Social Network Analysis based measures to extract communities and identify core and influential users.},
	language = {en},
	booktitle = {Databases in {Networked} {Information} {Systems}},
	publisher = {Springer International Publishing},
	author = {Agarwal, Swati and Sureka, Ashish},
	editor = {Chu, Wanming and Kikuchi, Shinji and Bhalla, Subhash},
	year = {2015},
	keywords = {Social Networks, Recommender Systems, Extremism},
	pages = {133--151},
	file = {Agarwal and Sureka - 2015 - Topic-Specific YouTube Crawling to Detect Online R.pdf:/Users/clente/Zotero/storage/W94GJPX5/Agarwal and Sureka - 2015 - Topic-Specific YouTube Crawling to Detect Online R.pdf:application/pdf},
}

@inproceedings{zhao_recommending_2019,
	address = {New York, NY, USA},
	series = {{RecSys} '19},
	title = {Recommending what video to watch next: a multitask ranking system},
	isbn = {978-1-4503-6243-6},
	shorttitle = {Recommending what video to watch next},
	url = {https://doi.org/10.1145/3298689.3346997},
	doi = {10.1145/3298689.3346997},
	abstract = {In this paper, we introduce a large scale multi-objective ranking system for recommending what video to watch next on an industrial video sharing platform. The system faces many real-world challenges, including the presence of multiple competing ranking objectives, as well as implicit selection biases in user feedback. To tackle these challenges, we explored a variety of soft-parameter sharing techniques such as Multi-gate Mixture-of-Experts so as to efficiently optimize for multiple ranking objectives. Additionally, we mitigated the selection biases by adopting a Wide \& Deep framework. We demonstrated that our proposed techniques can lead to substantial improvements on recommendation quality on one of the world's largest video sharing platforms.},
	urldate = {2020-11-05},
	booktitle = {Proceedings of the 13th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Zhe and Hong, Lichan and Wei, Li and Chen, Jilin and Nath, Aniruddh and Andrews, Shawn and Kumthekar, Aditee and Sathiamoorthy, Maheswaran and Yi, Xinyang and Chi, Ed},
	month = sep,
	year = {2019},
	keywords = {Social Networks, Bias, Recommender Systems},
	pages = {43--51},
	file = {Zhao et al. - 2019 - Recommending what video to watch next a multitask.pdf:/Users/clente/Zotero/storage/KIUSZ5P4/Zhao et al. - 2019 - Recommending what video to watch next a multitask.pdf:application/pdf},
}

@article{ledwich_algorithmic_2019,
	title = {Algorithmic {Extremism}: {Examining} {YouTube}'s {Rabbit} {Hole} of {Radicalization}},
	shorttitle = {Algorithmic {Extremism}},
	url = {http://arxiv.org/abs/1912.11211},
	abstract = {The role that YouTube and its behind-the-scenes recommendation algorithm plays in encouraging online radicalization has been suggested by both journalists and academics alike. This study directly quantifies these claims by examining the role that YouTube's algorithm plays in suggesting radicalized content. After categorizing nearly 800 political channels, we were able to differentiate between political schemas in order to analyze the algorithm traffic flows out and between each group. After conducting a detailed analysis of recommendations received by each channel type, we refute the popular radicalization claims. To the contrary, these data suggest that YouTube's recommendation algorithm actively discourages viewers from visiting radicalizing or extremist content. Instead, the algorithm is shown to favor mainstream media and cable news content over independent YouTube channels with slant towards left-leaning or politically neutral channels. Our study thus suggests that YouTube's recommendation algorithm fails to promote inflammatory or radicalized content, as previously claimed by several outlets.},
	urldate = {2020-11-03},
	journal = {arXiv:1912.11211 [cs]},
	author = {Ledwich, Mark and Zaitsev, Anna},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.11211},
	keywords = {Social Networks, Recommender Systems, Extremism},
	file = {Ledwich and Zaitsev - 2019 - Algorithmic Extremism Examining YouTube's Rabbit .pdf:/Users/clente/Zotero/storage/THGZJ52G/Ledwich and Zaitsev - 2019 - Algorithmic Extremism Examining YouTube's Rabbit .pdf:application/pdf},
}

@article{papadamou_disturbed_2019,
	title = {Disturbed {YouTube} for {Kids}: {Characterizing} and {Detecting} {Inappropriate} {Videos} {Targeting} {Young} {Children}},
	shorttitle = {Disturbed {YouTube} for {Kids}},
	url = {http://arxiv.org/abs/1901.07046},
	abstract = {A large number of the most-subscribed YouTube channels target children of very young age. Hundreds of toddler-oriented channels on YouTube feature inoffensive, well produced, and educational videos. Unfortunately, inappropriate content that targets this demographic is also common. YouTube's algorithmic recommendation system regrettably suggests inappropriate content because some of it mimics or is derived from otherwise appropriate content. Considering the risk for early childhood development, and an increasing trend in toddler's consumption of YouTube media, this is a worrisome problem. In this work, we build a classifier able to discern inappropriate content that targets toddlers on YouTube with 84.3\% accuracy, and leverage it to perform a first-of-its-kind, large-scale, quantitative characterization that reveals some of the risks of YouTube media consumption by young children. Our analysis reveals that YouTube is still plagued by such disturbing videos and its currently deployed counter-measures are ineffective in terms of detecting them in a timely manner. Alarmingly, using our classifier we show that young children are not only able, but likely to encounter disturbing videos when they randomly browse the platform starting from benign videos.},
	urldate = {2020-11-06},
	journal = {arXiv:1901.07046 [cs]},
	author = {Papadamou, Kostantinos and Papasavva, Antonis and Zannettou, Savvas and Blackburn, Jeremy and Kourtellis, Nicolas and Leontiadis, Ilias and Stringhini, Gianluca and Sirivianos, Michael},
	month = may,
	year = {2019},
	note = {arXiv: 1901.07046},
	keywords = {Social Networks, Politics},
}

@article{johnson_hidden_2019,
	title = {Hidden resilience and adaptive dynamics of the global online hate ecology},
	volume = {573},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1494-7},
	doi = {10.1038/s41586-019-1494-7},
	abstract = {Online hate and extremist narratives have been linked to abhorrent real-world events, including a current surge in hate crimes1–6 and an alarming increase in youth suicides that result from social media vitriol7; inciting mass shootings such as the 2019 attack in Christchurch, stabbings and bombings8–11; recruitment of extremists12–16, including entrapment and sex-trafficking of girls as fighter brides17; threats against public figures, including the 2019 verbal attack against an anti-Brexit politician, and hybrid (racist–anti-women–anti-immigrant) hate threats against a US member of the British royal family18; and renewed anti-western hate in the 2019 post-ISIS landscape associated with support for Osama Bin Laden’s son and Al Qaeda. Social media platforms seem to be losing the battle against online hate19,20 and urgently need new insights. Here we show that the key to understanding the resilience of online hate lies in its global network-of-network dynamics. Interconnected hate clusters form global ‘hate highways’ that—assisted by collective online adaptations—cross social media platforms, sometimes using ‘back doors’ even after being banned, as well as jumping between countries, continents and languages. Our mathematical model predicts that policing within a single platform (such as Facebook) can make matters worse, and will eventually generate global ‘dark pools’ in which online hate will flourish. We observe the current hate network rapidly rewiring and self-repairing at the micro level when attacked, in a way that mimics the formation of covalent bonds in chemistry. This understanding enables us to propose a policy matrix that can help to defeat online hate, classified by the preferred (or legally allowed) granularity of the intervention and top-down versus bottom-up nature. We provide quantitative ' assessments for the effects of each intervention. This policy matrix also offers a tool for tackling a broader class of illicit online behaviours21,22 such as financial fraud.},
	language = {en},
	number = {7773},
	urldate = {2020-11-03},
	journal = {Nature},
	author = {Johnson, N. F. and Leahy, R. and Restrepo, N. Johnson and Velasquez, N. and Zheng, M. and Manrique, P. and Devkota, P. and Wuchty, S.},
	month = sep,
	year = {2019},
	note = {Number: 7773
Publisher: Nature Publishing Group},
	keywords = {Social Networks, Opinion Polarization, Dynamic Systems, Extremism},
	pages = {261--265},
	file = {Johnson et al. - 2019 - Hidden resilience and adaptive dynamics of the glo.pdf:/Users/clente/Zotero/storage/ZKWAA6TS/Johnson et al. - 2019 - Hidden resilience and adaptive dynamics of the glo.pdf:application/pdf},
}

@article{wood_elusive_2019,
	title = {The {Elusive} {Backfire} {Effect}: {Mass} {Attitudes}' {Steadfast} {Factual} {Adherence}},
	volume = {41},
	issn = {1573-6687},
	shorttitle = {The {Elusive} {Backfire} {Effect}},
	url = {https://doi.org/10.1007/s11109-018-9443-y},
	doi = {10.1007/s11109-018-9443-y},
	abstract = {Can citizens heed factual information, even when such information challenges their partisan and ideological attachments? The “backfire effect,” described by Nyhan and Reifler (Polit Behav 32(2):303–330. https://doi.org/10.1007/s11109-010-9112-2, 2010), says no: rather than simply ignoring factual information, presenting respondents with facts can compound their ignorance. In their study, conservatives presented with factual information about the absence of Weapons of Mass Destruction in Iraq became more convinced that such weapons had been found. The present paper presents results from five experiments in which we enrolled more than 10,100 subjects and tested 52 issues of potential backfire. Across all experiments, we found no corrections capable of triggering backfire, despite testing precisely the kinds of polarized issues where backfire should be expected. Evidence of factual backfire is far more tenuous than prior research suggests. By and large, citizens heed factual information, even when such information challenges their ideological commitments.},
	language = {en},
	number = {1},
	urldate = {2020-11-03},
	journal = {Political Behavior},
	author = {Wood, Thomas and Porter, Ethan},
	month = mar,
	year = {2019},
	keywords = {Opinion Polarization, Backfire Effect},
	pages = {135--163},
}

@article{nyhan_when_2010,
	title = {When {Corrections} {Fail}: {The} {Persistence} of {Political} {Misperceptions}},
	volume = {32},
	issn = {1573-6687},
	shorttitle = {When {Corrections} {Fail}},
	url = {https://doi.org/10.1007/s11109-010-9112-2},
	doi = {10.1007/s11109-010-9112-2},
	abstract = {An extensive literature addresses citizen ignorance, but very little research focuses on misperceptions. Can these false or unsubstantiated beliefs about politics be corrected? Previous studies have not tested the efficacy of corrections in a realistic format. We conducted four experiments in which subjects read mock news articles that included either a misleading claim from a politician, or a misleading claim and a correction. Results indicate that corrections frequently fail to reduce misperceptions among the targeted ideological group. We also document several instances of a “backfire effect” in which corrections actually increase misperceptions among the group in question.},
	language = {en},
	number = {2},
	urldate = {2020-11-03},
	journal = {Political Behavior},
	author = {Nyhan, Brendan and Reifler, Jason},
	month = jun,
	year = {2010},
	keywords = {Opinion Polarization, Backfire Effect},
	pages = {303--330},
}

@misc{turner_paths_2018,
	type = {Research {Article}},
	title = {Paths to {Polarization}: {How} {Extreme} {Views}, {Miscommunication}, and {Random} {Chance} {Drive} {Opinion} {Dynamics}},
	shorttitle = {Paths to {Polarization}},
	url = {https://www.hindawi.com/journals/complexity/2018/2740959/},
	abstract = {Understanding the social conditions that tend to increase or decrease polarization is important for many reasons. We study a network-structured agent-based model of opinion dynamics, extending a model previously introduced by Flache and Macy (2011), who found that polarization appeared to increase with the introduction of long-range ties but decrease with the number of salient opinions, which they called the population’s “cultural complexity.” We find the following. First, polarization is strongly path dependent and sensitive to stochastic variation. Second, polarization depends strongly on the initial distribution of opinions in the population. In the absence of extremists, polarization may be mitigated. Third, noisy communication can drive a population toward more extreme opinions and even cause acute polarization. Finally, the apparent reduction in polarization under increased “cultural complexity” arises via a particular property of the polarization measurement, under which a population containing a wider diversity of extreme views is deemed less polarized. This work has implications for understanding the population dynamics of beliefs, opinions, and polarization as well as broader implications for the analysis of agent-based models of social phenomena.},
	language = {en},
	urldate = {2020-11-01},
	journal = {Complexity},
	author = {Turner, Matthew A. and Smaldino, Paul E.},
	month = nov,
	year = {2018},
	doi = {https://doi.org/10.1155/2018/2740959},
	doi = {https://doi.org/10.1155/2018/2740959},
	note = {ISSN: 1076-2787
Pages: e2740959
Publisher: Hindawi
Volume: 2018},
	keywords = {Opinion Dynamics, Polarization, Extremism},
}

@article{orkphol_word_2019,
	title = {Word {Sense} {Disambiguation} {Using} {Cosine} {Similarity} {Collaborates} with {Word2vec} and {WordNet}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1999-5903/11/5/114},
	doi = {10.3390/fi11050114},
	abstract = {Words have different meanings (i.e., senses) depending on the context. Disambiguating the correct sense is important and a challenging task for natural language processing. An intuitive way is to select the highest similarity between the context and sense definitions provided by a large lexical database of English, WordNet. In this database, nouns, verbs, adjectives, and adverbs are grouped into sets of cognitive synonyms interlinked through conceptual semantics and lexicon relations. Traditional unsupervised approaches compute similarity by counting overlapping words between the context and sense definitions which must match exactly. Similarity should compute based on how words are related rather than overlapping by representing the context and sense definitions on a vector space model and analyzing distributional semantic relationships among them using latent semantic analysis (LSA). When a corpus of text becomes more massive, LSA consumes much more memory and is not flexible to train a huge corpus of text. A word-embedding approach has an advantage in this issue. Word2vec is a popular word-embedding approach that represents words on a fix-sized vector space model through either the skip-gram or continuous bag-of-words (CBOW) model. Word2vec is also effectively capturing semantic and syntactic word similarities from a huge corpus of text better than LSA. Our method used Word2vec to construct a context sentence vector, and sense definition vectors then give each word sense a score using cosine similarity to compute the similarity between those sentence vectors. The sense definition also expanded with sense relations retrieved from WordNet. If the score is not higher than a specific threshold, the score will be combined with the probability of that sense distribution learned from a large sense-tagged corpus, SEMCOR. The possible answer senses can be obtained from high scores. Our method shows that the result (50.9\% or 48.7\% without the probability of sense distribution) is higher than the baselines (i.e., original, simplified, adapted and LSA Lesk) and outperforms many unsupervised systems participating in the SENSEVAL-3 English lexical sample task.},
	language = {en},
	number = {5},
	urldate = {2020-10-29},
	journal = {Future Internet},
	author = {Orkphol, Korawit and Yang, Wu},
	month = may,
	year = {2019},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Similarity, NLP, Word Embedding, Word2vec},
	pages = {114},
}

@techreport{maes_will_2015,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Will the {Personalization} of {Online} {Social} {Networks} {Foster} {Opinion} {Polarization}?},
	url = {https://papers.ssrn.com/abstract=2553436},
	abstract = {Pundits and scholars warned that the personalization of the web and in particular of online social networks fosters interaction between likeminded users and amplifies the polarization of political opinions. We criticize, however, that this warning is based on one particular polarization model and that an alternative and equally prominent theory implies the exact opposite effect, predicting that personalization fosters consensus rather than polarization. We develop a general modeling framework to compare the predictions of the competing models. Using agent-based modeling, we formally demonstrate that the two theories make contradicting predictions and study the conditions of polarization. In conclusion, we call for empirical research on the competing assumptions of the two models, discussing major roadblocks and novel methods to overcome them.},
	language = {en},
	number = {ID 2553436},
	urldate = {2020-10-29},
	institution = {Social Science Research Network},
	author = {Maes, Michael and Bischofberger, Lukas},
	month = jan,
	year = {2015},
	doi = {10.2139/ssrn.2553436},
	keywords = {Social Networks, Opinion Dynamics, Recommender Systems, Polarization, Personalization},
}

@article{kaplan_users_2010,
	title = {Users of the world, unite! {The} challenges and opportunities of {Social} {Media}},
	volume = {53},
	issn = {0007-6813},
	url = {http://www.sciencedirect.com/science/article/pii/S0007681309001232},
	doi = {10.1016/j.bushor.2009.09.003},
	abstract = {The concept of Social Media is top of the agenda for many business executives today. Decision makers, as well as consultants, try to identify ways in which firms can make profitable use of applications such as Wikipedia, YouTube, Facebook, Second Life, and Twitter. Yet despite this interest, there seems to be very limited understanding of what the term “Social Media” exactly means; this article intends to provide some clarification. We begin by describing the concept of Social Media, and discuss how it differs from related concepts such as Web 2.0 and User Generated Content. Based on this definition, we then provide a classification of Social Media which groups applications currently subsumed under the generalized term into more specific categories by characteristic: collaborative projects, blogs, content communities, social networking sites, virtual game worlds, and virtual social worlds. Finally, we present 10 pieces of advice for companies which decide to utilize Social Media.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Business Horizons},
	author = {Kaplan, Andreas M. and Haenlein, Michael},
	month = jan,
	year = {2010},
	keywords = {Social Networks, Politics},
	pages = {59--68},
}

@inproceedings{rader_understanding_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {Understanding {User} {Beliefs} {About} {Algorithmic} {Curation} in the {Facebook} {News} {Feed}},
	isbn = {978-1-4503-3145-6},
	url = {https://doi.org/10.1145/2702123.2702174},
	doi = {10.1145/2702123.2702174},
	abstract = {People are becoming increasingly reliant on online socio-technical systems that employ algorithmic curation to organize, select and present information. We wanted to understand how individuals make sense of the influence of algorithms, and how awareness of algorithmic curation may impact their interaction with these systems. We investigated user understanding of algorithmic curation in Facebook's News Feed, by analyzing open-ended responses to a survey question about whether respondents believe their News Feeds show them every post their Facebook Friends create. Responses included a wide range of beliefs and causal inferences, with different potential consequences for user behavior in the system. Because user behavior is both input for algorithms and constrained by them, these patterns of belief may have tangible consequences for the system as a whole.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Rader, Emilee and Gray, Rebecca},
	month = apr,
	year = {2015},
	keywords = {Social Networks, Recommender Systems, Politics, Facebook},
	pages = {173--182},
}

@inproceedings{nagulendra_understanding_2014,
	address = {New York, NY, USA},
	series = {{HT} '14},
	title = {Understanding and controlling the filter bubble through interactive visualization: a user study},
	isbn = {978-1-4503-2954-5},
	shorttitle = {Understanding and controlling the filter bubble through interactive visualization},
	url = {https://doi.org/10.1145/2631775.2631811},
	doi = {10.1145/2631775.2631811},
	abstract = {The "filter bubble" is a term which refers to people getting encapsulated in streams of data such as news or social network updates that are personalized to their interests. While people need protection from information overload and maybe prefer to see content they feel familiar or agree with, there is the danger that important issues that should be of concern for everyone will get filtered away and people will lack exposure to different views, living in "echo-chambers", blissfully unaware of the reality. We have proposed a design of an interactive visualization, which provides the user of a social networking site with awareness of the personalization mechanism (the semantics and the source of the content that is filtered away), and with means to control the filtering mechanism. The visualization has been implemented in a peer-to-peer social network, called MADMICA, and we present here the results of a large scale lab study with 163 crowd-sourced participants. The results demonstrate that the visualization leads to increased users' awareness of the filter bubble, understandability of the filtering mechanism and to a feeling of control over their data stream.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 25th {ACM} conference on {Hypertext} and social media},
	publisher = {Association for Computing Machinery},
	author = {Nagulendra, Sayooran and Vassileva, Julita},
	month = sep,
	year = {2014},
	keywords = {Social Networks, Recommender Systems, Filter Bubble},
	pages = {107--115},
}

@article{palla_uncovering_2005,
	title = {Uncovering the overlapping community structure of complex networks in nature and society},
	volume = {435},
	copyright = {2005 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature03607},
	doi = {10.1038/nature03607},
	abstract = {A network is a network — be it between words (those associated with ‘bright’ in this case) or protein structures.},
	language = {en},
	number = {7043},
	urldate = {2020-10-29},
	journal = {Nature},
	author = {Palla, Gergely and Derényi, Imre and Farkas, Illés and Vicsek, Tamás},
	month = jun,
	year = {2005},
	note = {Number: 7043
Publisher: Nature Publishing Group},
	keywords = {Community Detection, Networks},
	pages = {814--818},
}

@article{dhumal_topical_2015,
	title = {Topical {Context} {Aware} {Community} {Detection} in {Social} {Media} {Discussion}},
	volume = {6},
	abstract = {Community detection algorithms are used to uncover hidden properties of network. Existing methods of discovering community in online social network largely relies upon existing network topology for identifying community of users. With the immense of large number of users and multi type relationship between them, networks become larger and complex. Identifying user interest and based upon that identifying community of like minded users from such online social networks (e.g. Twitter, Facebook) becomes important for targeted advertising and friend recommendation. We propose a context aware community detection approach to identify users with similar topical interest. Initially topic modeling method is used to extract topic from textual content (e.g. messages) shared by user. Further users interested in similar topic are identified, relationship links between them is used to model network and finally community detection method is used to identify cluster of strongly connected users from the modeled network.},
	language = {en},
	number = {3},
	author = {Dhumal, Amit and Kamde, Pravin},
	year = {2015},
	keywords = {Social Networks, Community Detection},
	pages = {5},
}

@article{zeigler_theory_2000,
	title = {Theory of {Modeling} and {Simulation}},
	language = {en},
	author = {Zeigler, Bernard P and Praehofer, Herbert and Kim, Tag Gon and Mavor, Anne S and Pew, Richard W},
	month = jan,
	year = {2000},
	keywords = {Dynamic Systems},
	pages = {37},
}

@techreport{giller_statistical_2012,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {The {Statistical} {Properties} of {Random} {Bitstreams} and the {Sampling} {Distribution} of {Cosine} {Similarity}},
	url = {https://papers.ssrn.com/abstract=2167044},
	abstract = {We summarize the statistical properties of statistics computed from independent random bitstreams including the commonly discussed support and cosine similarity. We derive the moments of the asymptotically normal approximation to the sampling distribution of the cosine similarity of independent random bitstreams and compare those computed moments to those measured by Monte-Carlo simulation. We find agreement for bitstreams of internet scale in length (i.e. of order 10,000 bits) and much smaller (100 and 10 bits) and demonstrate that the expected value of the cosine similarity of independent bitstreams might very significantly distant from zero. To compensate for this bias we propose a new statistic Support Adjusted Cosine Similarity or SACS.},
	language = {en},
	number = {ID 2167044},
	urldate = {2020-10-29},
	institution = {Social Science Research Network},
	author = {Giller, Graham L.},
	month = oct,
	year = {2012},
	doi = {10.2139/ssrn.2167044},
	keywords = {Bias, Similarity, Collaborative Filtering},
	file = {Giller - 2012 - The Statistical Properties of Random Bitstreams an.pdf:/Users/clente/Zotero/storage/T4XLVJIX/Giller - 2012 - The Statistical Properties of Random Bitstreams an.pdf:application/pdf},
}

@article{peel_ground_2017,
	title = {The ground truth about metadata and community detection in networks},
	volume = {3},
	copyright = {Copyright © 2017, The Authors. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	url = {https://advances.sciencemag.org/content/3/5/e1602548},
	doi = {10.1126/sciadv.1602548},
	abstract = {Across many scientific domains, there is a common need to automatically extract a simplified view or coarse-graining of how a complex system’s components interact. This general task is called community detection in networks and is analogous to searching for clusters in independent vector data. It is common to evaluate the performance of community detection algorithms by their ability to find so-called ground truth communities. This works well in synthetic networks with planted communities because these networks’ links are formed explicitly based on those known communities. However, there are no planted communities in real-world networks. Instead, it is standard practice to treat some observed discrete-valued node attributes, or metadata, as ground truth. We show that metadata are not the same as ground truth and that treating them as such induces severe theoretical and practical problems. We prove that no algorithm can uniquely solve community detection, and we prove a general No Free Lunch theorem for community detection, which implies that there can be no algorithm that is optimal for all possible community detection tasks. However, community detection remains a powerful tool and node metadata still have value, so a careful exploration of their relationship with network structure can yield insights of genuine worth. We illustrate this point by introducing two statistical techniques that can quantify the relationship between metadata and community structure for a broad class of models. We demonstrate these techniques using both synthetic and real-world networks, and for multiple types of metadata and community structures.
Troubles with community detection in networks: No ground truth, no free lunch, and the complex coupling of metadata with structure.
Troubles with community detection in networks: No ground truth, no free lunch, and the complex coupling of metadata with structure.},
	language = {en},
	number = {5},
	urldate = {2020-10-29},
	journal = {Science Advances},
	author = {Peel, Leto and Larremore, Daniel B. and Clauset, Aaron},
	month = may,
	year = {2017},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	keywords = {Community Detection, Networks},
	pages = {e1602548},
}

@inproceedings{su_effect_2016,
	address = {Republic and Canton of Geneva, CHE},
	series = {{WWW} '16},
	title = {The {Effect} of {Recommendations} on {Network} {Structure}},
	isbn = {978-1-4503-4143-1},
	url = {https://doi.org/10.1145/2872427.2883040},
	doi = {10.1145/2872427.2883040},
	abstract = {Online social networks regularly offer users personalized, algorithmic suggestions of whom to connect to. Here we examine the aggregate effects of such recommendations on network structure, focusing on whether these recommendations increase the popularity of niche users or, conversely, those who are already popular. We investigate this issue by empirically and theoretically analyzing abrupt changes in Twitter's network structure around the mid-2010 introduction of its "Who to Follow" feature. We find that users across the popularity spectrum benefitted from the recommendations; however, the most popular users profited substantially more than average. We trace this "rich get richer" phenomenon to three intertwined factors. First, as is typical of network recommenders, the system relies on a "friend-of-friend"-style algorithm, which we show generally results in users being recommended proportional to their degree. Second, we find that the baseline growth rate of users is sublinear in degree. This mismatch between the recommender and the natural network dynamics thus alters the structural evolution of the network. Finally, we find that people are much more likely to respond positively to recommendations for popular users---perhaps because of their greater name recognition---further amplifying the cumulative advantage of well-known individuals.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 25th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Su, Jessica and Sharma, Aneesh and Goel, Sharad},
	month = apr,
	year = {2016},
	keywords = {Social Networks, Bias, Recommender Systems, Twitter},
	pages = {1157--1167},
	file = {Su et al. - 2016 - The Effect of Recommendations on Network Structure.pdf:/Users/clente/Zotero/storage/G7GIXDPZ/Su et al. - 2016 - The Effect of Recommendations on Network Structure.pdf:application/pdf},
}

@incollection{plantie_survey_2013,
	address = {London},
	series = {Computer {Communications} and {Networks}},
	title = {Survey on {Social} {Community} {Detection}},
	isbn = {978-1-4471-4555-4},
	url = {https://doi.org/10.1007/978-1-4471-4555-4_4},
	abstract = {Community detection is a growing field of interest in the area of social network applications. Many community detection methods and surveys have been introduced in recent years, with each such method being classified according to its algorithm type. This chapter presents an original survey on this topic, featuring a new approach based on both semantics and type of output. Semantics opens up new perspectives and allows interpreting high-order social relations. A special focus is also given to community evaluation since this step becomes important in social data mining.},
	language = {en},
	urldate = {2020-10-29},
	booktitle = {Social {Media} {Retrieval}},
	publisher = {Springer},
	author = {Plantié, Michel and Crampes, Michel},
	editor = {Ramzan, Naeem and van Zwol, Roelof and Lee, Jong-Seok and Clüver, Kai and Hua, Xian-Sheng},
	year = {2013},
	doi = {10.1007/978-1-4471-4555-4_4},
	keywords = {Social Networks, Survey, Community Detection, Graph Theory},
	pages = {65--85},
}

@article{newman_structure_2016,
	title = {Structure and inference in annotated networks},
	volume = {7},
	copyright = {2016 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/ncomms11863},
	doi = {10.1038/ncomms11863},
	abstract = {For many networks of scientific interest we know both the connections of the network and information about the network nodes, such as the age or gender of individuals in a social network. Here we demonstrate how this ‘metadata’ can be used to improve our understanding of network structure. We focus in particular on the problem of community detection in networks and develop a mathematically principled approach that combines a network and its metadata to detect communities more accurately than can be done with either alone. Crucially, the method does not assume that the metadata are correlated with the communities we are trying to find. Instead, the method learns whether a correlation exists and correctly uses or ignores the metadata depending on whether they contain useful information. We demonstrate our method on synthetic networks with known structure and on real-world networks, large and small, drawn from social, biological and technological domains.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Nature Communications},
	author = {Newman, M. E. J. and Clauset, Aaron},
	month = jun,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Community Detection},
	pages = {11863},
}

@inproceedings{diehl_socialocean_2018,
	title = {{SocialOcean}: {Visual} {Analysis} and {Characterization} of {Social} {Media} {Bubbles}},
	shorttitle = {{SocialOcean}},
	doi = {10.1109/BDVA.2018.8534023},
	abstract = {Social media allows citizens, corporations, and authorities to create, post, and exchange information. The study of its dynamics will enable analysts to understand user activities and social group characteristics such as connectedness, geospatial distribution, and temporal behavior. In this context, social media bubbles can be defined as social groups that exhibit certain biases in social media. These biases strongly depend on the dimensions selected in the analysis, for example, topic affinity, credibility, sentiment, and geographic distribution. In this paper, we present SocialOcean, a visual analytics system that allows for the investigation of social media bubbles. There exists a large body of research in social sciences which identifies important dimensions of social media bubbles (SMBs). While such dimensions have been studied separately, and also some of them in combination, it is still an open question which dimensions play the most important role in defining SMBs. Since the concept of SMBs is fairly recent, there are many unknowns regarding their characterization. We investigate the thematic and spatiotemporal characteristics of SMBs and present a visual analytics system to address questions such as: What are the most important dimensions that characterize SMBs? and How SMBs embody in the presence of specific events that resonate with them? We illustrate our approach using three different real scenarios related to the single event of Boston Marathon Bombing, and political news about Global Warming. We perform an expert evaluation, analyze the experts' feedback, and present the lessons learned.},
	booktitle = {2018 {International} {Symposium} on {Big} {Data} {Visual} and {Immersive} {Analytics} ({BDVA})},
	author = {Diehl, A. and Hundt, M. and Haussler, J. and Seebacher, D. and Chen, S. and Cilasun, N. and Keim, D. and Shreck, T.},
	month = oct,
	year = {2018},
	keywords = {Social Networks, Filter Bubble, Politics, Facebook, Twitter},
	pages = {1--11},
}

@article{lee_social_2014,
	title = {Social {Media}, {Network} {Heterogeneity}, and {Opinion} {Polarization}},
	volume = {64},
	issn = {0021-9916},
	url = {https://academic.oup.com/joc/article/64/4/702/4086042},
	doi = {10.1111/jcom.12077},
	abstract = {Abstract.  Employing a national probability survey in 2012, this study tests relationships between social media, social network service (SNS) network heterogene},
	language = {en},
	number = {4},
	urldate = {2020-10-29},
	journal = {Journal of Communication},
	author = {Lee, Jae Kook and Choi, Jihyang and Kim, Cheonsoo and Kim, Yonghwan},
	month = aug,
	year = {2014},
	note = {Publisher: Oxford Academic},
	keywords = {Social Networks, Polarization},
	pages = {702--722},
	file = {Lee et al. - 2014 - Social Media, Network Heterogeneity, and Opinion P.pdf:/Users/clente/Zotero/storage/ETBIRWRP/Lee et al. - 2014 - Social Media, Network Heterogeneity, and Opinion P.pdf:application/pdf},
}

@article{stieglitz_social_2013,
	title = {Social media and political communication: a social media analytics framework},
	volume = {3},
	issn = {1869-5469},
	shorttitle = {Social media and political communication},
	url = {https://doi.org/10.1007/s13278-012-0079-3},
	doi = {10.1007/s13278-012-0079-3},
	abstract = {In recent years, social media are said to have an impact on the public discourse and communication in the society. In particular, social media are increasingly used in political context. More recently, microblogging services (e.g., Twitter) and social network sites (e.g., Facebook) are believed to have the potential for increasing political participation. While Twitter is an ideal platform for users to spread not only information in general but also political opinions publicly through their networks, political institutions (e.g., politicians, political parties, political foundations, etc.) have also begun to use Facebook pages or groups for the purpose of entering into direct dialogs with citizens and encouraging more political discussions. Previous studies have shown that from the perspective of political institutions, there is an emerging need to continuously collect, monitor, analyze, summarize, and visualize politically relevant information from social media. These activities, which are subsumed under “social media analytics,” are considered difficult tasks due to a large numbers of different social media platforms as well as the large amount and complexity of information and data. Systematic tracking and analysis approaches along with appropriate scientific methods and techniques in political domain are still lacking. In this paper, we propose a methodological framework for social media analytics in political context. More specifically, our framework summarizes most important politically relevant issues from the perspective of political institutions and corresponding methodologies from different scientific disciplines.},
	language = {en},
	number = {4},
	urldate = {2020-10-29},
	journal = {Social Network Analysis and Mining},
	author = {Stieglitz, Stefan and Dang-Xuan, Linh},
	month = dec,
	year = {2013},
	keywords = {Social Networks, Politics},
	pages = {1277--1291},
}

@techreport{zuiderveen_borgesius_should_2016,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Should {We} {Worry} {About} {Filter} {Bubbles}?},
	url = {https://papers.ssrn.com/abstract=2758126},
	abstract = {Some fear that personalised communication can lead to information cocoons or filter bubbles. For instance, a personalised news website could give more prominence to conservative or liberal media items, based on the (assumed) political interests of the user. As a result, users may encounter only a limited range of political ideas. We synthesise empirical research on the extent and effects of self-selected personalisation, where people actively choose which content they receive, and pre-selected personalisation, where algorithms personalise content for users without any deliberate user choice. We conclude that at present there is little empirical evidence that warrants any worries about filter bubbles.},
	language = {en},
	number = {ID 2758126},
	urldate = {2020-10-29},
	institution = {Social Science Research Network},
	author = {Zuiderveen Borgesius, Frederik and Trilling, Damian and Moeller, Judith and Bodó, Balázs and de Vreese, Claes H. and Helberger, Natali},
	month = apr,
	year = {2016},
	keywords = {Filter Bubble, Manipulation},
}

@article{kurahashi-nakamura_robust_2016,
	title = {Robust {Clustering} in {Generalized} {Bounded} {Confidence} {Models}},
	volume = {19},
	issn = {1460-7425},
	number = {4},
	journal = {Journal of Artificial Societies and Social Simulation},
	author = {Kurahashi-Nakamura, Takasumi and Mäs, Michael and Lorenz, Jan},
	year = {2016},
	keywords = {Opinion Dynamics, Bounded Confidence, Community Detection},
	pages = {7},
}

@article{bobadilla_recommender_2013,
	title = {Recommender systems survey},
	volume = {46},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705113001044},
	doi = {10.1016/j.knosys.2013.03.012},
	abstract = {Recommender systems have developed in parallel with the web. They were initially based on demographic, content-based and collaborative filtering. Currently, these systems are incorporating social information. In the future, they will use implicit, local and personal information from the Internet of things. This article provides an overview of recommender systems as well as collaborative filtering methods and algorithms; it also explains their evolution, provides an original classification for these systems, identifies areas of future implementation and develops certain areas selected for past, present or future importance.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Knowledge-Based Systems},
	author = {Bobadilla, J. and Ortega, F. and Hernando, A. and Gutiérrez, A.},
	month = jul,
	year = {2013},
	keywords = {Recommender Systems, Similarity, Survey, Collaborative Filtering},
	pages = {109--132},
	file = {Bobadilla et al. - 2013 - Recommender systems survey.pdf:/Users/clente/Zotero/storage/2XPYBW9R/Bobadilla et al. - 2013 - Recommender systems survey.pdf:application/pdf},
}

@article{palla_quantifying_2007,
	title = {Quantifying social group evolution},
	volume = {446},
	copyright = {2007 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature05670},
	doi = {10.1038/nature05670},
	abstract = {The dynamics of social groups as they interact electronically is central to how modern society operates. A study of patterns of information exchange between two groups of individuals — collaborating scientists and cell phone users — has been used to devise an algorithm that relates information exchange to group stability. The data show that small groups have a few strong relationships at their core. And as long as these persist, the clique remains. But for large communities, continuous change is the key to stability. These findings offer a new view on the fundamental differences between the dynamics of small groups and large institutions.},
	language = {en},
	number = {7136},
	urldate = {2020-10-29},
	journal = {Nature},
	author = {Palla, Gergely and Barabási, Albert-László and Vicsek, Tamás},
	month = apr,
	year = {2007},
	note = {Number: 7136
Publisher: Nature Publishing Group},
	keywords = {Politics, Community Detection},
	pages = {664--667},
}

@article{wong_quantifying_2016,
	title = {Quantifying {Political} {Leaning} from {Tweets}, {Retweets}, and {Retweeters}},
	volume = {28},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2016.2553667},
	abstract = {The widespread use of online social networks (OSNs) to disseminate information and exchange opinions, by the general public, news media, and political actors alike, has enabled new avenues of research in computational political science. In this paper, we study the problem of quantifying and inferring the political leaning of Twitter users. We formulate political leaning inference as a convex optimization problem that incorporates two ideas: (a) users are consistent in their actions of tweeting and retweeting about political issues, and (b) similar users tend to be retweeted by similar audience. We then apply our inference technique to 119 million election-related tweets collected in seven months during the 2012 U.S. presidential election campaign. On a set of frequently retweeted sources, our technique achieves 94 percent accuracy and high rank correlation as compared with manually created labels. By studying the political leaning of 1,000 frequently retweeted sources, 232,000 ordinary users who retweeted them, and the hashtags used by these sources, our quantitative study sheds light on the political demographics of the Twitter population, and the temporal dynamics of political polarization as events unfold.},
	number = {8},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wong, F. M. F. and Tan, C. W. and Sen, S. and Chiang, M.},
	month = aug,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Social Networks, Opinion Dynamics, Politics, Polarization, Twitter, Machine Learning},
	pages = {2158--2172},
}

@article{cota_quantifying_2019,
	title = {Quantifying echo chamber effects in information spreading over political communication networks},
	volume = {8},
	issn = {2193-1127},
	url = {https://doi.org/10.1140/epjds/s13688-019-0213-9},
	doi = {10.1140/epjds/s13688-019-0213-9},
	abstract = {Echo chambers in online social networks, in which users prefer to interact only with ideologically-aligned peers, are believed to facilitate misinformation spreading and contribute to radicalize political discourse. In this paper, we gauge the effects of echo chambers in information spreading phenomena over political communication networks. Mining 12 million Twitter messages, we reconstruct a network in which users interchange opinions related to the impeachment of the former Brazilian President Dilma Rousseff. We define a continuous political leaning parameter, independent of the network’s structure, that allows to quantify the presence of echo chambers in the strongly connected component of the network. These are reflected in two well-separated communities of similar sizes with opposite views of the impeachment process. By means of simple spreading models, we show that the capability of users in propagating the content they produce, measured by the associated spreading capacity, strongly depends on their attitude. Users expressing pro-impeachment leanings are capable to transmit information, on average, to a larger audience than users expressing anti-impeachment leanings. Furthermore, the users’ spreading capacity is correlated to the diversity, in terms of political position, of the audience reached. Our method can be exploited to identify the presence of echo chambers and their effects across different contexts and shed light upon the mechanisms allowing to break echo chambers.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {EPJ Data Science},
	author = {Cota, Wesley and Ferreira, Silvio C. and Pastor-Satorras, Romualdo and Starnini, Michele},
	month = dec,
	year = {2019},
	keywords = {Social Networks, Filter Bubble},
	pages = {35},
}

@article{garimella_quantifying_2018,
	title = {Quantifying {Controversy} on {Social} {Media}},
	volume = {1},
	issn = {2469-7818},
	url = {https://doi.org/10.1145/3140565},
	doi = {10.1145/3140565},
	abstract = {Which topics spark the most heated debates on social media? Identifying those topics is not only interesting from a societal point of view but also allows the filtering and aggregation of social media content for disseminating news stories. In this article, we perform a systematic methodological study of controversy detection by using the content and the network structure of social media. Unlike previous work, rather than studying controversy in a single hand-picked topic and using domain-specific knowledge, we take a general approach to study topics in any domain. Our approach to quantifying controversy is based on a graph-based three-stage pipeline, which involves (i) building a conversation graph about a topic, (ii) partitioning the conversation graph to identify potential sides of the controversy, and (iii) measuring the amount of controversy from characteristics of the graph. We perform an extensive comparison of controversy measures, different graph-building approaches, and data sources. We use both controversial and non-controversial topics on Twitter, as well as other external datasets. We find that our new random-walk-based measure outperforms existing ones in capturing the intuitive notion of controversy and show that content features are vastly less helpful in this task.},
	number = {1},
	urldate = {2020-10-29},
	journal = {ACM Transactions on Social Computing},
	author = {Garimella, Kiran and Morales, Gianmarco De Francisci and Gionis, Aristides and Mathioudakis, Michael},
	month = jan,
	year = {2018},
	keywords = {Social Networks, Filter Bubble, Polarization, Twitter},
	pages = {3:1--3:27},
}

@inproceedings{yang_quantifying_2017,
	title = {Quantifying {Content} {Polarization} on {Twitter}},
	doi = {10.1109/CIC.2017.00047},
	abstract = {Social media like Facebook and Twitter have become major battlegrounds, with increasingly polarized content disseminated to people having different interests and ideologies. This work examines the extent of content polarization during the 2016 U.S. presidential election, from a unique, "content" perspective. We propose a new approach to quantify the polarization of content semantics by leveraging the word embedding representation and clustering metrics. We then propose an evaluation framework to verify the proposed quantitative measurement using a stance classification task. Based on the results, we further explore the extent of content polarization during the election period and how it changed across time, geography, and different types of users. This work contributes to understanding the online "echo chamber" phenomenon based on user-generated content.},
	booktitle = {2017 {IEEE} 3rd {International} {Conference} on {Collaboration} and {Internet} {Computing} ({CIC})},
	author = {Yang, M. and Wen, X. and Lin, Y. and Deng, L.},
	month = oct,
	year = {2017},
	keywords = {Social Networks, Filter Bubble, Politics, Polarization, Community Detection, Clustering},
	pages = {299--308},
}

@article{zhao_probabilistic_2017,
	title = {Probabilistic {Community} {Using} {Link} and {Content} for {Social} {Networks}},
	volume = {5},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2017.2774798},
	abstract = {Community detection is one of the most important problems in social network analysis in the context of the structure of underlying graphs. Many researchers have proposed methods, which only consider the network structure of social networks, for discovering dense regions in social networks. However, increasing media information in networks, such as images, videos, user tags, and comments, are observed with the development and application of Web 2.0. Abundant content information is available to provide a different view for community detection process. In this paper, we propose an overlapping community detection method, namely, latent Dirichlet allocation-based link partition (LBLP), which uses a graphical model and considers network structure and content information. Two feature integration strategies are proposed to combine the influence of network structure and content information on the network generation process. Experimental results on synthetic and real-world networks show that the LBLP method is effective, and content information is beneficial in mining community structure.},
	journal = {IEEE Access},
	author = {Zhao, S. and Yu, L. and Cheng, B.},
	year = {2017},
	note = {Conference Name: IEEE Access},
	keywords = {Social Networks, Model, Community Detection, Graph Theory, Clustering},
	pages = {27189--27202},
}

@article{conover_political_2011,
	title = {Political {Polarization} on {Twitter}},
	abstract = {In this study we investigate how social media shape the networked public sphere and facilitate communication between communities with different political orientations. We examine two networks of political communication on Twitter, comprised of more than 250,000 tweets from the six weeks leading up to the 2010 U.S. congressional midterm elections. Using a combination of network clustering algorithms and manually-annotated data we demonstrate that the network of political retweets exhibits a highly segregated partisan structure, with extremely limited connectivity between left- and right-leaning users. Surprisingly this is not the case for the user-to-user mention network, which is dominated by a single politically heterogeneous cluster of users in which ideologically-opposed individuals interact at a much higher rate compared to the network of retweets. To explain the distinct topologies of the retweet and mention networks we conjecture that politically motivated individuals provoke interaction by injecting partisan content into information streams whose primary audience consists of ideologically-opposed users. We conclude with statistical evidence in support of this hypothesis.},
	language = {en},
	author = {Conover, M D and Ratkiewicz, J and Francisco, M and Goncalves, B and Flammini, A and Menczer, F},
	year = {2011},
	keywords = {Social Networks, Polarization},
	pages = {8},
}

@article{bessi_personality_2016,
	title = {Personality traits and echo chambers on facebook},
	volume = {65},
	issn = {0747-5632},
	url = {http://www.sciencedirect.com/science/article/pii/S0747563216305817},
	doi = {10.1016/j.chb.2016.08.016},
	abstract = {In online social networks, users tend to select information that adhere to their system of beliefs and to form polarized groups of like minded people. Polarization as well as its effects on online social interactions have been extensively investigated. Still, the relation between group formation and personality traits remains unclear. A better understanding of the cognitive and psychological determinants of online social dynamics might help to design more efficient communication strategies and to challenge the digital misinformation threat. In this work, we focus on users commenting posts published by US Facebook pages supporting scientific and conspiracy-like narratives, and we classify the personality traits of those users according to their online behavior. We show that different and conflicting communities are populated by users showing similar psychological profiles, and that the dominant personality model is the same in both scientific and conspiracy echo chambers. Moreover, we observe that the permanence within echo chambers slightly shapes users' psychological profiles. Our results suggest that the presence of specific personality traits in individuals lead to their considerable involvement in supporting narratives inside virtual echo chambers.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Computers in Human Behavior},
	author = {Bessi, Alessandro},
	month = dec,
	year = {2016},
	keywords = {Social Networks, Filter Bubble},
	pages = {319--324},
}

@article{lupu_party_2015,
	title = {Party {Polarization} and {Mass} {Partisanship}: {A} {Comparative} {Perspective}},
	volume = {37},
	copyright = {2014 Springer Science+Business Media New York},
	issn = {1573-6687},
	shorttitle = {Party {Polarization} and {Mass} {Partisanship}},
	url = {https://link.springer.com/article/10.1007/s11109-014-9279-z},
	doi = {10.1007/s11109-014-9279-z},
	abstract = {Scholars view polarization with trepidation. But polarization may clarify voters’ choices and generate stronger party attachments. The link between party polarization and mass partisanship remains unclear. I look to theories of partisanship to derive implications about the relationships among polarization, citizens’ perceptions of polarization, and mass partisanship. I test those implications using cross-national and longitudinal survey data. My results confirm that polarization correlates with individual partisanship across space and time. Citizens in polarized systems also perceive their parties to be more polarized. And perceiving party polarization makes people more likely to be partisan. That relationship appears to be causal: using a long-term panel survey from the United States, I find that citizens become more partisan as they perceive polarization increasing.},
	language = {en},
	number = {2},
	urldate = {2020-10-29},
	journal = {Political Behavior},
	author = {Lupu, Noam},
	month = jun,
	year = {2015},
	note = {Company: Springer
Distributor: Springer
Institution: Springer
Label: Springer
Number: 2
Publisher: Springer US},
	keywords = {Politics, Polarization},
	pages = {331--356},
}

@inproceedings{nguyen_overlapping_2011,
	title = {Overlapping {Community} {Structures} and {Their} {Detection} on {Social} {Networks}},
	doi = {10.1109/PASSAT/SocialCom.2011.16},
	abstract = {We propose DOCA (Detecting Overlapping Community Algorithm), a connection-based algorithm for discovering high quality overlapping community structures in social networks. Our proposed method is fast, very limited parameter dependent and only requires local knowledge about the network topology. Furthermore, the community structures discovered by DOCA are deterministic, i.e., no fuzzy community assignments are produced. DOCA's performance is certified by extensive experiments on real-world traces including Enron communication network, ArXiv citation and Astro physics collaboration networks as well as Face book and Foursquare social networks. The demonstrative benchmark with other detection methods highlights the efficiency of DOCA when discovering community structures of large-scale networks. By using DOCA to analyze the community structures of real datasets, we find that overlapping communities occur naturally and quite frequently, especially for top largest communities. In addition, overlapped nodes tend to be active users who participate in multiple communities at the same time. This happens not only on social networks but also on collaboration, citation and communication networks.},
	booktitle = {2011 {IEEE} {Third} {International} {Conference} on {Privacy}, {Security}, {Risk} and {Trust} and 2011 {IEEE} {Third} {International} {Conference} on {Social} {Computing}},
	author = {Nguyen, N. P. and Dinh, T. N. and Nguyen, D. T. and Thai, M. T.},
	month = oct,
	year = {2011},
	keywords = {Social Networks, Community Detection, Facebook, Complexity Theory},
	pages = {35--40},
}

@article{acemoglu_opinion_2012,
	title = {Opinion {Fluctuations} and {Disagreement} in {Social} {Networks}},
	volume = {38},
	issn = {0364-765X},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/moor.1120.0570},
	doi = {10.1287/moor.1120.0570},
	abstract = {We study a tractable opinion dynamics model that generates long-run disagreements and persistent opinion fluctuations. Our model involves an inhomogeneous stochastic gossip process of continuous opinion dynamics in a society consisting of two types of agents: (1) regular agents who update their beliefs according to information that they receive from their social neighbors and (2) stubborn agents who never update their opinions and might represent leaders, political parties, or media sources attempting to influence the beliefs in the rest of the society. When the society contains stubborn agents with different opinions, the belief dynamics never lead to a consensus (among the regular agents). Instead, beliefs in the society fail to converge almost surely, the belief profile keeps on fluctuating in an ergodic fashion, and it converges in law to a nondegenerate random vector.The structure of the graph describing the social network and the location of the stubborn agents within it shape the opinion dynamics. The expected belief vector is proved to evolve according to an ordinary differential equation coinciding with the Kolmogorov backward equation of a continuous-time Markov chain on the graph with absorbing states corresponding to the stubborn agents, and hence to converge to a harmonic vector, with every regular agent's value being the weighted average of its neighbors' values, and boundary conditions corresponding to the stubborn agents' beliefs. Expected cross products of the agents' beliefs allow for a similar characterization in terms of coupled Markov chains on the graph describing the social network.We prove that, in large-scale societies, which are highly fluid, meaning that the product of the mixing time of the Markov chain on the graph describing the social network and the relative size of the linkages to stubborn agents vanishes as the population size grows large, a condition of homogeneous influence emerges, whereby the stationary beliefs' marginal distributions of most of the regular agents have approximately equal first and second moments.},
	number = {1},
	urldate = {2020-10-29},
	journal = {Mathematics of Operations Research},
	author = {Acemoğlu, Daron and Como, Giacomo and Fagnani, Fabio and Ozdaglar, Asuman},
	month = nov,
	year = {2012},
	note = {Publisher: INFORMS},
	keywords = {Social Networks, Polarization},
	pages = {1--27},
}

@article{acemoglu_opinion_2011,
	title = {Opinion {Dynamics} and {Learning} in {Social} {Networks}},
	volume = {1},
	issn = {2153-0785, 2153-0793},
	url = {http://link.springer.com/10.1007/s13235-010-0004-1},
	doi = {10.1007/s13235-010-0004-1},
	abstract = {We provide an overview of recent research on belief and opinion dynamics in social networks. We discuss both Bayesian and non-Bayesian models of social learning and focus on the implications of the form of learning (e.g., Bayesian vs. non-Bayesian), the sources of information (e.g., observation vs. communication), and the structure of social networks in which individuals are situated on three key questions: (1) whether social learning will lead to consensus, i.e., to agreement among individuals starting with different views; (2) whether social learning will effectively aggregate dispersed information and thus weed out incorrect beliefs; (3) whether media sources, prominent agents, politicians and the state will be able to manipulate beliefs and spread misinformation in a society.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Dynamic Games and Applications},
	author = {Acemoglu, Daron and Ozdaglar, Asuman},
	month = mar,
	year = {2011},
	keywords = {Social Networks, Opinion Dynamics},
	pages = {3--49},
	file = {Acemoglu and Ozdaglar - 2011 - Opinion Dynamics and Learning in Social Networks.pdf:/Users/clente/Zotero/storage/HMUM6N5M/Acemoglu and Ozdaglar - 2011 - Opinion Dynamics and Learning in Social Networks.pdf:application/pdf},
}

@misc{hegselmann_opinion_2002,
	type = {Text.{Article}},
	title = {Opinion dynamics and bounded confidence models, analysis and simulation},
	copyright = {JASSS@soc.surrey.ac.uk},
	url = {http://jasss.soc.surrey.ac.uk/5/3/2.html},
	abstract = {When does opinion formation within an interacting group lead to consensus, polarization or fragmentation? The article investigates various models for the dynamics of continuous opinions by analytical methods as well as by computer simulations. Section 2 develops within a unified framework the classical model of consensus formation, the variant of this model due to Friedkin and Johnsen, a time-dependent version and a nonlinear version with bounded confidence of the agents. Section 3 presents for all these models major analytical results. Section 4 gives an extensive exploration of the nonlinear model with bounded confidence by a series of computer simulations. An appendix supplies needed mathematical definitions, tools, and theorems.},
	language = {en},
	urldate = {2020-10-29},
	author = {Hegselmann, Rainer; Krause},
	month = jun,
	year = {2002},
	note = {Publisher: JASSS},
	keywords = {Opinion Dynamics, Bounded Confidence},
}

@article{murase_multilayer_2014,
	title = {Multilayer weighted social network model},
	volume = {90},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.90.052810},
	doi = {10.1103/PhysRevE.90.052810},
	abstract = {Recent empirical studies using large-scale data sets have validated the Granovetter hypothesis on the structure of the society in that there are strongly wired communities connected by weak ties. However, as interaction between individuals takes place in diverse contexts, these communities turn out to be overlapping. This implies that the society has a multilayered structure, where the layers represent the different contexts. To model this structure we begin with a single-layer weighted social network (WSN) model showing the Granovetterian structure. We find that when merging such WSN models, a sufficient amount of interlayer correlation is needed to maintain the relationship between topology and link weights, while these correlations destroy the enhancement in the community overlap due to multiple layers. To resolve this, we devise a geographic multilayer WSN model, where the indirect interlayer correlations due to the geographic constraints of individuals enhance the overlaps between the communities and, at the same time, the Granovetterian structure is preserved.},
	number = {5},
	urldate = {2020-10-29},
	journal = {Physical Review E},
	author = {Murase, Yohsuke and Török, János and Jo, Hang-Hyun and Kaski, Kimmo and Kertész, János},
	month = nov,
	year = {2014},
	note = {Publisher: American Physical Society},
	keywords = {Social Networks, Model},
	pages = {052810},
}

@article{del_vicario_modeling_2017,
	title = {Modeling confirmation bias and polarization},
	volume = {7},
	copyright = {2017 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep40391},
	doi = {10.1038/srep40391},
	abstract = {Online users tend to select claims that adhere to their system of beliefs and to ignore dissenting information. Confirmation bias, indeed, plays a pivotal role in viral phenomena. Furthermore, the wide availability of content on the web fosters the aggregation of likeminded people where debates tend to enforce group polarization. Such a configuration might alter the public debate and thus the formation of the public opinion. In this paper we provide a mathematical model to study online social debates and the related polarization dynamics. We assume the basic updating rule of the Bounded Confidence Model (BCM) and we develop two variations a) the Rewire with Bounded Confidence Model (RBCM), in which discordant links are broken until convergence is reached; and b) the Unbounded Confidence Model, under which the interaction among discordant pairs of users is allowed even with a negative feedback, either with the rewiring step (RUCM) or without it (UCM). From numerical simulations we find that the new models (UCM and RUCM), unlike the BCM, are able to explain the coexistence of two stable final opinions, often observed in reality. Lastly, we present a mean field approximation of the newly introduced models.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Scientific Reports},
	author = {Del Vicario, Michela and Scala, Antonio and Caldarelli, Guido and Stanley, H. Eugene and Quattrociocchi, Walter},
	month = jan,
	year = {2017},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Bias, Model, Polarization},
	pages = {40391},
}

@article{deffuant_mixing_2000,
	title = {Mixing beliefs among interacting agents},
	volume = {03},
	issn = {0219-5259},
	url = {https://www.worldscientific.com/doi/abs/10.1142/s0219525900000078},
	doi = {10.1142/S0219525900000078},
	abstract = {We present a model of opinion dynamics in which agents adjust continuous opinions as a result of random binary encounters whenever their difference in opinion is below a given threshold. High thresholds yield convergence of opinions towards an average opinion, whereas low thresholds result in several opinion clusters: members of the same cluster share the same opinion but are no longer influenced by members of other clusters.},
	number = {01n04},
	urldate = {2020-10-29},
	journal = {Advances in Complex Systems},
	author = {Deffuant, Guillaume and Neau, David and Amblard, Frederic and Weisbuch, Gérard},
	month = jan,
	year = {2000},
	note = {Publisher: World Scientific Publishing Co.},
	keywords = {Opinion Dynamics},
	pages = {87--98},
}

@article{sun_mining_2012,
	title = {Mining {Heterogeneous} {Information} {Networks}: {Principles} and {Methodologies}},
	volume = {3},
	issn = {2151-0067},
	shorttitle = {Mining {Heterogeneous} {Information} {Networks}},
	url = {https://www.morganclaypool.com/doi/abs/10.2200/s00433ed1v01y201207dmk005},
	doi = {10.2200/S00433ED1V01Y201207DMK005},
	number = {2},
	urldate = {2020-10-29},
	journal = {Synthesis Lectures on Data Mining and Knowledge Discovery},
	author = {Sun, Yizhou and Han, Jiawei},
	month = jul,
	year = {2012},
	note = {Publisher: Morgan \& Claypool Publishers},
	keywords = {Networks},
	pages = {1--159},
}

@inproceedings{musco_minimizing_2018,
	address = {Republic and Canton of Geneva, CHE},
	series = {{WWW} '18},
	title = {Minimizing {Polarization} and {Disagreement} in {Social} {Networks}},
	isbn = {978-1-4503-5639-8},
	url = {https://doi.org/10.1145/3178876.3186103},
	doi = {10.1145/3178876.3186103},
	abstract = {The rise of social media and online social networks has been a disruptive force in society. Opinions are increasingly shaped by interactions on online social media, and social phenomena including disagreement and polarization are now tightly woven into everyday life. In this work we initiate the study of the following question: {\textbackslash}beginquotation {\textbackslash}noindent Given n agents, each with its own initial opinion that reflects its core value on a topic, and an opinion dynamics model, what is the structure of a social network that minimizes {\textbackslash}em disagreementand {\textbackslash}em controversy simultaneously? {\textbackslash}endquotation {\textbackslash}noindent This question is central to recommender systems: should a recommender system prefer a link suggestion between two online users with similar mindsets in order to keep disagreement low, or between two users with different opinions in order to expose each to the others viewpoint of the world, and decrease overall levels of polarization and controversy? Such decisions have an important global effect on society {\textbackslash}citewilliams2007social. Our contributions include a mathematical formalization of this question as an optimization problem and an exact, time-efficient algorithm. We also prove that there always exists a graph with \$O(n/ε{\textasciicircum}2)\$ edges that is a \$(1+ε)\$ approximation to the optimum. Our formulation is an instance of optimization over {\textbackslash}em graph topologies, see also {\textbackslash}citeboyd2004fastest,daitch2009fitting,sun2006fastest. Furthermore, for a given graph, we show how to optimize the same objective over the agents» innate opinions in polynomial time. Finally, we perform an empirical study of our proposed methods on synthetic and real-world data that verify their value as mining tools to better understand the trade-off between of disagreement and polarization. We find that there is a lot of space to reduce both controversy and disagreement in real-world networks; for instance, on a Reddit network where users exchange comments on politics, our methods achieve a reduction in controversy and disagreement of the order \$6.2 {\textbackslash}times 10{\textasciicircum}4\$.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Musco, Cameron and Musco, Christopher and Tsourakakis, Charalampos E.},
	month = apr,
	year = {2018},
	keywords = {Social Networks, Bias, Opinion Dynamics, Polarization},
	pages = {369--378},
	file = {Musco et al. - 2018 - Minimizing Polarization and Disagreement in Social.pdf:/Users/clente/Zotero/storage/BL3AV83U/Musco et al. - 2018 - Minimizing Polarization and Disagreement in Social.pdf:application/pdf},
}

@article{morales_measuring_2015,
	title = {Measuring political polarization: {Twitter} shows the two sides of {Venezuela}},
	volume = {25},
	issn = {1054-1500},
	shorttitle = {Measuring political polarization},
	url = {https://aip.scitation.org/doi/abs/10.1063/1.4913758},
	doi = {10.1063/1.4913758},
	number = {3},
	urldate = {2020-10-29},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Morales, A. J. and Borondo, J. and Losada, J. C. and Benito, R. M.},
	month = mar,
	year = {2015},
	note = {Publisher: American Institute of Physics},
	keywords = {Social Networks, Polarization},
	pages = {033114},
}

@article{nikolov_measuring_2015,
	title = {Measuring online social bubbles},
	volume = {1},
	issn = {2376-5992},
	url = {https://peerj.com/articles/cs-38},
	doi = {10.7717/peerj-cs.38},
	abstract = {Social media have become a prevalent channel to access information, spread ideas, and influence opinions. However, it has been suggested that social and algorithmic filtering may cause exposure to less diverse points of view. Here we quantitatively measure this kind of social bias at the collective level by mining a massive datasets of web clicks. Our analysis shows that collectively, people access information from a significantly narrower spectrum of sources through social media and email, compared to a search baseline. The significance of this finding for individual exposure is revealed by investigating the relationship between the diversity of information sources experienced by users at both the collective and individual levels in two datasets where individual users can be analyzed—Twitter posts and search logs. There is a strong correlation between collective and individual diversity, supporting the notion that when we use social media we find ourselves inside “social bubbles.” Our results could lead to a deeper understanding of how technology biases our exposure to new information.},
	language = {en},
	urldate = {2020-10-29},
	journal = {PeerJ Computer Science},
	author = {Nikolov, Dimitar and Oliveira, Diego F. M. and Flammini, Alessandro and Menczer, Filippo},
	month = dec,
	year = {2015},
	note = {Publisher: PeerJ Inc.},
	keywords = {Social Networks, Filter Bubble, Polarization},
	pages = {e38},
	file = {Nikolov et al. - 2015 - Measuring online social bubbles.pdf:/Users/clente/Zotero/storage/VKQ22SV6/Nikolov et al. - 2015 - Measuring online social bubbles.pdf:application/pdf},
}

@article{matakos_measuring_2017,
	title = {Measuring and moderating opinion polarization in social networks},
	volume = {31},
	issn = {1573-756X},
	url = {https://doi.org/10.1007/s10618-017-0527-9},
	doi = {10.1007/s10618-017-0527-9},
	abstract = {The polarization of society over controversial social issues has been the subject of study in social sciences for decades (Isenberg in J Personal Soc Psychol 50(6):1141–1151, 1986, Sunstein in J Polit Philos 10(2):175–195, 2002). The widespread usage of online social networks and social media, and the tendency of people to connect and interact with like-minded individuals has only intensified the phenomenon of polarization (Bakshy et al. in Science 348(6239):1130–1132, 2015). In this paper, we consider the problem of measuring and reducing polarization of opinions in a social network. Using a standard opinion formation model (Friedkin and Johnsen in J Math Soc 15(3–4):193–206, 1990), we define the polarization index, which, given a network and the opinions of the individuals in the network, it quantifies the polarization observed in the network. Our measure captures the tendency of opinions to concentrate in network communities, creating echo-chambers. Given this numeric measure of polarization, we then consider the problem of reducing polarization in the network by convincing individuals (e.g., through education, exposure to diverse viewpoints, or incentives) to adopt a more neutral stand towards controversial issues. We formally define the ModerateInternal and ModerateExpressed problems, and we prove that both our problems are NP-hard. By exploiting the linear-algebraic characteristics of the opinion formation model we design polynomial-time algorithms for both problems. Our experiments with real-world datasets demonstrate the validity of our metric, and the efficiency and the effectiveness of our algorithms in practice.},
	language = {en},
	number = {5},
	urldate = {2020-10-29},
	journal = {Data Mining and Knowledge Discovery},
	author = {Matakos, Antonis and Terzi, Evimaria and Tsaparas, Panayiotis},
	month = sep,
	year = {2017},
	keywords = {Social Networks, Polarization},
	pages = {1480--1505},
}

@article{de_learning_2016,
	title = {Learning and {Forecasting} {Opinion} {Dynamics} in {Social} {Networks}},
	url = {http://arxiv.org/abs/1506.05474},
	abstract = {Social media and social networking sites have become a global pinboard for exposition and discussion of news, topics, and ideas, where social media users often update their opinions about a particular topic by learning from the opinions shared by their friends. In this context, can we learn a data-driven model of opinion dynamics that is able to accurately forecast opinions from users? In this paper, we introduce SLANT, a probabilistic modeling framework of opinion dynamics, which represents users opinions over time by means of marked jump diffusion stochastic differential equations, and allows for efficient model simulation and parameter estimation from historical fine grained event data. We then leverage our framework to derive a set of efficient predictive formulas for opinion forecasting and identify conditions under which opinions converge to a steady state. Experiments on data gathered from Twitter show that our model provides a good fit to the data and our formulas achieve more accurate forecasting than alternatives.},
	urldate = {2020-10-30},
	journal = {arXiv:1506.05474 [physics]},
	author = {De, Abir and Valera, Isabel and Ganguly, Niloy and Bhattacharya, Sourangshu and Rodriguez, Manuel Gomez},
	month = may,
	year = {2016},
	note = {arXiv: 1506.05474},
	keywords = {Social Networks, Opinion Dynamics},
	file = {De et al. - 2016 - Learning and Forecasting Opinion Dynamics in Socia.pdf:/Users/clente/Zotero/storage/IBWEI8I3/De et al. - 2016 - Learning and Forecasting Opinion Dynamics in Socia.pdf:application/pdf},
}

@techreport{boxell_is_2017,
	title = {Is the {Internet} {Causing} {Political} {Polarization}? {Evidence} from {Demographics}},
	shorttitle = {Is the {Internet} {Causing} {Political} {Polarization}?},
	url = {https://www.nber.org/papers/w23258},
	abstract = {Founded in 1920, the NBER is a private, non-profit, non-partisan organization dedicated to conducting economic research and to disseminating research findings among academics, public policy makers, and business professionals.},
	language = {en},
	number = {w23258},
	urldate = {2020-10-29},
	institution = {National Bureau of Economic Research},
	author = {Boxell, Levi and Gentzkow, Matthew and Shapiro, Jesse M.},
	month = mar,
	year = {2017},
	doi = {10.3386/w23258},
	keywords = {Social Networks, Politics, Polarization},
}

@article{ceni_interpreting_2020,
	title = {Interpreting {Recurrent} {Neural} {Networks} {Behaviour} via {Excitable} {Network} {Attractors}},
	volume = {12},
	issn = {1866-9964},
	url = {https://doi.org/10.1007/s12559-019-09634-2},
	doi = {10.1007/s12559-019-09634-2},
	abstract = {Machine learning provides fundamental tools both for scientific research and for the development of technologies with significant impact on society. It provides methods that facilitate the discovery of regularities in data and that give predictions without explicit knowledge of the rules governing a system. However, a price is paid for exploiting such flexibility: machine learning methods are typically black boxes where it is difficult to fully understand what the machine is doing or how it is operating. This poses constraints on the applicability and explainability of such methods. Our research aims to open the black box of recurrent neural networks, an important family of neural networks used for processing sequential data. We propose a novel methodology that provides a mechanistic interpretation of behaviour when solving a computational task. Our methodology uses mathematical constructs called excitable network attractors, which are invariant sets in phase space composed of stable attractors and excitable connections between them. As the behaviour of recurrent neural networks depends both on training and on inputs to the system, we introduce an algorithm to extract network attractors directly from the trajectory of a neural network while solving tasks. Simulations conducted on a controlled benchmark task confirm the relevance of these attractors for interpreting the behaviour of recurrent neural networks, at least for tasks that involve learning a finite number of stable states and transitions between them.},
	language = {en},
	number = {2},
	urldate = {2020-10-29},
	journal = {Cognitive Computation},
	author = {Ceni, Andrea and Ashwin, Peter and Livi, Lorenzo},
	month = mar,
	year = {2020},
	keywords = {Dynamic Systems, Deep Learning},
	pages = {330--356},
}

@article{he_interactive_2016,
	title = {Interactive recommender systems: {A} survey of the state of the art and future research challenges and opportunities},
	volume = {56},
	issn = {0957-4174},
	shorttitle = {Interactive recommender systems},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417416300367},
	doi = {10.1016/j.eswa.2016.02.013},
	abstract = {Recommender systems have been researched extensively over the past decades. Whereas several algorithms have been developed and deployed in various application domains, recent research efforts are increasingly oriented towards the user experience of recommender systems. This research goes beyond accuracy of recommendation algorithms and focuses on various human factors that affect acceptance of recommendations, such as user satisfaction, trust, transparency and sense of control. In this paper, we present an interactive visualization framework that combines recommendation with visualization techniques to support human-recommender interaction. Then, we analyze existing interactive recommender systems along the dimensions of our framework, including our work. Based on our survey results, we present future research challenges and opportunities.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Expert Systems with Applications},
	author = {He, Chen and Parra, Denis and Verbert, Katrien},
	month = sep,
	year = {2016},
	keywords = {Recommender Systems, Survey},
	pages = {9--27},
	file = {He et al. - 2016 - Interactive recommender systems A survey of the s.pdf:/Users/clente/Zotero/storage/4M394G28/He et al. - 2016 - Interactive recommender systems A survey of the s.pdf:application/pdf},
}

@article{shekatkar_importance_2018,
	title = {Importance of initial conditions in the polarization of complex networks},
	volume = {122},
	issn = {0295-5075},
	url = {https://doi.org/10.1209%2F0295-5075%2F122%2F38002},
	doi = {10.1209/0295-5075/122/38002},
	abstract = {Currently used models of opinion formation use random initial conditions. In reality, most people in a social network, except for a small fraction of the population, are initially either unaware of, or indifferent to, the disputed issue. To explore the consequences of such specific initial conditions, we study the polarization of social networks when conflicting ideas arise on two different seed nodes and then spread according to a majority rule. Using the configuration model and the stochastic block model as examples, we show that this framework leads to substantially different outcomes than those which employ random initial conditions. Moreover, the empirically observed splits in the karate and the dolphins' networks naturally come out of this paradigm. Our work thus suggests that the existing opinion dynamics models should be reevaluated to incorporate the initial condition dependence.},
	language = {en},
	number = {3},
	urldate = {2020-10-29},
	journal = {EPL (Europhysics Letters)},
	author = {Shekatkar, Snehal M. and Barve, Sukratu},
	month = jun,
	year = {2018},
	note = {Publisher: IOP Publishing},
	keywords = {Social Networks, Polarization},
	pages = {38002},
}

@article{garcia_ideological_2015,
	title = {Ideological and {Temporal} {Components} of {Network} {Polarization} in {Online} {Political} {Participatory} {Media}},
	volume = {7},
	copyright = {© 2015 Policy Studies Organization},
	issn = {1944-2866},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/poi3.82},
	doi = {10.1002/poi3.82},
	abstract = {Political polarization is traditionally analyzed through the ideological stances of groups and parties, but it also has a behavioral component that manifests in the interactions between individuals. We present an empirical analysis of the digital traces of politicians in politnetz.ch, a Swiss online platform focused on political activity, in which politicians interact by creating support links, comments, and likes. We analyze network polarization as the level of intra-party cohesion with respect to inter-party connectivity, finding that supports show a very strongly polarized structure with respect to party alignment. The analysis of this multiplex network shows that each layer of interaction contains relevant information, where comment groups follow topics related to Swiss politics. Our analysis reveals that polarization in the layer of likes evolves in time, increasing close to the federal elections of 2011. Furthermore, we analyze the internal social network of each party through metrics related to hierarchical structures, information efficiency, and social resilience. Our results suggest that the online social structure of a party is related to its ideology, and reveal that the degree of connectivity across two parties increases when they are close in the ideological space of a multi-party system.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Policy \& Internet},
	author = {Garcia, David and Abisheva, Adiya and Schweighofer, Simon and Serdült, Uwe and Schweitzer, Frank},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/poi3.82},
	keywords = {Social Networks, Polarization},
	pages = {46--79},
}

@article{mieghem_human_2011,
	title = {Human {Psychology} of {Common} {Appraisal}: {The} {Reddit} {Score}},
	volume = {13},
	issn = {1941-0077},
	shorttitle = {Human {Psychology} of {Common} {Appraisal}},
	doi = {10.1109/TMM.2011.2165054},
	abstract = {The Reddit score reflects a common appraisal by a community of Reddit subscribers of a submitted item, called a story. The general random walk with random maximum boundary is demonstrated to describe the distribution function of the Reddit score of an arbitrary story in the online social news aggregator Reddit.com. Exponential tails, predicted by the analysis, are observed, while a curious intermediate “power law-like” region seems to correspond to a remarkable empirical observation that the total number of downvotes depends in “power law” fashion on the total number of upvotes. Stronger even, those downvotes increase faster than the upvotes, which is a surprising fact that asks for a (socio-psychological?) explanation.},
	number = {6},
	journal = {IEEE Transactions on Multimedia},
	author = {Mieghem, P. Van},
	month = dec,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Multimedia},
	keywords = {Social Networks, Politics, Reddit},
	pages = {1404--1406},
}

@inproceedings{wang_how_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {How {Polarized} {Have} {We} {Become}? {A} {Multimodal} {Classification} of {Trump} {Followers} and {Clinton} {Followers}},
	isbn = {978-3-319-67217-5},
	shorttitle = {How {Polarized} {Have} {We} {Become}?},
	doi = {10.1007/978-3-319-67217-5_27},
	abstract = {Polarization in American politics has been extensively documented and analyzed for decades, and the phenomenon became all the more apparent during the 2016 presidential election, where Trump and Clinton depicted two radically different pictures of America. Inspired by this gaping polarization and the extensive utilization of Twitter during the 2016 presidential campaign, in this paper we take the first step in measuring polarization in social media and we attempt to predict individuals’ Twitter following behavior through analyzing ones’ everyday tweets, profile images and posted pictures. As such, we treat polarization as a classification problem and study to what extent Trump followers and Clinton followers on Twitter can be distinguished, which in turn serves as a metric of polarization in general. We apply LSTM to processing tweet features and we extract visual features using the VGG neural network. Integrating these two sets of features boosts the overall performance. We are able to achieve an accuracy of 69\%, suggesting that the high degree of polarization recorded in the literature has started to manifest itself in social media as well.},
	language = {en},
	booktitle = {Social {Informatics}},
	publisher = {Springer International Publishing},
	author = {Wang, Yu and Feng, Yang and Hong, Zhe and Berger, Ryan and Luo, Jiebo},
	editor = {Ciampaglia, Giovanni Luca and Mashhadi, Afra and Yasseri, Taha},
	year = {2017},
	keywords = {Social Networks, Politics, Polarization},
	pages = {440--456},
}

@inproceedings{stoica_hegemony_2019,
	address = {New York, NY, USA},
	series = {{WWW} '19},
	title = {Hegemony in {Social} {Media} and the effect of recommendations},
	isbn = {978-1-4503-6675-5},
	url = {https://doi.org/10.1145/3308560.3317589},
	doi = {10.1145/3308560.3317589},
	abstract = {As today’s media landscape is carved by social media endorsements and built on automated recommendations, both of these are often criticized for inducing vicious dynamics, such as the filter bubble effect, echo chamber, or polarization. We introduce a new model featuring a mild version of homophily and two well-known popularity dynamics. These broadly reproduce the organic activity and the algorithmic filtering, respectively, of which the latter is now commonplace within social media or other online services. Surprisingly, we show this is all that is needed to create hegemony: a single viewpoint (or side) not only receives undue attention, but it also captures all the attention given to “top trending” items.},
	urldate = {2020-10-29},
	booktitle = {Companion {Proceedings} of {The} 2019 {World} {Wide} {Web} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Stoica, Ana-Andreea and Chaintreau, Augustin},
	month = may,
	year = {2019},
	keywords = {Social Networks, Bias, Recommender Systems, Homophily},
	pages = {575--580},
	file = {Stoica and Chaintreau - 2019 - Hegemony in Social Media and the effect of recomme.pdf:/Users/clente/Zotero/storage/XSUPN2PU/Stoica and Chaintreau - 2019 - Hegemony in Social Media and the effect of recomme.pdf:application/pdf},
}

@article{clauset_finding_2005,
	title = {Finding local community structure in networks},
	volume = {72},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.72.026132},
	doi = {10.1103/PhysRevE.72.026132},
	abstract = {Although the inference of global community structure in networks has recently become a topic of great interest in the physics community, all such algorithms require that the graph be completely known. Here, we define both a measure of local community structure and an algorithm that infers the hierarchy of communities that enclose a given vertex by exploring the graph one vertex at a time. This algorithm runs in time O(k2d) for general graphs when d is the mean degree and k is the number of vertices to be explored. For graphs where exploring a new vertex is time consuming, the running time is linear, O(k). We show that on computer-generated graphs the average behavior of this technique approximates that of algorithms that require global knowledge. As an application, we use this algorithm to extract meaningful local clustering information in the large recommender network of an online retailer.},
	number = {2},
	urldate = {2020-10-29},
	journal = {Physical Review E},
	author = {Clauset, Aaron},
	month = aug,
	year = {2005},
	note = {Publisher: American Physical Society},
	keywords = {Community Detection, Networks},
	pages = {026132},
}

@article{clauset_finding_2004,
	title = {Finding community structure in very large networks},
	volume = {70},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.70.066111},
	doi = {10.1103/PhysRevE.70.066111},
	abstract = {The discovery and analysis of community structure in networks is a topic of considerable recent interest within the physics community, but most methods proposed so far are unsuitable for very large networks because of their computational cost. Here we present a hierarchical agglomeration algorithm for detecting community structure which is faster than many competing algorithms: its running time on a network with n vertices and m edges is O(mdlogn) where d is the depth of the dendrogram describing the community structure. Many real-world networks are sparse and hierarchical, with m∼n and d∼logn, in which case our algorithm runs in essentially linear time, O(nlog2n). As an example of the application of this algorithm we use it to analyze a network of items for sale on the web site of a large on-line retailer, items in the network being linked if they are frequently purchased by the same buyer. The network has more than 400 000 vertices and 2×106 edges. We show that our algorithm can extract meaningful communities from this network, revealing large-scale patterns present in the purchasing habits of customers.},
	number = {6},
	urldate = {2020-10-29},
	journal = {Physical Review E},
	author = {Clauset, Aaron and Newman, M. E. J. and Moore, Cristopher},
	month = dec,
	year = {2004},
	note = {Publisher: American Physical Society},
	keywords = {Community Detection, Networks},
	pages = {066111},
}

@article{flaxman_filter_2016,
	title = {Filter {Bubbles}, {Echo} {Chambers}, and {Online} {News} {Consumption}},
	volume = {80},
	issn = {0033-362X},
	url = {https://academic.oup.com/poq/article/80/S1/298/2223402},
	doi = {10.1093/poq/nfw006},
	abstract = {Abstract.  Online publishing, social networks, and web search have dramatically lowered the costs of producing, distributing, and discovering news articles. Som},
	language = {en},
	number = {S1},
	urldate = {2020-10-29},
	journal = {Public Opinion Quarterly},
	author = {Flaxman, Seth and Goel, Sharad and Rao, Justin M.},
	month = jan,
	year = {2016},
	note = {Publisher: Oxford Academic},
	keywords = {Filter Bubble, Politics},
	pages = {298--320},
	file = {Flaxman et al. - 2016 - Filter Bubbles, Echo Chambers, and Online News Con.pdf:/Users/clente/Zotero/storage/ZFI6SP3E/Flaxman et al. - 2016 - Filter Bubbles, Echo Chambers, and Online News Con.pdf:application/pdf},
}

@article{difranzo_filter_2017,
	title = {Filter bubbles and fake news},
	volume = {23},
	issn = {1528-4972},
	url = {https://doi.org/10.1145/3055153},
	doi = {10.1145/3055153},
	abstract = {The results of the 2016 Brexit referendum in the U.K. and presidential election in the U.S. surprised pollsters and traditional media alike, and social media is now being blamed in part for creating echo chambers that encouraged the spread of fake news that influenced voters.},
	number = {3},
	urldate = {2020-10-29},
	journal = {XRDS: Crossroads, The ACM Magazine for Students},
	author = {DiFranzo, Dominic and Gloria-Garcia, Kristine},
	month = apr,
	year = {2017},
	keywords = {Filter Bubble},
	pages = {32--35},
}

@article{jin_fast_2015,
	title = {Fast community detection by {SCORE}},
	volume = {43},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1416322036},
	doi = {10.1214/14-AOS1265},
	abstract = {Consider a network where the nodes split into KKK different communities. The community labels for the nodes are unknown and it is of major interest to estimate them (i.e., community detection). Degree Corrected Block Model (DCBM) is a popular network model. How to detect communities with the DCBM is an interesting problem, where the main challenge lies in the degree heterogeneity. We propose a new approach to community detection which we call the Spectral Clustering On Ratios-of-Eigenvectors (SCORE). Compared to classical spectral methods, the main innovation is to use the entry-wise ratios between the first leading eigenvector and each of the other leading eigenvectors for clustering. Let AAA be the adjacency matrix of the network. We first obtain the KKK leading eigenvectors of AAA, say, η{\textasciicircum}1,…,η{\textasciicircum}Kη{\textasciicircum}1,…,η{\textasciicircum}K{\textbackslash}hat\{{\textbackslash}eta\}\_\{1\},{\textbackslash}ldots,{\textbackslash}hat\{{\textbackslash}eta\}\_\{K\}, and let R{\textasciicircum}R{\textasciicircum}{\textbackslash}hat\{R\} be the n×(K−1)n×(K−1)n{\textbackslash}times(K-1) matrix such that R{\textasciicircum}(i,k)=η{\textasciicircum}k+1(i)/η{\textasciicircum}1(i)R{\textasciicircum}(i,k)=η{\textasciicircum}k+1(i)/η{\textasciicircum}1(i){\textbackslash}hat\{R\}(i,k)={\textbackslash}hat\{{\textbackslash}eta\}\_\{k+1\}(i)/{\textbackslash}hat\{{\textbackslash}eta\}\_\{1\}(i), 1≤i≤n1≤i≤n1{\textbackslash}leq i{\textbackslash}leq n, 1≤k≤K−11≤k≤K−11{\textbackslash}leq k{\textbackslash}leq K-1. We then use R{\textasciicircum}R{\textasciicircum}{\textbackslash}hat\{R\} for clustering by applying the kkk-means method. The central surprise is, the effect of degree heterogeneity is largely ancillary, and can be effectively removed by taking entry-wise ratios between η{\textasciicircum}k+1η{\textasciicircum}k+1{\textbackslash}hat\{{\textbackslash}eta\}\_\{k+1\} and η{\textasciicircum}1η{\textasciicircum}1{\textbackslash}hat\{{\textbackslash}eta\}\_\{1\}, 1≤k≤K−11≤k≤K−11{\textbackslash}leq k{\textbackslash}leq K-1. The method is successfully applied to the web blogs data and the karate club data, with error rates of 58/122258/122258/1222 and 1/341/341/34, respectively. These results are more satisfactory than those by the classical spectral methods. Additionally, compared to modularity methods, SCORE is easier to implement, computationally faster, and also has smaller error rates. We develop a theoretic framework where we show that under mild conditions, the SCORE stably yields consistent community detection. In the core of the analysis is the recent development on Random Matrix Theory (RMT), where the matrix-form Bernstein inequality is especially helpful.},
	language = {EN},
	number = {1},
	urldate = {2020-10-29},
	journal = {Annals of Statistics},
	author = {Jin, Jiashun},
	month = feb,
	year = {2015},
	mrnumber = {MR3285600},
	zmnumber = {1310.62076},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Social Networks, Community Detection, K-Means},
	pages = {57--89},
}

@article{spohr_fake_2017,
	title = {Fake news and ideological polarization: {Filter} bubbles and selective exposure on social media},
	volume = {34},
	issn = {0266-3821},
	shorttitle = {Fake news and ideological polarization},
	url = {https://doi.org/10.1177/0266382117722446},
	doi = {10.1177/0266382117722446},
	abstract = {This article addresses questions of ideological polarization and the filter bubble in social media. It develops a theoretical analysis of ideological polarization on social media by considering a range of relevant factors. Over recent years, fake news and the effect of the social media filter bubble have become of increasing importance both in academic and general discourse. The article reviews the assumption that algorithmic curation and personalization systems place users in a filter bubble of content that decreases their likelihood of encountering ideologically cross-cutting news content. At the intersection of new media, politics and behavioural science, the article establishes a theoretical framework for further research and future actions by society, policymakers and industries.},
	language = {en},
	number = {3},
	urldate = {2020-10-29},
	journal = {Business Information Review},
	author = {Spohr, Dominic},
	month = sep,
	year = {2017},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {Social Networks, Filter Bubble, Polarization},
	pages = {150--160},
	file = {Spohr - 2017 - Fake news and ideological polarization Filter bub.pdf:/Users/clente/Zotero/storage/QXQ44C99/Spohr - 2017 - Fake news and ideological polarization Filter bub.pdf:application/pdf},
}

@inproceedings{stoica_fairness_2019,
	address = {New York, NY, USA},
	series = {{WWW} '19},
	title = {Fairness in {Social} {Influence} {Maximization}},
	isbn = {978-1-4503-6675-5},
	url = {https://doi.org/10.1145/3308560.3317588},
	doi = {10.1145/3308560.3317588},
	abstract = {Algorithms for social influence maximization have been extensively studied for the purpose of strategically choosing an initial set of individuals in a social network from which information gets propagated. With many applications in advertisement, news spread, vaccination, and online trend-setting, this problem is a central one in understanding how information flows in a network of individuals. As human networks may encode historical biases, algorithms performing on them might capture and reproduce such biases when automating outcomes. In this work, we study the social influence maximization problem for the purpose of designing fair algorithms for diffusion, aiming to understand the effect of communities in the creation of disparate impact among network participants based on demographic attributes (gender, race etc). We propose a set of definitions and models for assessing the fairness-utility tradeoff in designing algorithms that maximize influence through a mathematical model of diffusion and an empirical analysis of a collected dataset from Instagram. Our work shows that being feature-aware can lead to more diverse outcomes in outreach and seed selection, as well as better efficiency, than being feature-blind.},
	urldate = {2020-10-29},
	booktitle = {Companion {Proceedings} of {The} 2019 {World} {Wide} {Web} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Stoica, Ana-Andreea and Chaintreau, Augustin},
	month = may,
	year = {2019},
	keywords = {Social Networks, Bias, Recommender Systems, Graph Theory},
	pages = {569--574},
}

@article{askitas_explaining_2017,
	title = {Explaining opinion polarisation with opinion copulas},
	volume = {12},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0183277},
	doi = {10.1371/journal.pone.0183277},
	abstract = {An empirically founded and widely established driving force in opinion dynamics is homophily i.e. the tendency of “birds of a feather” to “flock together”. The closer our opinions are the more likely it is that we will interact and converge. Models using these assumptions are called bounded confidence models (BCM) as they assume a tolerance threshold after which interaction is unlikely. They are known to produce one or more clusters, depending on the size of the bound, with more than one cluster being possible only in the deterministic case. Introducing noise, as is likely to happen in a stochastic world, causes BCM to produce consensus which leaves us with the open problem of explaining the emergence and sustainance of opinion clusters and polarisation. We investigate the role of heterogeneous priors in opinion formation, introduce the concept of opinion copulas, argue that it is well supported by findings in Social Psychology and use it to show that the stochastic BCM does indeed produce opinion clustering without the need for extra assumptions.},
	language = {en},
	number = {8},
	urldate = {2020-10-29},
	journal = {PLOS ONE},
	author = {Askitas, Nikolaos},
	month = aug,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Social Networks, Opinion Dynamics, Bounded Confidence, Polarization},
	pages = {e0183277},
	file = {Askitas - 2017 - Explaining opinion polarisation with opinion copul.pdf:/Users/clente/Zotero/storage/WKE92P2E/Askitas - 2017 - Explaining opinion polarisation with opinion copul.pdf:application/pdf},
}

@article{stewart_examining_2018,
	title = {Examining {Trolls} and {Polarization} with a {Retweet} {Network}},
	abstract = {This research examines the relationship between political homophily and organized trolling efforts. This is accomplished by analyzing how Russian troll accounts were retweeted on Twitter in the context of the \#BlackLivesMatter movement. This analysis shows that these conversations were divided along political lines, and that the examined trolling accounts systematically took advantage of these divisions. The findings of this research can help us better understand how to combat systematic trolling.},
	language = {en},
	author = {Stewart, Leo G and Arif, Ahmer and Starbird, Kate},
	year = {2018},
	keywords = {Social Networks, Politics, Polarization},
	pages = {6},
}

@article{barabasi_evolution_2002,
	title = {Evolution of the social network of scientific collaborations},
	volume = {311},
	issn = {0378-4371},
	url = {http://www.sciencedirect.com/science/article/pii/S0378437102007367},
	doi = {10.1016/S0378-4371(02)00736-7},
	abstract = {The co-authorship network of scientists represents a prototype of complex evolving networks. In addition, it offers one of the most extensive database to date on social networks. By mapping the electronic database containing all relevant journals in mathematics and neuro-science for an 8-year period (1991–98), we infer the dynamic and the structural mechanisms that govern the evolution and topology of this complex system. Three complementary approaches allow us to obtain a detailed characterization. First, empirical measurements allow us to uncover the topological measures that characterize the network at a given moment, as well as the time evolution of these quantities. The results indicate that the network is scale-free, and that the network evolution is governed by preferential attachment, affecting both internal and external links. However, in contrast with most model predictions the average degree increases in time, and the node separation decreases. Second, we propose a simple model that captures the network's time evolution. In some limits the model can be solved analytically, predicting a two-regime scaling in agreement with the measurements. Third, numerical simulations are used to uncover the behavior of quantities that could not be predicted analytically. The combined numerical and analytical results underline the important role internal links play in determining the observed scaling behavior and network topology. The results and methodologies developed in the context of the co-authorship network could be useful for a systematic study of other complex evolving networks as well, such as the world wide web, Internet, or other social networks.},
	language = {en},
	number = {3},
	urldate = {2020-10-29},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Barabási, A. L and Jeong, H and Néda, Z and Ravasz, E and Schubert, A and Vicsek, T},
	month = aug,
	year = {2002},
	keywords = {Social Networks},
	pages = {590--614},
}

@inproceedings{burke_evaluating_2010,
	address = {New York, NY, USA},
	series = {{RecSys} '10},
	title = {Evaluating the dynamic properties of recommendation algorithms},
	isbn = {978-1-60558-906-0},
	url = {https://doi.org/10.1145/1864708.1864753},
	doi = {10.1145/1864708.1864753},
	abstract = {Collaborative recommendation algorithms are typically evaluated on a static matrix of user rating data. However, when users experience a recommender system, it is dynamic, constantly evolving as new items and new users arrive. The dynamic properties of collaborative recommendation have become important as prediction algorithms based on the interactions of rating histories have been proposed, and as researchers seek to understand problems of robustness and maintenance in rating databases. This paper proposes a new evaluation method for the dynamic aspects of collaborative algorithms, the "temporal leave-one-out" approach, which can provide insight into both user-specific and system-level evolution of recommendation behavior. As a case study, the methodology is applied to the Influence Limiter algorithm [12], showing that its robustness to attack comes at a high accuracy cost.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the fourth {ACM} conference on {Recommender} systems},
	publisher = {Association for Computing Machinery},
	author = {Burke, Robin},
	month = sep,
	year = {2010},
	keywords = {Recommender Systems, Dynamic Systems},
	pages = {225--228},
	file = {Burke - 2010 - Evaluating the dynamic properties of recommendatio.pdf:/Users/clente/Zotero/storage/GQULT94S/Burke - 2010 - Evaluating the dynamic properties of recommendatio.pdf:application/pdf},
}

@article{mirtabatabaei_eulerian_2014,
	title = {Eulerian {Opinion} {Dynamics} with {Bounded} {Confidence} and {Exogenous} {Inputs}},
	volume = {13},
	url = {https://epubs.siam.org/doi/abs/10.1137/130934040},
	doi = {10.1137/130934040},
	abstract = {The formation of opinions in a large population is governed by endogenous (interactions with peers) and exogenous (influence of media) factors. In the analysis of opinion evolution in a large population, decision making rules are often approximated with non-Bayesian “rule of thumb” methods. Adopting a non-Bayesian averaging rule, this paper focuses on an Eulerian bounded-confidence model of opinion dynamics and studies the information assimilation process resulting from exogenous inputs.  In this model, a population is distributed over an opinion set, and each individual updates its opinion via (i) opinions of the population inside the individual's confidence range and (ii) the information from an exogenous input in that range.  First, we establish various mathematical properties of this system's dynamics with time-varying inputs.  Second, for the case of no exogenous input, we prove the convergence of the population's distribution to a sum of Dirac delta distributions.  We further derive a simple sufficient condition for opinion consensus under the influence of a time-varying input.  Third, regarding information assimilation, we define the attracted population of a constant input.  For a weighted Dirac delta input and for uniformly distributed initial population, we establish an upper bound on the attracted population valid under some technical assumptions. This upper bound is an increasing function of the population's confidence bound and a decreasing function of the input's measure (i.e., the integral of input's distribution over the opinion space). Fourth, for a normally distributed input with truncated support, we conjecture that the attracted population is approximately an increasing affine function of the population's confidence bound and of the input's standard deviation; we illustrate this conjecture numerically.},
	number = {1},
	urldate = {2020-10-29},
	journal = {SIAM Journal on Applied Dynamical Systems},
	author = {Mirtabatabaei, Anahita and Jia, Peng and Bullo, Francesco},
	month = jan,
	year = {2014},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {Opinion Dynamics, Bounded Confidence},
	pages = {425--446},
}

@article{tata_estimating_2007,
	title = {Estimating the selectivity of tf-idf based cosine similarity predicates},
	volume = {36},
	issn = {0163-5808},
	url = {https://doi.org/10.1145/1328854.1328855},
	doi = {10.1145/1328854.1328855},
	abstract = {An increasing number of database applications today require sophisticated approximate string matching capabilities. Examples of such application areas include data integration and data cleaning. Cosine similarity has proven to be a robust metric for scoring the similarity between two strings, and it is increasingly being used in complex queries. An immediate challenge faced by current database optimizers is to find accurate and efficient methods for estimating the selectivity of cosine similarity predicates. To the best of our knowledge, there are no known methods for this problem. In this paper, we present the first approach for estimating the selectivity of tf.idf based cosine similarity predicates. We evaluate our approach on three different real datasets and show that our method often produces estimates that are within 40\% of the actual selectivity.},
	number = {2},
	urldate = {2020-10-29},
	journal = {ACM SIGMOD Record},
	author = {Tata, Sandeep and Patel, Jignesh M.},
	month = jun,
	year = {2007},
	keywords = {Similarity},
	pages = {7--12},
}

@inproceedings{li_distance_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Distance {Weighted} {Cosine} {Similarity} {Measure} for {Text} {Classification}},
	isbn = {978-3-642-41278-3},
	doi = {10.1007/978-3-642-41278-3_74},
	abstract = {In Vector Space Model, Cosine is widely used to measure the similarity between two vectors. Its calculation is very efficient, especially for sparse vectors, as only the non-zero dimensions need to be considered. As a fundamental component, cosine similarity has been applied in solving different text mining problems, such as text classification, text summarization, information retrieval, question answering, and so on. Although it is popular, the cosine similarity does have some problems. Starting with a few synthetic samples, we demonstrate some problems of cosine similarity: it is overly biased by features of higher values and does not care much about how many features two vectors share. A distance weighted cosine similarity metric is thus proposed. Extensive experiments on text classification exhibit the effectiveness of the proposed metric.},
	language = {en},
	booktitle = {Intelligent {Data} {Engineering} and {Automated} {Learning} – {IDEAL} 2013},
	publisher = {Springer},
	author = {Li, Baoli and Han, Liping},
	editor = {Yin, Hujun and Tang, Ke and Gao, Yang and Klawonn, Frank and Lee, Minho and Weise, Thomas and Li, Bin and Yao, Xin},
	year = {2013},
	keywords = {Bias, Similarity},
	pages = {611--618},
}

@article{zamani_differences_2019,
	title = {Differences in structure and dynamics of networks retrieved from dark and public web forums},
	volume = {525},
	issn = {0378-4371},
	url = {http://www.sciencedirect.com/science/article/pii/S037843711930281X},
	doi = {10.1016/j.physa.2019.03.048},
	abstract = {Humans make decisions based on the information they obtain from several major sources, among which the comments of others in Internet forums play an increasing role. Such forums cover a wide spectrum of topics and represent an essential tool in choosing the best products, manipulating views or optimizing our decisions regarding a number of aspects of our everyday life. However, many forums have extremely controversial topics and contents including those which radicalize the readers or spread information about dangerous products and ideas (e.g., drugs, weapons or aggressive ideologies). These just mentioned activities are taking place mainly on the so called “dark web” allowing the hiding of the identity of members using dark forums. We use network theoretical approaches to analyze the data we obtained by studying the connectivity features of the members and the threads within a wide selection of forums (including dark and semi-dark) and establish several characteristic behavioral patterns. Our findings reveal both common and rather different features in the two types of behavior. In particular, we show that the various distributions of quantities, like the activity of the commenters, the dynamics of the threads (defined using their lifetime) or the degree distributions corresponding to the three major types of forums we have investigated display characteristic deviations. This knowledge can be useful, for example, in identifying an activity typical for the dark web when it appears in the public web (since the public web can be accessed and used much more easily).},
	language = {en},
	urldate = {2020-10-29},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Zamani, Maryam and Rabbani, Fereshteh and Horicsányi, Attila and Zafeiris, Anna and Vicsek, Tamas},
	month = jul,
	year = {2019},
	keywords = {Social Networks, Opinion Dynamics},
	pages = {326--336},
}

@article{harambam_democratizing_2018,
	title = {Democratizing algorithmic news recommenders: how to materialize voice in a technologically saturated media ecosystem},
	volume = {376},
	shorttitle = {Democratizing algorithmic news recommenders},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2018.0088},
	doi = {10.1098/rsta.2018.0088},
	abstract = {The deployment of various forms of AI, most notably of machine learning algorithms, radically transforms many domains of social life. In this paper we focus on the news industry, where different algorithms are used to customize news offerings to increasingly specific audience preferences. While this personalization of news enables media organizations to be more receptive to their audience, it can be questioned whether current deployments of algorithmic news recommenders (ANR) live up to their emancipatory promise. Like in various other domains, people have little knowledge of what personal data is used and how such algorithmic curation comes about, let alone that they have any concrete ways to influence these data-driven processes. Instead of going down the intricate avenue of trying to make ANR more transparent, we explore in this article ways to give people more influence over the information news recommendation algorithms provide by thinking about and enabling possibilities to express voice. After differentiating four ideal typical modalities of expressing voice (alternation, awareness, adjustment and obfuscation) which are illustrated with currently existing empirical examples, we present and argue for algorithmic recommender personae as a way for people to take more control over the algorithms that curate people's news provision.This article is part of a theme issue ‘Governing artificial intelligence: ethical, legal, and technical opportunities and challenges’.},
	number = {2133},
	urldate = {2020-10-29},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Harambam, Jaron and Helberger, Natali and van Hoboken, Joris},
	month = nov,
	year = {2018},
	note = {Publisher: Royal Society},
	keywords = {Recommender Systems},
	pages = {20180088},
}

@article{buyl_debayes_2020,
	title = {{DeBayes}: a {Bayesian} method for debiasing network embeddings},
	shorttitle = {{DeBayes}},
	url = {http://arxiv.org/abs/2002.11442},
	abstract = {As machine learning algorithms are increasingly deployed for high-impact automated decision making, ethical and increasingly also legal standards demand that they treat all individuals fairly, without discrimination based on their age, gender, race or other sensitive traits. In recent years much progress has been made on ensuring fairness and reducing bias in standard machine learning settings. Yet, for network embedding, with applications in vulnerable domains ranging from social network analysis to recommender systems, current options remain limited both in number and performance. We thus propose DeBayes: a conceptually elegant Bayesian method that is capable of learning debiased embeddings by using a biased prior. Our experiments show that these representations can then be used to perform link prediction that is significantly more fair in terms of popular metrics such as demographic parity and equalized opportunity.},
	urldate = {2020-10-29},
	journal = {arXiv:2002.11442 [cs, stat]},
	author = {Buyl, Maarten and De Bie, Tijl},
	month = mar,
	year = {2020},
	note = {arXiv: 2002.11442},
	keywords = {Bias, Recommender Systems, Machine Learning},
}

@article{lorenz_continuous_2007,
	title = {Continuous opinion dynamics under bounded confidence: a survey},
	volume = {18},
	issn = {0129-1831},
	shorttitle = {Continuous opinion dynamics under bounded confidence},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0129183107011789},
	doi = {10.1142/S0129183107011789},
	abstract = {Models of continuous opinion dynamics under bounded confidence have been presented independently by Krause and Hegselmann and by Deffuant et al. in 2000. They have raised a fair amount of attention in the communities of social simulation, sociophysics and complexity science. The researchers working on it come from disciplines such as physics, mathematics, computer science, social psychology and philosophy.In these models agents hold continuous opinions which they can gradually adjust if they hear the opinions of others. The idea of bounded confidence is that agents only interact if they are close in opinion to each other. Usually, the models are analyzed with agent-based simulations in a Monte Carlo style, but they can also be reformulated on the agent's density in the opinion space in a master equation style. The contribution of this survey is fourfold. First, it will present the agent-based and density-based modeling frameworks including the cases of multidimensional opinions and heterogeneous bounds of confidence. Second, it will give the bifurcation diagrams of cluster configuration in the homogeneous model with uniformly distributed initial opinions. Third, it will review the several extensions and the evolving phenomena which have been studied so far, and fourth it will state some open questions.},
	number = {12},
	urldate = {2020-10-29},
	journal = {International Journal of Modern Physics C},
	author = {Lorenz, Jan},
	month = dec,
	year = {2007},
	note = {Publisher: World Scientific Publishing Co.},
	keywords = {Opinion Dynamics, Bounded Confidence},
	pages = {1819--1838},
}

@article{lancichinetti_consensus_2012,
	title = {Consensus clustering in complex networks},
	volume = {2},
	copyright = {2012 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep00336},
	doi = {10.1038/srep00336},
	abstract = {The community structure of complex networks reveals both their organization and hidden relationships among their constituents. Most community detection methods currently available are not deterministic and their results typically depend on the specific random seeds, initial conditions and tie-break rules adopted for their execution. Consensus clustering is used in data analysis to generate stable results out of a set of partitions delivered by stochastic methods. Here we show that consensus clustering can be combined with any existing method in a self-consistent way, enhancing considerably both the stability and the accuracy of the resulting partitions. This framework is also particularly suitable to monitor the evolution of community structure in temporal networks. An application of consensus clustering to a large citation network of physics papers demonstrates its capability to keep track of the birth, death and diversification of topics.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Scientific Reports},
	author = {Lancichinetti, Andrea and Fortunato, Santo},
	month = mar,
	year = {2012},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Community Detection, Networks},
	pages = {336},
}

@article{papadopoulos_community_2012,
	title = {Community detection in {Social} {Media}},
	volume = {24},
	issn = {1573-756X},
	url = {https://doi.org/10.1007/s10618-011-0224-z},
	doi = {10.1007/s10618-011-0224-z},
	abstract = {The proposed survey discusses the topic of community detection in the context of Social Media. Community detection constitutes a significant tool for the analysis of complex networks by enabling the study of mesoscopic structures that are often associated with organizational and functional characteristics of the underlying networks. Community detection has proven to be valuable in a series of domains, e.g. biology, social sciences, bibliometrics. However, despite the unprecedented scale, complexity and the dynamic nature of the networks derived from Social Media data, there has only been limited discussion of community detection in this context. More specifically, there is hardly any discussion on the performance characteristics of community detection methods as well as the exploitation of their results in the context of real-world web mining and information retrieval scenarios. To this end, this survey first frames the concept of community and the problem of community detection in the context of Social Media, and provides a compact classification of existing algorithms based on their methodological principles. The survey places special emphasis on the performance of existing methods in terms of computational complexity and memory requirements. It presents both a theoretical and an experimental comparative discussion of several popular methods. In addition, it discusses the possibility for incremental application of the methods and proposes five strategies for scaling community detection to real-world networks of huge scales. Finally, the survey deals with the interpretation and exploitation of community detection results in the context of intelligent web applications and services.},
	language = {en},
	number = {3},
	urldate = {2020-10-29},
	journal = {Data Mining and Knowledge Discovery},
	author = {Papadopoulos, Symeon and Kompatsiaris, Yiannis and Vakali, Athena and Spyridonos, Ploutarchos},
	month = may,
	year = {2012},
	keywords = {Social Networks, Community Detection},
	pages = {515--554},
	file = {Papadopoulos et al. - 2012 - Community detection in Social Media.pdf:/Users/clente/Zotero/storage/WT52UI9J/Papadopoulos et al. - 2012 - Community detection in Social Media.pdf:application/pdf},
}

@article{hric_community_2014,
	title = {Community detection in networks: {Structural} communities versus ground truth},
	volume = {90},
	shorttitle = {Community detection in networks},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.90.062805},
	doi = {10.1103/PhysRevE.90.062805},
	abstract = {Algorithms to find communities in networks rely just on structural information and search for cohesive subsets of nodes. On the other hand, most scholars implicitly or explicitly assume that structural communities represent groups of nodes with similar (nontopological) properties or functions. This hypothesis could not be verified, so far, because of the lack of network datasets with information on the classification of the nodes. We show that traditional community detection methods fail to find the metadata groups in many large networks. Our results show that there is a marked separation between structural communities and metadata groups, in line with recent findings. That means that either our current modeling of community structure has to be substantially modified, or that metadata groups may not be recoverable from topology alone.},
	number = {6},
	urldate = {2020-10-29},
	journal = {Physical Review E},
	author = {Hric, Darko and Darst, Richard K. and Fortunato, Santo},
	month = dec,
	year = {2014},
	note = {Publisher: American Physical Society},
	keywords = {Community Detection},
	pages = {062805},
}

@article{javed_community_2018,
	title = {Community detection in networks: {A} multidisciplinary review},
	volume = {108},
	issn = {1084-8045},
	shorttitle = {Community detection in networks},
	url = {http://www.sciencedirect.com/science/article/pii/S1084804518300560},
	doi = {10.1016/j.jnca.2018.02.011},
	abstract = {The modern science of networks has made significant advancement in the modeling of complex real-world systems. One of the most important features in these networks is the existence of community structure. In recent years, many community detection algorithms have been proposed to unveil the structural properties and dynamic behaviors of networks. In this study, we attempt a contemporary survey on the methods of community detection and its applications in the various domains of real life. Besides highlighting the strengths and weaknesses of each community detection approach, different aspects of algorithmic performance comparison and their testing on standard benchmarks are discussed. The challenges faced by community detection algorithms, open issues and future trends related to community detection are also postulated. The main goal of this paper is to put forth a review of prevailing community detection algorithms that range from traditional algorithms to state of the art algorithms for overlapping community detection. Algorithms based on dimensionality reduction techniques such as non-negative matrix factorization (NMF) and principal component analysis (PCA) are also focused. This study will serve as an up-to-date report on the evolution of community detection and its potential applications in various domains from real world networks.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Journal of Network and Computer Applications},
	author = {Javed, Muhammad Aqib and Younis, Muhammad Shahzad and Latif, Siddique and Qadir, Junaid and Baig, Adeel},
	month = apr,
	year = {2018},
	keywords = {Social Networks, Survey, Community Detection, Clustering},
	pages = {87--111},
}

@article{fortunato_community_2010,
	title = {Community detection in graphs},
	volume = {486},
	issn = {0370-1573},
	url = {http://www.sciencedirect.com/science/article/pii/S0370157309002841},
	doi = {10.1016/j.physrep.2009.11.002},
	abstract = {The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks.},
	language = {en},
	number = {3},
	urldate = {2020-10-29},
	journal = {Physics Reports},
	author = {Fortunato, Santo},
	month = feb,
	year = {2010},
	keywords = {Community Detection, Networks, Graph Theory, Clustering},
	pages = {75--174},
}

@inproceedings{abbe_community_2015,
	title = {Community {Detection} in {General} {Stochastic} {Block} models: {Fundamental} {Limits} and {Efficient} {Algorithms} for {Recovery}},
	shorttitle = {Community {Detection} in {General} {Stochastic} {Block} models},
	doi = {10.1109/FOCS.2015.47},
	abstract = {New phase transition phenomena have recently been discovered for the stochastic block model, for the special case of two non-overlapping symmetric communities. This gives raise in particular to new algorithmic challenges driven by the thresholds. This paper investigates whether a general phenomenon takes place for multiple communities, without imposing symmetry. In the general stochastic block model SBM(n,p,W), n vertices are split into k communities of relative size pii∈[k], and vertices in community i and j connect independently with probability Wiji,j∈[k]. This paper investigates the partial and exact recovery of communities in the general SBM (in the constant and logarithmic degree regimes), and uses the generality of the results to tackle overlapping communities. The contributions of the paper are: (i) an explicit characterization of the recovery threshold in the general SBM in terms of a new f-divergence function D+, which generalizes the Hellinger and Chernoff divergences, and which provides an operational meaning to a divergence function analog to the KL-divergence in the channel coding theorem, (ii) the development of an algorithm that recovers the communities all the way down to the optimal threshold and runs in quasi-linear time, showing that exact recovery has no information-theoretic to computational gap for multiple communities, (iii) the development of an efficient algorithm that detects communities in the constant degree regime with an explicit accuracy bound that can be made arbitrarily close to 1 when a prescribed signal-to-noise ratio [defined in terms of the spectrum of diag(p)W] tends to infinity.},
	booktitle = {2015 {IEEE} 56th {Annual} {Symposium} on {Foundations} of {Computer} {Science}},
	author = {Abbe, E. and Sandon, C.},
	month = oct,
	year = {2015},
	note = {ISSN: 0272-5428},
	keywords = {Dynamic Systems, Community Detection, Graph Theory, Clustering, Complexity Theory, Stochastic Processes},
	pages = {670--688},
}

@article{robert_james_2011,
	title = {James {E}. {Gentle}: {Computational} statistics ({Statistics} and {Computing} {Series})},
	volume = {21},
	issn = {1573-1375},
	shorttitle = {James {E}. {Gentle}},
	url = {https://doi.org/10.1007/s11222-010-9189-9},
	doi = {10.1007/s11222-010-9189-9},
	language = {en},
	number = {2},
	urldate = {2023-02-15},
	journal = {Statistics and Computing},
	author = {Robert, Christian P.},
	month = apr,
	year = {2011},
	pages = {289--291},
}

@article{allison_fixed-effects_2002,
	title = {Fixed-{Effects} {Negative} {Binomial} {Regression} {Models}},
	volume = {32},
	issn = {0081-1750},
	url = {https://www.jstor.org/stable/3186160},
	abstract = {This paper demonstrates that the conditional negative binomial model for panel data, proposed by Hausman, Hall, and Griliches (1984), is not a true fixed-effects method. This method-which has been implemented in both Stata and LIMDEP-does not in fact control for all stable covariates. Three alternative methods are explored. A negative multinomial model yields the same estimator as the conditional Poisson estimator and hence does not provide any additional leverage for dealing with over-dispersion. On the other hand, a simulation study yields good results from applying an unconditional negative binomial regression estimator with dummy variables to represent the fixed effects. There is no evidence for any incidental parameters bias in the coefficients, and downward bias in the standard error estimates can be easily and effectively corrected using the deviance statistic. Finally, an approximate conditional method is found to perform at about the same level as the unconditional estimator.},
	urldate = {2023-02-15},
	journal = {Sociological Methodology},
	author = {Allison, Paul D. and Waterman, Richard P.},
	year = {2002},
	note = {Publisher: [American Sociological Association, Wiley, Sage Publications, Inc.]},
	pages = {247--265},
}

@book{atkinson_plots_1987,
	address = {Oxford, New York},
	series = {Oxford {Statistical} {Science} {Series}},
	title = {Plots, {Transformations}, and {Regression}: {An} {Introduction} to {Graphical} {Methods} of {Diagnostic} {Regression} {Analysis}},
	isbn = {978-0-19-853371-9},
	shorttitle = {Plots, {Transformations}, and {Regression}},
	abstract = {This handbook provides a detailed, down-to-earth introduction to regression diagnostic analysis, a technique of growing importance for work in applied statistics. Heavily illustrated, with numerous examples to illuminate the discussion, this timely volume outlines methods for regression models, stressing detection of outliers and inadequate models; describes the transformation of variables in an equation, particularly the response; and considers such advanced topics as generalized linear models. A useful guide that combines lucid explanations with up-to-date research findings.
            ,
             This handbook provides a detailed, down-to-earth introduction to regression diagnostic analysis, a technique of growing importance for work in applied statistics. Heavily illustrated, with numerous examples to illuminate the discussion, this timely volume outlines methods for regression models, stressing detection of outliers and inadequate models; describes the transformation of variables in an equation, particularly the response; and considers such advanced topics as generalized linear models. A useful guide that combines lucid explanations with up-to-date research findings.},
	publisher = {Oxford University Press},
	author = {Atkinson, A. C.},
	month = dec,
	year = {1987},
}

@article{gomes_should_2022,
	title = {Should {I} use fixed effects or random effects when {I} have fewer than five levels of a grouping factor in a mixed-effects model?},
	volume = {10},
	issn = {2167-8359},
	url = {https://peerj.com/articles/12794},
	doi = {10.7717/peerj.12794},
	abstract = {As linear mixed-effects models (LMMs) have become a widespread tool in ecology, the need to guide the use of such tools is increasingly important. One common guideline is that one needs at least five levels of the grouping variable associated with a random effect. Having so few levels makes the estimation of the variance of random effects terms (such as ecological sites, individuals, or populations) difficult, but it need not muddy one’s ability to estimate fixed effects terms—which are often of primary interest in ecology. Here, I simulate datasets and fit simple models to show that having few random effects levels does not strongly influence the parameter estimates or uncertainty around those estimates for fixed effects terms—at least in the case presented here. Instead, the coverage probability of fixed effects estimates is sample size dependent. LMMs including low-level random effects terms may come at the expense of increased singular fits, but this did not appear to influence coverage probability or RMSE, except in low sample size (N = 30) scenarios. Thus, it may be acceptable to use fewer than five levels of random effects if one is not interested in making inferences about the random effects terms (i.e. when they are ‘nuisance’ parameters used to group non-independent data), but further work is needed to explore alternative scenarios. Given the widespread accessibility of LMMs in ecology and evolution, future simulation studies and further assessments of these statistical methods are necessary to understand the consequences both of violating and of routinely following simple guidelines.},
	language = {en},
	urldate = {2023-02-15},
	journal = {PeerJ},
	author = {Gomes, Dylan G. E.},
	month = jan,
	year = {2022},
	note = {Publisher: PeerJ Inc.},
	pages = {e12794},
}

@misc{noauthor_applied_2023,
	title = {Applied {Regression} {Analysis} and {Generalized} {Linear} {Models}},
	url = {https://us.sagepub.com/en-us/nam/applied-regression-analysis-and-generalized-linear-models/book237254},
	language = {en},
	urldate = {2023-02-15},
	journal = {SAGE Publications Inc},
	author = {Fox, John},
	month = feb,
	year = {2023},
}

@article{lancichinetti_community_2009,
	title = {Community detection algorithms: {A} comparative analysis},
	volume = {80},
	shorttitle = {Community detection algorithms},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.80.056117},
	doi = {10.1103/PhysRevE.80.056117},
	abstract = {Uncovering the community structure exhibited by real networks is a crucial step toward an understanding of complex systems that goes beyond the local organization of their constituents. Many algorithms have been proposed so far, but none of them has been subjected to strict tests to evaluate their performance. Most of the sporadic tests performed so far involved small networks with known community structure and/or artificial graphs with a simplified structure, which is very uncommon in real systems. Here we test several methods against a recently introduced class of benchmark graphs, with heterogeneous distributions of degree and community size. The methods are also tested against the benchmark by Girvan and Newman [Proc. Natl. Acad. Sci. U.S.A. 99, 7821 (2002)] and on random graphs. As a result of our analysis, three recent algorithms introduced by Rosvall and Bergstrom [Proc. Natl. Acad. Sci. U.S.A. 104, 7327 (2007); Proc. Natl. Acad. Sci. U.S.A. 105, 1118 (2008)], Blondel et al. [J. Stat. Mech.: Theory Exp. (2008), P10008], and Ronhovde and Nussinov [Phys. Rev. E 80, 016109 (2009)] have an excellent performance, with the additional advantage of low computational complexity, which enables one to analyze large systems.},
	number = {5},
	urldate = {2020-10-29},
	journal = {Physical Review E},
	author = {Lancichinetti, Andrea and Fortunato, Santo},
	month = nov,
	year = {2009},
	note = {Publisher: American Physical Society},
	keywords = {Survey, Community Detection},
	pages = {056117},
}

@article{bozdag_breaking_2015,
	title = {Breaking the filter bubble: democracy and design},
	volume = {17},
	issn = {1572-8439},
	shorttitle = {Breaking the filter bubble},
	url = {https://doi.org/10.1007/s10676-015-9380-y},
	doi = {10.1007/s10676-015-9380-y},
	abstract = {It has been argued that the Internet and social media increase the number of available viewpoints, perspectives, ideas and opinions available, leading to a very diverse pool of information. However, critics have argued that algorithms used by search engines, social networking platforms and other large online intermediaries actually decrease information diversity by forming so-called “filter bubbles”. This may form a serious threat to our democracies. In response to this threat others have developed algorithms and digital tools to combat filter bubbles. This paper first provides examples of different software designs that try to break filter bubbles. Secondly, we show how norms required by two democracy models dominate the tools that are developed to fight the filter bubbles, while norms of other models are completely missing in the tools. The paper in conclusion argues that democracy itself is a contested concept and points to a variety of norms. Designers of diversity enhancing tools must thus be exposed to diverse conceptions of democracy.},
	language = {en},
	number = {4},
	urldate = {2020-10-29},
	journal = {Ethics and Information Technology},
	author = {Bozdag, Engin and van den Hoven, Jeroen},
	month = dec,
	year = {2015},
	keywords = {Filter Bubble, Politics},
	pages = {249--265},
	file = {Bozdag and van den Hoven - 2015 - Breaking the filter bubble democracy and design.pdf:/Users/clente/Zotero/storage/2TEMG4NM/Bozdag and van den Hoven - 2015 - Breaking the filter bubble democracy and design.pdf:application/pdf},
}

@article{jiang_bias_2019,
	title = {Bias {Misperceived}:{The} {Role} of {Partisanship} and {Misinformation} in {YouTube} {Comment} {Moderation}},
	volume = {13},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2334-0770},
	shorttitle = {Bias {Misperceived}},
	url = {https://www.aaai.org/ojs/index.php/ICWSM/article/view/3229},
	abstract = {Social media platforms have been the subject of controversy and scrutiny due to the spread of hateful content. To address this problem, the platforms implement content moderation using a mix of human and algorithmic processes. However, content moderation itself has lead to further accusations against the platforms of political bias. In this study, we investigate how channel partisanship and video misinformation affect the likelihood of comment moderation on YouTube. Using a dataset of 84,068 comments on 258 videos, we find that although comments on right-leaning videos are more heavily moderated from a correlational perspective, we find no evidence to support claims of political bias when using a causal model that controls for common confounders (e.g., hate speech). Additionally, we find that comments are more likely to be moderated if the video channel is ideologically extreme, if the video content is false, and if the comments were posted after a fact-check.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Jiang, Shan and Robertson, Ronald E. and Wilson, Christo},
	month = jul,
	year = {2019},
	keywords = {Social Networks, Bias, Polarization},
	pages = {278--289},
}

@inproceedings{ribeiro_auditing_2020,
	address = {New York, NY, USA},
	series = {{FAT}* '20},
	title = {Auditing radicalization pathways on {YouTube}},
	isbn = {978-1-4503-6936-7},
	url = {https://doi.org/10.1145/3351095.3372879},
	doi = {10.1145/3351095.3372879},
	abstract = {Non-profits, as well as the media, have hypothesized the existence of a radicalization pipeline on YouTube, claiming that users systematically progress towards more extreme content on the platform. Yet, there is to date no substantial quantitative evidence of this alleged pipeline. To close this gap, we conduct a large-scale audit of user radicalization on YouTube. We analyze 330,925 videos posted on 349 channels, which we broadly classified into four types: Media, the Alt-lite, the Intellectual Dark Web (I.D.W.), and the Alt-right. According to the aforementioned radicalization hypothesis, channels in the I.D.W. and the Alt-lite serve as gateways to fringe far-right ideology, here represented by Alt-right channels. Processing 72M+ comments, we show that the three channel types indeed increasingly share the same user base; that users consistently migrate from milder to more extreme content; and that a large percentage of users who consume Alt-right content now consumed Alt-lite and I.D.W. content in the past. We also probe YouTube's recommendation algorithm, looking at more than 2M video and channel recommendations between May/July 2019. We find that Alt-lite content is easily reachable from I.D.W. channels, while Alt-right videos are reachable only through channel recommendations. Overall, we paint a comprehensive picture of user radicalization on YouTube.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Ribeiro, Manoel Horta and Ottoni, Raphael and West, Robert and Almeida, Virgílio A. F. and Meira, Wagner},
	month = jan,
	year = {2020},
	keywords = {Social Networks, Dynamic Systems, Polarization, Extremism},
	pages = {131--141},
	file = {Ribeiro et al. - 2020 - Auditing radicalization pathways on YouTube.pdf:/Users/clente/Zotero/storage/KMMHKMIJ/Ribeiro et al. - 2020 - Auditing radicalization pathways on YouTube.pdf:application/pdf},
}

@article{tangherlini_automated_2020,
	title = {An automated pipeline for the discovery of conspiracy and conspiracy theory narrative frameworks: {Bridgegate}, {Pizzagate} and storytelling on the web},
	volume = {15},
	issn = {1932-6203},
	shorttitle = {An automated pipeline for the discovery of conspiracy and conspiracy theory narrative frameworks},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0233879},
	doi = {10.1371/journal.pone.0233879},
	abstract = {Although a great deal of attention has been paid to how conspiracy theories circulate on social media, and the deleterious effect that they, and their factual counterpart conspiracies, have on political institutions, there has been little computational work done on describing their narrative structures. Predicating our work on narrative theory, we present an automated pipeline for the discovery and description of the generative narrative frameworks of conspiracy theories that circulate on social media, and actual conspiracies reported in the news media. We base this work on two separate comprehensive repositories of blog posts and news articles describing the well-known conspiracy theory Pizzagate from 2016, and the New Jersey political conspiracy Bridgegate from 2013. Inspired by the qualitative narrative theory of Greimas, we formulate a graphical generative machine learning model where nodes represent actors/actants, and multi-edges and self-loops among nodes capture context-specific relationships. Posts and news items are viewed as samples of subgraphs of the hidden narrative framework network. The problem of reconstructing the underlying narrative structure is then posed as a latent model estimation problem. To derive the narrative frameworks in our target corpora, we automatically extract and aggregate the actants (people, places, objects) and their relationships from the posts and articles. We capture context specific actants and interactant relationships by developing a system of supernodes and subnodes. We use these to construct an actant-relationship network, which constitutes the underlying generative narrative framework for each of the corpora. We show how the Pizzagate framework relies on the conspiracy theorists’ interpretation of “hidden knowledge” to link otherwise unlinked domains of human interaction, and hypothesize that this multi-domain focus is an important feature of conspiracy theories. We contrast this to the single domain focus of an actual conspiracy. While Pizzagate relies on the alignment of multiple domains, Bridgegate remains firmly rooted in the single domain of New Jersey politics. We hypothesize that the narrative framework of a conspiracy theory might stabilize quickly in contrast to the narrative framework of an actual conspiracy, which might develop more slowly as revelations come to light. By highlighting the structural differences between the two narrative frameworks, our approach could be used by private and public analysts to help distinguish between conspiracy theories and conspiracies.},
	language = {en},
	number = {6},
	urldate = {2020-10-29},
	journal = {PLOS ONE},
	author = {Tangherlini, Timothy R. and Shahsavari, Shadi and Shahbazi, Behnam and Ebrahimzadeh, Ehsan and Roychowdhury, Vwani},
	month = jun,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Social Networks, Politics, Polarization, Community Detection},
	pages = {e0233879},
	file = {Tangherlini et al. - 2020 - An automated pipeline for the discovery of conspir.pdf:/Users/clente/Zotero/storage/I9J48MV9/Tangherlini et al. - 2020 - An automated pipeline for the discovery of conspir.pdf:application/pdf},
}

@inproceedings{stoica_algorithmic_2018,
	address = {Republic and Canton of Geneva, CHE},
	series = {{WWW} '18},
	title = {Algorithmic {Glass} {Ceiling} in {Social} {Networks}: {The} effects of social recommendations on network diversity},
	isbn = {978-1-4503-5639-8},
	shorttitle = {Algorithmic {Glass} {Ceiling} in {Social} {Networks}},
	url = {https://doi.org/10.1145/3178876.3186140},
	doi = {10.1145/3178876.3186140},
	abstract = {As social recommendations such as friend suggestions and people to follow become increasingly popular and influential on the growth of social media, we find that prominent social recommendation algorithms can exacerbate the under-representation of certain demographic groups at the top of the social hierarchy. To study this imbalance in online equal opportunities, we leverage new Instagram data and offer for the first time an analysis that studies the effect of gender, homophily and growth dynamics under social recommendations. Our mathematical analysis demonstrates the existence of an algorithmic glass ceiling that exhibits all the properties of the metaphorical social barrier that hinders groups like women or people of color from attaining equal representation. What raises concern is that our proof shows that under fixed minority and homophily parameters the algorithmic effect is systematically larger than the glass ceiling generated by the spontaneous growth of social networks. We discuss ways to address this concern in future design.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Stoica, Ana-Andreea and Riederer, Christopher and Chaintreau, Augustin},
	month = apr,
	year = {2018},
	keywords = {Social Networks, Bias, Recommender Systems, Polarization, Community Detection, Homophily},
	pages = {923--932},
	file = {Stoica et al. - 2018 - Algorithmic Glass Ceiling in Social Networks The .pdf:/Users/clente/Zotero/storage/NIIH2SX6/Stoica et al. - 2018 - Algorithmic Glass Ceiling in Social Networks The .pdf:application/pdf},
}

@inproceedings{stoica_algorithmic_2020,
	address = {Richland, SC},
	series = {{AAMAS} '20},
	title = {Algorithmic {Fairness} for {Networked} {Algorithms}},
	isbn = {978-1-4503-7518-4},
	abstract = {Recent evidence points to the detrimental effects of algorithmic deployment on human datasets, as often times such algorithms mirror and exacerbate existing inequalities in the input data. This work focuses on understanding the disparate effects of algorithms on social inequality and building theory and applications for graph algorithms with ramifications in the way we learn information online and offline. We show that in the case of recommendation algorithms, the most common heuristics that learn connections for providing social recommendations exacerbate disparity between different communities in a bi-populated network by reinforcing certain patterns in the network, such as homophilic behavior. Similar results occur for content recommendation, where we show that minority viewpoints are being further diminished by algorithms that learn relational data and over-recommend a majority viewpoint. On the other hand, algorithms may leverage community affiliation to disperse information in a network in a more effective manner while being more equitable in terms of the demographics reached in certain conditions. For such studies, we find closed-form conditions of the results using graph theoretical models that replicate inequality in social networks and use them to develop a set of algorithms that use network statistics to diffuse information in a feature-aware way, effectively reaching more communities than the status quo heuristics that are blind to sensitive features. Through validation on real-world data, we show that such learning algorithms benefit from being feature-aware in learning relational data in order to mitigate bias.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Autonomous} {Agents} and {MultiAgent} {Systems}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Stoica, Ana-Andreea},
	month = may,
	year = {2020},
	keywords = {Social Networks, Bias, Recommender Systems, Graph Theory, Clustering},
	pages = {2214--2216},
	file = {Stoica - 2020 - Algorithmic Fairness for Networked Algorithms.pdf:/Users/clente/Zotero/storage/47HVXDMX/Stoica - 2020 - Algorithmic Fairness for Networked Algorithms.pdf:application/pdf},
}

@article{sirbu_algorithmic_2019,
	title = {Algorithmic bias amplifies opinion fragmentation and polarization: {A} bounded confidence model},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {Algorithmic bias amplifies opinion fragmentation and polarization},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0213246},
	doi = {10.1371/journal.pone.0213246},
	abstract = {The flow of information reaching us via the online media platforms is optimized not by the information content or relevance but by popularity and proximity to the target. This is typically performed in order to maximise platform usage. As a side effect, this introduces an algorithmic bias that is believed to enhance fragmentation and polarization of the societal debate. To study this phenomenon, we modify the well-known continuous opinion dynamics model of bounded confidence in order to account for the algorithmic bias and investigate its consequences. In the simplest version of the original model the pairs of discussion participants are chosen at random and their opinions get closer to each other if they are within a fixed tolerance level. We modify the selection rule of the discussion partners: there is an enhanced probability to choose individuals whose opinions are already close to each other, thus mimicking the behavior of online media which suggest interaction with similar peers. As a result we observe: a) an increased tendency towards opinion fragmentation, which emerges also in conditions where the original model would predict consensus, b) increased polarisation of opinions and c) a dramatic slowing down of the speed at which the convergence at the asymptotic state is reached, which makes the system highly unstable. Fragmentation and polarization are augmented by a fragmented initial population.},
	language = {en},
	number = {3},
	urldate = {2020-10-29},
	journal = {PLOS ONE},
	author = {Sîrbu, Alina and Pedreschi, Dino and Giannotti, Fosca and Kertész, János},
	month = mar,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Social Networks, Bias, Opinion Dynamics, Bounded Confidence, Polarization},
	pages = {e0213246},
	file = {Sîrbu et al. - 2019 - Algorithmic bias amplifies opinion fragmentation a.pdf:/Users/clente/Zotero/storage/4HG8HJSV/Sîrbu et al. - 2019 - Algorithmic bias amplifies opinion fragmentation a.pdf:application/pdf},
}

@article{dong_survey_2018,
	title = {A survey on the fusion process in opinion dynamics},
	volume = {43},
	issn = {1566-2535},
	url = {http://www.sciencedirect.com/science/article/pii/S1566253517306322},
	doi = {10.1016/j.inffus.2017.11.009},
	abstract = {Opinion dynamics is a fusion process of individual opinions, in which a group of interacting agents continuously fuse their opinions on the same issue based on established fusion rules to reach a consensus, polarization, or fragmentation in the final stage. To date, many studies have been conducted on opinion dynamics. To provide a clear perspective on the fusion process in opinion dynamics, this paper presents a review of the framework and formulation of opinion dynamics as well as some basic models, extensions, and applications. Based on the insights gained from prior studies, several open problems are proposed for future research.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Information Fusion},
	author = {Dong, Yucheng and Zhan, Min and Kou, Gang and Ding, Zhaogang and Liang, Haiming},
	month = sep,
	year = {2018},
	keywords = {Opinion Dynamics, Survey, Consensus},
	pages = {57--65},
}

@article{rana_study_2012,
	title = {A study of the dynamic features of recommender systems},
	volume = {43},
	issn = {0269-2821, 1573-7462},
	url = {http://link.springer.com/10.1007/s10462-012-9359-6},
	doi = {10.1007/s10462-012-9359-6},
	abstract = {The extensive usage of internet is fundamentally changing the way we live and communicate. Consequently, the requirements of users while browsing internet are changing drastically. Recommender Systems (RSs) provide a technology that helps users in ﬁnding relevant contents on internet. Revolutionary innovations in the ﬁeld of internet and their consequent effects on users have activated the research in the area of recommender systems. This paper presents issues related to the changing needs of user requirements as well as changes in the systems’ contents. The RSs involving said issues are termed as Dynamic Recommender Systems (DRSs). The paper ﬁrst deﬁnes the concept of DRS and explores the various parameters that contribute in developing a DRS. The paper also discusses the scope of contributions in this ﬁeld and concludes citing in possible extensions that can improve the dynamic qualities of recommendation systems in future.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Artificial Intelligence Review},
	author = {Rana, Chhavi and Jain, Sanjay Kumar},
	month = nov,
	year = {2012},
	keywords = {Recommender Systems, Dynamic Systems},
	pages = {141--153},
	file = {Rana and Jain - 2012 - A study of the dynamic features of recommender sys.pdf:/Users/clente/Zotero/storage/YX3GQTTA/Rana and Jain - 2012 - A study of the dynamic features of recommender sys.pdf:application/pdf},
}

@article{weinan_proposal_2017,
	title = {A {Proposal} on {Machine} {Learning} via {Dynamical} {Systems}},
	volume = {5},
	issn = {2194-6701, 2194-671X},
	url = {http://link.springer.com/10.1007/s40304-017-0103-z},
	doi = {10.1007/s40304-017-0103-z},
	abstract = {We discuss the idea of using continuous dynamical systems to model general high-dimensional nonlinear functions used in machine learning. We also discuss the connection with deep learning.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Communications in Mathematics and Statistics},
	author = {Weinan, E},
	month = mar,
	year = {2017},
	keywords = {Dynamic Systems, Machine Learning},
	pages = {1--11},
}

@article{liu_multiobjective_2014,
	title = {A {Multiobjective} {Evolutionary} {Algorithm} {Based} on {Similarity} for {Community} {Detection} {From} {Signed} {Social} {Networks}},
	volume = {44},
	issn = {2168-2275},
	doi = {10.1109/TCYB.2014.2305974},
	abstract = {Various types of social relationships, such as friends and foes, can be represented as signed social networks (SNs) that contain both positive and negative links. Although many community detection (CD) algorithms have been proposed, most of them were designed primarily for networks containing only positive links. Thus, it is important to design CD algorithms which can handle large-scale SNs. To this purpose, we first extend the original similarity to the signed similarity based on the social balance theory. Then, based on the signed similarity and the natural contradiction between positive and negative links, two objective functions are designed to model the problem of detecting communities in SNs as a multiobjective problem. Afterward, we propose a multiobjective evolutionary algorithm, called MEAsSN. In MEAs-SN, to overcome the defects of direct and indirect representations for communities, a direct and indirect combined representation is designed. Attributing to this representation, MEAs-SN can switch between different representations during the evolutionary process. As a result, MEAs-SN can benefit from both representations. Moreover, owing to this representation, MEAs-SN can also detect overlapping communities directly. In the experiments, both benchmark problems and large-scale synthetic networks generated by various parameter settings are used to validate the performance of MEAs-SN. The experimental results show the effectiveness and efficacy of MEAs-SN on networks with 1000, 5000, and 10000 nodes and also in various noisy situations. A thorough comparison is also made between MEAs-SN and three existing algorithms, and the results show that MEAs-SN outperforms other algorithms.},
	number = {12},
	journal = {IEEE Transactions on Cybernetics},
	author = {Liu, C. and Liu, J. and Jiang, Z.},
	month = dec,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Cybernetics},
	keywords = {Social Networks, Community Detection},
	pages = {2274--2287},
}

@article{lunardi_metric_2020,
	title = {A metric for {Filter} {Bubble} measurement in recommender algorithms considering the news domain},
	volume = {97},
	issn = {1568-4946},
	url = {http://www.sciencedirect.com/science/article/pii/S1568494620307092},
	doi = {10.1016/j.asoc.2020.106771},
	abstract = {Recommender systems have been constantly refined to improve the accuracy of rating prediction and ranking generation. However, when a recommender system is too accurate in predicting the users’ interests, negative impacts can arise. One of the most critical is the filter bubbles creation, a situation where a user receives less content diversity. In the news domain, such effect is critical once they are ways of opinion formation. In this paper, we aim to assess the role that a specific set of recommender algorithms has in the creation of filter bubbles and if diversification approaches can decrease such effect. We also verify the effects of such an environment in the users’ exposition and interaction to fake news in the Brazilian presidential election of 2018. To perform such a study, we developed a prototype that recommends news stories and presents these recommendations in a feed. To measure the filter bubble, we introduce a new metric based on the homogenization of a recommended items’ set. Our results show KNN item-based recommendation with the MMR diversification algorithm performs slightly better in putting the user in contact with less homogeneous content while presenting a lower index of likes in fake news.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Applied Soft Computing},
	author = {Lunardi, Gabriel Machado and Machado, Guilherme Medeiros and Maran, Vinicius and de Oliveira, José Palazzo M.},
	month = dec,
	year = {2020},
	keywords = {Recommender Systems, Filter Bubble, Fake News},
	pages = {106771},
}

@article{guerra_measure_2013,
	title = {A {Measure} of {Polarization} on {Social} {Media} {Networks} {Based} on {Community} {Boundaries}},
	abstract = {Polarization in social media networks is a fact in several scenarios such as political debates and other contexts such as same-sex marriage, abortion and gun control. Understanding and quantifying polarization is a longterm challenge to researchers from several areas, also being a key information for tasks such as opinion analysis. In this paper, we perform a systematic comparison between social networks that arise from both polarized and non-polarized contexts. This comparison shows that the traditional polarization metric – modularity – is not a direct measure of antagonism between groups, since non-polarized networks may be also divided into fairly modular communities. To bridge this conceptual gap, we propose a novel polarization metric based on the analysis of the boundary of a pair of (potentially polarized) communities, which better captures the notions of antagonism and polarization. We then characterize polarized and non-polarized social networks according to the concentration of high-degree nodes in the boundary of communities, and found that polarized networks tend to exhibit low concentration of popular nodes along the boundary. To demonstrate the usefulness of our polarization measures, we analyze opinions expressed on Twitter on the gun control issue in the United States, and conclude that our novel metrics help making sense of opinions expressed on online media.},
	language = {en},
	author = {Guerra, Pedro Calais and Jr, Wagner Meira and Cardie, Claire and Kleinberg, Robert},
	year = {2013},
	keywords = {Social Networks, Polarization, Community Detection},
	pages = {10},
	file = {Guerra et al. - 2013 - A Measure of Polarization on Social Media Networks.pdf:/Users/clente/Zotero/storage/RPMHNYLU/Guerra et al. - 2013 - A Measure of Polarization on Social Media Networks.pdf:application/pdf},
}

@article{yang_comparative_2016,
	title = {A {Comparative} {Analysis} of {Community} {Detection} {Algorithms} on {Artificial} {Networks}},
	volume = {6},
	copyright = {2016 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep30750},
	doi = {10.1038/srep30750},
	abstract = {Many community detection algorithms have been developed to uncover the mesoscopic properties of complex networks. However how good an algorithm is, in terms of accuracy and computing time, remains still open. Testing algorithms on real-world network has certain restrictions which made their insights potentially biased: the networks are usually small, and the underlying communities are not defined objectively. In this study, we employ the Lancichinetti-Fortunato-Radicchi benchmark graph to test eight state-of-the-art algorithms. We quantify the accuracy using complementary measures and algorithms’ computing time. Based on simple network properties and the aforementioned results, we provide guidelines that help to choose the most adequate community detection algorithm for a given network. Moreover, these rules allow uncovering limitations in the use of specific algorithms given macroscopic network properties. Our contribution is threefold: firstly, we provide actual techniques to determine which is the most suited algorithm in most circumstances based on observable properties of the network under consideration. Secondly, we use the mixing parameter as an easily measurable indicator of finding the ranges of reliability of the different algorithms. Finally, we study the dependency with network size focusing on both the algorithm’s predicting power and the effective computing time.},
	language = {en},
	number = {1},
	urldate = {2020-10-29},
	journal = {Scientific Reports},
	author = {Yang, Zhao and Algesheimer, René and Tessone, Claudio J.},
	month = aug,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Social Networks, Community Detection},
	pages = {30750},
}

@inproceedings{qi_community_2012,
	title = {Community {Detection} with {Edge} {Content} in {Social} {Media} {Networks}},
	doi = {10.1109/ICDE.2012.77},
	abstract = {The problem of community detection in social media has been widely studied in the social networking community in the context of the structure of the underlying graphs. Most community detection algorithms use the links between the nodes in order to determine the dense regions in the graph. These dense regions are the communities of social media in the graph. Such methods are typically based purely on the linkage structure of the underlying social media network. However, in many recent applications, edge content is available in order to provide better supervision to the community detection process. Many natural representations of edges in social interactions such as shared images and videos, user tags and comments are naturally associated with content on the edges. While some work has been done on utilizing node content for community detection, the presence of edge content presents unprecedented opportunities and flexibility for the community detection process. We will show that such edge content can be leveraged in order to greatly improve the effectiveness of the community detection process in social media networks. We present experimental results illustrating the effectiveness of our approach.},
	booktitle = {2012 {IEEE} 28th {International} {Conference} on {Data} {Engineering}},
	author = {Qi, G. and Aggarwal, C. C. and Huang, T.},
	month = apr,
	year = {2012},
	note = {ISSN: 2375-026X},
	keywords = {Social Networks, Community Detection, Graph Theory, Clustering},
	pages = {534--545},
}

@inproceedings{massoulie_community_2014,
	address = {New York, NY, USA},
	series = {{STOC} '14},
	title = {Community detection thresholds and the weak {Ramanujan} property},
	isbn = {978-1-4503-2710-7},
	url = {https://doi.org/10.1145/2591796.2591857},
	doi = {10.1145/2591796.2591857},
	abstract = {Decelle et al. [1] conjectured the existence of a sharp threshold on model parameters for community detection in sparse random graphs drawn from the stochastic block model. Mossel, Neeman and Sly [2] established the negative part of the conjecture, proving impossibility of non-trivial reconstruction below the threshold. In this work we solve the positive part of the conjecture. To that end we introduce a modified adjacency matrix B which counts self-avoiding paths of a given length ℓ between pairs of nodes. We then prove that for logarithmic length ℓ, the leading eigenvectors of this modified matrix provide a non-trivial reconstruction of the underlying structure, thereby settling the conjecture. A key step in the proof consists in establishing a weak Ramanujan property of the constructed matrix B. Namely, the spectrum of B consists in two leading eigenvalues ρ(B), λ2 and n -- 2 eigenvalues of a lower order O(nε √ρ(B) for all ε 0, ρ(B) denoting B's spectral radius.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the forty-sixth annual {ACM} symposium on {Theory} of computing},
	publisher = {Association for Computing Machinery},
	author = {Massoulié, Laurent},
	month = may,
	year = {2014},
	keywords = {Dynamic Systems, Community Detection},
	pages = {694--703},
}

@article{fortunato_community_2016,
	series = {Community detection in networks: {A} user guide},
	title = {Community detection in networks: {A} user guide},
	volume = {659},
	issn = {0370-1573},
	shorttitle = {Community detection in networks},
	url = {http://www.sciencedirect.com/science/article/pii/S0370157316302964},
	doi = {10.1016/j.physrep.2016.09.002},
	abstract = {Community detection in networks is one of the most popular topics of modern network science. Communities, or clusters, are usually groups of vertices having higher probability of being connected to each other than to members of other groups, though other patterns are possible. Identifying communities is an ill-defined problem. There are no universal protocols on the fundamental ingredients, like the definition of community itself, nor on other crucial issues, like the validation of algorithms and the comparison of their performances. This has generated a number of confusions and misconceptions, which undermine the progress in the field. We offer a guided tour through the main aspects of the problem. We also point out strengths and weaknesses of popular methods, and give directions to their use.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Physics Reports},
	author = {Fortunato, Santo and Hric, Darko},
	month = nov,
	year = {2016},
	keywords = {Community Detection, Networks, Clustering},
	pages = {1--44},
}

@inproceedings{nguyen_exploring_2014,
	address = {New York, NY, USA},
	series = {{WWW} '14},
	title = {Exploring the filter bubble: the effect of using recommender systems on content diversity},
	isbn = {978-1-4503-2744-2},
	shorttitle = {Exploring the filter bubble},
	url = {https://doi.org/10.1145/2566486.2568012},
	doi = {10.1145/2566486.2568012},
	abstract = {Eli Pariser coined the term 'filter bubble' to describe the potential for online personalization to effectively isolate people from a diversity of viewpoints or content. Online recommender systems - built on algorithms that attempt to predict which items users will most enjoy consuming - are one family of technologies that potentially suffers from this effect. Because recommender systems have become so prevalent, it is important to investigate their impact on users in these terms. This paper examines the longitudinal impacts of a collaborative filtering-based recommender system on users. To the best of our knowledge, it is the first paper to measure the filter bubble effect in terms of content diversity at the individual level. We contribute a novel metric to measure content diversity based on information encoded in user-generated tags, and we present a new set of methods to examine the temporal effect of recommender systems on the user experience. We do find that recommender systems expose users to a slightly narrowing set of items over time. However, we also see evidence that users who actually consume the items recommended to them experience lessened narrowing effects and rate items more positively.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 23rd international conference on {World} wide web},
	publisher = {Association for Computing Machinery},
	author = {Nguyen, Tien T. and Hui, Pik-Mai and Harper, F. Maxwell and Terveen, Loren and Konstan, Joseph A.},
	month = apr,
	year = {2014},
	keywords = {Recommender Systems, Filter Bubble, Content Diversity},
	pages = {677--686},
}

@techreport{bright_explaining_2017,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Explaining the {Emergence} of {Echo} {Chambers} on {Social} {Media}: {The} {Role} of {Ideology} and {Extremism}},
	shorttitle = {Explaining the {Emergence} of {Echo} {Chambers} on {Social} {Media}},
	url = {https://papers.ssrn.com/abstract=2839728},
	abstract = {The emergence of politically driven divisions in online discussion networks has attracted a wealth of literature, but also one which has thus far been largely limited to single country studies. Hence whilst there is good evidence that these networks do divide and fragment into what are often described as "echo chambers", we know little about the factors which might explain this division or make networks more or less fragmented, as studies have been limited to a small number of political groupings with limited possibilities for systematic comparison.},
	language = {en},
	number = {ID 2839728},
	urldate = {2020-10-29},
	institution = {Social Science Research Network},
	author = {Bright, Jonathan},
	month = mar,
	year = {2017},
	doi = {10.2139/ssrn.2839728},
}

@article{zhao_bounded_2016,
	title = {Bounded confidence opinion dynamics with opinion leaders and environmental noises},
	volume = {74},
	issn = {0305-0548},
	url = {http://www.sciencedirect.com/science/article/pii/S030505481500204X},
	doi = {10.1016/j.cor.2015.07.022},
	abstract = {Opinion dynamics is a kind of collective decision-making process and focuses on the study of evolution and formation of opinions within a human society. Particularly, bounded confidence rule is one of intrinsic interaction principles in the opinion dynamics. In this paper, a leader–follower opinion dynamics model is built, with the help of the bounded confidence rule, to consider the opinion formation of a community, which is constituted of opinion leaders and opinion followers. At the same time, environmental uncertainties are considered in the opinion formation and called as environmental noises, which are modeled as Gaussian stochastic processes. All the agents are assumed to have heterogeneous confidence levels. Then the impacts of the opinion leaders and the environmental noises on the final opinions of the opinion followers are analyzed. Finally, some simulation results are presented to demonstrate the collective opinion evolution in three cases: no opinion leader, single opinion leader and multiple opinion leaders.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Computers \& Operations Research},
	author = {Zhao, Yiyi and Zhang, Libin and Tang, Mingfeng and Kou, Gang},
	month = oct,
	year = {2016},
	keywords = {Opinion Dynamics, Bounded Confidence},
	pages = {205--213},
}

@article{fu_opinion_2015,
	title = {Opinion dynamics of modified {Hegselmann}–{Krause} model in a group-based population with heterogeneous bounded confidence},
	volume = {419},
	issn = {0378-4371},
	url = {http://www.sciencedirect.com/science/article/pii/S0378437114008838},
	doi = {10.1016/j.physa.2014.10.045},
	abstract = {Continuous opinion dynamics in a group-based population with heterogeneous bounded confidences is considered in this paper. A slightly modified Hegselmann–Krause model is proposed, and agents are classified into three categories: open-minded-, moderate-minded-, and closed-minded-agents, while the whole population is divided into three subgroups accordingly. We study how agents of each category and the population size can affect opinion dynamics. It is observed that the number of final opinion clusters is dominated by the closed-minded agents; open-minded agents cannot contribute to forming opinion consensus and the existence of open-minded agents may diversify the final opinions instead; for the fixed population size and proportion of closed-minded agents, the relative size of the largest final opinion cluster varies along concave-parabola-like curve as the proportion of open-minded agents increases, and there is a tipping point when the number of open-minded agents is almost equal to that of moderate-minded agents; for the fixed proportion of the three categories in the population, as the population size becomes larger, the number of final opinion clusters will reach a plateau. Some of the results are different from the previous studies.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Fu, Guiyuan and Zhang, Weidong and Li, Zhijun},
	month = feb,
	year = {2015},
	keywords = {Model, Opinion Dynamics, Bounded Confidence},
	pages = {558--565},
}

@article{kunaver_diversity_2017,
	title = {Diversity in recommender systems – {A} survey},
	volume = {123},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705117300680},
	doi = {10.1016/j.knosys.2017.02.009},
	abstract = {Diversification has become one of the leading topics of recommender system research not only as a way to solve the over-fitting problem but also an approach to increasing the quality of the user’s experience with the recommender system. This article aims to provide an overview of research done on this topic from one of the first mentions of diversity in 2001 until now. The articles ,and research, have been divided into three sub-topics for a better overview of the work done in the field of recommendation diversification: the definition and evaluation of diversity; the impact of diversification on the quality of recommendation results and the development of diversification algorithms themselves. In this way, the article aims both to offer a good overview to a researcher looking for the state-of-the-art on this topic and to help a new developer get familiar with the topic.},
	language = {en},
	urldate = {2020-10-29},
	journal = {Knowledge-Based Systems},
	author = {Kunaver, Matevž and Požrl, Tomaž},
	month = may,
	year = {2017},
	keywords = {Recommender Systems, Survey, Personalization},
	pages = {154--162},
	file = {Kunaver and Požrl - 2017 - Diversity in recommender systems – A survey.pdf:/Users/clente/Zotero/storage/ELL2HDJF/Kunaver and Požrl - 2017 - Diversity in recommender systems – A survey.pdf:application/pdf},
}

@article{lengyel_geographies_2015,
	title = {Geographies of an {Online} {Social} {Network}},
	volume = {10},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0137248},
	doi = {10.1371/journal.pone.0137248},
	abstract = {How is online social media activity structured in the geographical space? Recent studies have shown that in spite of earlier visions about the “death of distance”, physical proximity is still a major factor in social tie formation and maintenance in virtual social networks. Yet, it is unclear, what are the characteristics of the distance dependence in online social networks. In order to explore this issue the complete network of the former major Hungarian online social network is analyzed. We find that the distance dependence is weaker for the online social network ties than what was found earlier for phone communication networks. For a further analysis we introduced a coarser granularity: We identified the settlements with the nodes of a network and assigned two kinds of weights to the links between them. When the weights are proportional to the number of contacts we observed weakly formed, but spatially based modules resemble to the borders of macro-regions, the highest level of regional administration in the country. If the weights are defined relative to an uncorrelated null model, the next level of administrative regions, counties are reflected.},
	language = {en},
	number = {9},
	urldate = {2020-10-29},
	journal = {PLOS ONE},
	author = {Lengyel, Balázs and Varga, Attila and Ságvári, Bence and Jakobi, Ákos and Kertész, János},
	month = sep,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Social Networks, Community Detection},
	pages = {e0137248},
}

@incollection{aggarwal_introduction_2011,
	address = {Boston, MA},
	title = {An {Introduction} to {Social} {Network} {Data} {Analytics}},
	isbn = {978-1-4419-8462-3},
	url = {https://doi.org/10.1007/978-1-4419-8462-3_1},
	abstract = {The advent of online social networks has been one of the most exciting events in this decade. Many popular online social networks such as Twitter, LinkedIn, and Facebook have become increasingly popular. In addition, a number of multimedia networks such as Flickr have also seen an increasing level of popularity in recent years. Many such social networks are extremely rich in content, and they typically contain a tremendous amount of content and linkage data which can be leveraged for analysis. The linkage data is essentially the graph structure of the social network and the communications between entities; whereas the content data contains the text, images and other multimedia data in the network. The richness of this network provides unprecedented opportunities for data analytics in the context of social networks. This book provides a data-centric view of online social networks; a topic which has been missing from much of the literature. This chapter provides an overview of the key topics in this field, and their coverage in this book.},
	language = {en},
	urldate = {2020-10-29},
	booktitle = {Social {Network} {Data} {Analytics}},
	publisher = {Springer US},
	author = {Aggarwal, Charu C.},
	editor = {Aggarwal, Charu C.},
	year = {2011},
	doi = {10.1007/978-1-4419-8462-3_1},
	keywords = {Social Networks},
	pages = {1--15},
}

@inproceedings{guy_social_2010,
	address = {New York, NY, USA},
	series = {{SIGIR} '10},
	title = {Social media recommendation based on people and tags},
	isbn = {978-1-4503-0153-4},
	url = {https://doi.org/10.1145/1835449.1835484},
	doi = {10.1145/1835449.1835484},
	abstract = {We study personalized item recommendation within an enterprise social media application suite that includes blogs, bookmarks, communities, wikis, and shared files. Recommendations are based on two of the core elements of social media - people and tags. Relationship information among people, tags, and items, is collected and aggregated across different sources within the enterprise. Based on these aggregated relationships, the system recommends items related to people and tags that are related to the user. Each recommended item is accompanied by an explanation that includes the people and tags that led to its recommendation, as well as their relationships with the user and the item. We evaluated our recommender system through an extensive user study. Results show a significantly better interest ratio for the tag-based recommender than for the people-based recommender, and an even better performance for a combined recommender. Tags applied on the user by other people are found to be highly effective in representing that user's topics of interest.},
	urldate = {2020-10-29},
	booktitle = {Proceedings of the 33rd international {ACM} {SIGIR} conference on {Research} and development in information retrieval},
	publisher = {Association for Computing Machinery},
	author = {Guy, Ido and Zwerdling, Naama and Ronen, Inbal and Carmel, David and Uziel, Erel},
	month = jul,
	year = {2010},
	keywords = {Social Networks, Recommender Systems, Personalization, Collaborative Filtering},
	pages = {194--201},
	file = {Guy et al. - 2010 - Social media recommendation based on people and ta.pdf:/Users/clente/Zotero/storage/8GCVUT57/Guy et al. - 2010 - Social media recommendation based on people and ta.pdf:application/pdf},
}

@article{min_endogenetic_nodate,
	title = {Endogenetic structure of filter bubble in social networks},
	volume = {6},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.190868},
	doi = {10.1098/rsos.190868},
	abstract = {The filter bubble is an intermediate structure to provoke polarization and echo chambers in social networks, and it has become one of today's most urgent issues for social media. Previous studies usually equated filter bubbles with community structures and emphasized this exogenous isolation effect, but there is a lack of full discussion of the internal organization of filter bubbles. Here, we design an experiment for analysing filter bubbles taking advantage of social bots. We deployed 128 bots to Weibo (the largest microblogging network in China), and each bot consumed a specific topic (entertainment or sci-tech) and ran for at least two months. In total, we recorded about 1.3 million messages exposed to these bots and their social networks. By analysing the text received by the bots and motifs in their social networks, we found that a filter bubble is not only a dense community of users with the same preferences but also presents an endogenetic unidirectional star-like structure. The structure could spontaneously exclude non-preferred information and cause polarization. Moreover, our work proved that the felicitous use of artificial intelligence technology could provide a useful experimental approach that combines privacy protection and controllability in studying social media.},
	number = {11},
	urldate = {2021-08-09},
	journal = {Royal Society Open Science},
	author = {Min, Yong and Jiang, Tingjun and Jin, Cheng and Li, Qu and Jin, Xiaogang},
	note = {Publisher: Royal Society},
	keywords = {Social Networks, Filter Bubble},
	pages = {190868},
}

@article{geschke_triple-filter_2019,
	title = {The triple-filter bubble: {Using} agent-based modelling to test a meta-theoretical framework for the emergence of filter bubbles and echo chambers},
	volume = {58},
	issn = {2044-8309},
	shorttitle = {The triple-filter bubble},
	url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/bjso.12286},
	doi = {10.1111/bjso.12286},
	abstract = {Filter bubbles and echo chambers have both been linked recently by commentators to rapid societal changes such as Brexit and the polarization of the US American society in the course of Donald Trump's election campaign. We hypothesize that information filtering processes take place on the individual, the social, and the technological levels (triple-filter-bubble framework). We constructed an agent-based modelling (ABM) and analysed twelve different information filtering scenarios to answer the question under which circumstances social media and recommender algorithms contribute to fragmentation of modern society into distinct echo chambers. Simulations show that, even without any social or technological filters, echo chambers emerge as a consequence of cognitive mechanisms, such as confirmation bias, under conditions of central information propagation through channels reaching a large part of the population. When social and technological filtering mechanisms are added to the model, polarization of society into even more distinct and less interconnected echo chambers is observed. Merits and limits of the theoretical framework, and more generally of studying complex social phenomena using ABM, are discussed. Directions for future research such as ways of comparing our simulations with actual empirical data and possible measures against societal fragmentation on the three different levels are suggested.},
	language = {en},
	number = {1},
	urldate = {2021-08-09},
	journal = {British Journal of Social Psychology},
	author = {Geschke, Daniel and Lorenz, Jan and Holtz, Peter},
	year = {2019},
	note = {\_eprint: https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/bjso.12286},
	keywords = {Social Networks, Model, Filter Bubble},
	pages = {129--149},
}

@article{helberger_exposure_2018,
	title = {Exposure diversity as a design principle for recommender systems},
	volume = {21},
	issn = {1369-118X},
	url = {https://doi.org/10.1080/1369118X.2016.1271900},
	doi = {10.1080/1369118X.2016.1271900},
	abstract = {Personalized recommendations in search engines, social media and also in more traditional media increasingly raise concerns over potentially negative consequences for diversity and the quality of public discourse. The algorithmic filtering and adaption of online content to personal preferences and interests is often associated with a decrease in the diversity of information to which users are exposed. Notwithstanding the question of whether these claims are correct or not, this article discusses whether and how recommendations can also be designed to stimulate more diverse exposure to information and to break potential ‘filter bubbles’ rather than create them. Combining insights from democratic theory, computer science and law, the article makes suggestions for design principles and explores the potential and possible limits of ‘diversity sensitive design’.},
	number = {2},
	urldate = {2021-08-09},
	journal = {Information, Communication \& Society},
	author = {Helberger, Natali and Karppinen, Kari and D’Acunto, Lucia},
	month = feb,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1369118X.2016.1271900},
	keywords = {Bias, Recommender Systems},
	pages = {191--207},
}

@inproceedings{bountouridis_siren_2019,
	address = {New York, NY, USA},
	series = {{FAT}* '19},
	title = {{SIREN}: {A} {Simulation} {Framework} for {Understanding} the {Effects} of {Recommender} {Systems} in {Online} {News} {Environments}},
	isbn = {978-1-4503-6125-5},
	shorttitle = {{SIREN}},
	url = {https://doi.org/10.1145/3287560.3287583},
	doi = {10.1145/3287560.3287583},
	abstract = {The growing volume of digital data stimulates the adoption of recommender systems in different socioeconomic domains, including news industries. While news recommenders help consumers deal with information overload and increase their engagement, their use also raises an increasing number of societal concerns, such as "Matthew effects", "filter bubbles", and the overall lack of transparency. We argue that focusing on transparency for content-providers is an under-explored avenue. As such, we designed a simulation framework called SIREN1 (SImulating Recommender Effects in online News environments), that allows content providers to (i) select and parameterize different recommenders and (ii) analyze and visualize their effects with respect to two diversity metrics. Taking the U.S. news media as a case study, we present an analysis on the recommender effects with respect to long-tail novelty and unexpectedness using SIREN. Our analysis offers a number of interesting findings, such as the similar potential of certain algorithmically simple (item-based k-Nearest Neighbour) and sophisticated strategies (based on Bayesian Personalized Ranking) to increase diversity over time. Overall, we argue that simulating the effects of recommender systems can help content providers to make more informed decisions when choosing algorithmic recommenders, and as such can help mitigate the aforementioned societal concerns.},
	urldate = {2021-08-08},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Bountouridis, Dimitrios and Harambam, Jaron and Makhortykh, Mykola and Marrero, Mónica and Tintarev, Nava and Hauff, Claudia},
	month = jan,
	year = {2019},
	keywords = {Bias, Model, Recommender Systems},
	pages = {150--159},
}

@misc{timmer_if_2021,
	title = {If {YouTube}’s algorithms radicalize people, it’s hard to tell from the data},
	url = {https://arstechnica.com/science/2021/08/if-youtubes-algorithms-radicalize-people-its-hard-to-tell-from-the-data/},
	abstract = {Tracking user behavior shows that most people don't go down radical rabbit holes.},
	language = {en-us},
	urldate = {2021-08-09},
	journal = {Ars Technica},
	author = {Timmer, John},
	month = aug,
	year = {2021},
}

@misc{noauthor_facebook_nodate,
	title = {Facebook {Got} {Rid} of {Racial} {Ad} {Categories}. {Or} {Did} {It}? – {The} {Markup}},
	shorttitle = {Facebook {Got} {Rid} of {Racial} {Ad} {Categories}. {Or} {Did} {It}?},
	url = {https://themarkup.org/citizen-browser/2021/07/09/facebook-got-rid-of-racial-ad-categories-or-did-it},
	abstract = {Our Citizen Browser project found an array of proxies through which advertisers can target Black Facebook users, among other demographics},
	language = {en},
	urldate = {2021-08-09},
	note = {Section: Citizen Browser},
}

@article{simonite_new_nodate,
	title = {A {New} {Tool} {Shows} {How} {Google} {Results} {Vary} {Around} the {World}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/tool-shows-google-results-vary-world/},
	abstract = {Search Atlas displays three sets of links—or images—from different countries for any search.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wired},
	author = {Simonite, Tom},
	note = {Section: tags},
}

@misc{noauthor_science_2021,
	title = {Science denial, partisanship on social media indicate where {COVID}-19 strikes next},
	url = {https://pressroom.usc.edu/science-denial-partisanship-on-social-media-indicate-where-covid-19-strikes-next/},
	abstract = {USC researchers found political discourse on Twitter helped predict where the next COVID-19 outbreaks could occur, offering a new tool for health officials to thwart pandemic. Contact: Gary Polakovic at uscnews@usc.edu or polakovi@usc.edu In the realm of social media, anti-science views about COVID-19 align so closely with political ideology — especially among conservatives — that its predictability offers […]},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Press Room},
	month = jun,
	year = {2021},
}

@misc{noauthor_after_nodate,
	title = {After {Repeatedly} {Promising} {Not} to, {Facebook} {Keeps} {Recommending} {Political} {Groups} to {Its} {Users} – {The} {Markup}},
	url = {https://themarkup.org/citizen-browser/2021/06/24/after-repeatedly-promising-not-to-facebook-keeps-recommending-political-groups-to-its-users},
	abstract = {The company announced the policy as a way to stop spreading divisive content},
	language = {en},
	urldate = {2021-08-09},
	note = {Section: Citizen Browser},
}

@article{ovide_facebook_2021,
	chapter = {Technology},
	title = {Facebook {Takes} on {Superspreaders}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2021/05/28/technology/facebook-superspreaders-misinformation.html},
	abstract = {Internet companies are making it harder for those with big followings to spread misinformation. Finally!},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {The New York Times},
	author = {Ovide, Shira},
	month = may,
	year = {2021},
}

@misc{the_royal_institution_there_nodate,
	title = {There is {No} {Algorithm} for {Truth} - with {Tom} {Scott}},
	url = {https://www.youtube.com/watch?v=leX541Dr2rU},
	abstract = {How does science get communicated in an age of social media?
Subscribe for regular science videos: http://bit.ly/RiSubscRibe
Watch all of Tom's videos on his channel - https://youtube.com/TomScottGo

In this Discourse, Tom Scott talks about science communication in the age of social media, how to be popular on the internet, and dealing with a world where view counts are often more important than truth.

Watch the Q\&A: https://youtu.be/ZIv4tqJNuxs

Tom Scott is a British entertainer, educator, YouTuber, web developer and former presenter of 'Gadget Geeks' on Sky One. He graduated from the University of York with a degree in linguistics. He has a popular YouTube channel with over 1.6 million subscribers and more than 325 million video views as of June 2019.

In more than fifteen years of publishing on the internet, Tom has visited the High Arctic, passed out in a centrifuge, and somehow got three million people to watch a video about why the British plug is a great invention.

This talk and Q\&A was filmed in the Ri on 27 September 2019.

---
A very special thank you to our Patreon supporters who help make these videos happen, especially:
Andrew McGhee, Dave Ostler, David Lindo, David Schick, Erik Shepherd, Greg Nagel, Jan Bannister, Joe Godenzi, John C. Vesey, Kellas Lowery, Lasse T. Stendan, Lester Su, Osian Gwyn Williams, Paul Brown, Radu Tizu, Rebecca Pan, Robert Hillier, Robert Reinecke and Roger Baker.
---

The Ri is on Patreon: https://www.patreon.com/TheRoyalInsti...
and Twitter: http://twitter.com/ri\_science
and Facebook: http://www.facebook.com/royalinstitution
and Tumblr: http://ri-science.tumblr.com/
Our editorial policy: http://www.rigb.org/home/editorial-po...
Subscribe for the latest science videos: http://bit.ly/RiNewsletter},
	urldate = {2021-08-09},
	author = {{The Royal Institution}},
}

@misc{noauthor_facebook_nodate-1,
	title = {Facebook {Said} {It} {Would} {Stop} {Recommending} {Anti}-{Vaccine} {Groups}. {It} {Didn}’t – {The} {Markup}},
	url = {https://themarkup.org/citizen-browser/2021/05/20/facebook-said-it-would-stop-recommending-anti-vaccine-groups-it-didnt},
	abstract = {As COVID-19 surged, the social media company pointed users to all sorts of anti-vaccine and anti-mask groups},
	language = {en},
	urldate = {2021-08-09},
	note = {Section: Citizen Browser},
}

@article{fussell_facebook_nodate,
	title = {Facebook {Allows} {Drug} {Ads} to {Target} {Teens}, {Activists} {Say}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/activists-facebook-allows-drug-ads-target-teens/},
	abstract = {The social network has rules about what can be shown to minors. The Tech Transparency Project found that they aren’t being enforced.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wired},
	author = {Fussell, Sidney},
	note = {Section: tags},
}

@misc{noauthor_alise_2021,
	title = {Análise: {Após} {Facebook} manter veto a {Trump}, fica a pergunta: e {Bolsonaro}?},
	shorttitle = {Análise},
	url = {https://www1.folha.uol.com.br/mundo/2021/05/apos-facebook-manter-veto-a-trump-fica-a-pergunta-e-bolsonaro.shtml},
	abstract = {Presidente brasileiro violou regras da rede social para posts sobre Covid ao menos 29 vezes e não foi punido},
	language = {pt-BR},
	urldate = {2021-08-09},
	journal = {Folha de S.Paulo},
	month = may,
	year = {2021},
	note = {Section: Mundo},
}

@misc{ribeiro_como_2021,
	title = {Como a extrema direita burla punições do {YouTube} – e o {Google} finge que não vê},
	url = {https://theintercept.com/2021/04/19/como-a-extrema-direita-burla-punicoes-do-youtube-e-o-google-finge-que-nao-ve/},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {The Intercept},
	author = {Ribeiro, Paulo Victor},
	month = apr,
	year = {2021},
}

@misc{noauthor_shadow_nodate,
	title = {Shadow {Bans}, {Dopamine} {Hits}, and {Viral} {Videos}, {All} in the {Life} of {TikTok} {Creators} – {The} {Markup}},
	url = {https://themarkup.org/working-for-an-algorithm/2021/04/22/shadow-bans-dopamine-hits-and-viral-videos-all-in-the-life-of-tiktok-creators},
	abstract = {A secretive algorithm that’s constantly being tweaked can turn influencers’ accounts, and their prospects, upside down},
	language = {en},
	urldate = {2021-08-09},
	note = {Section: Working for an Algorithm},
}

@misc{guynn_is_nodate,
	title = {Is {Amazon} recommending books on {QAnon} and white nationalism? {Browsing} books can lead to extremist rabbit hole},
	shorttitle = {Is {Amazon} recommending books on {QAnon} and white nationalism?},
	url = {https://www.usatoday.com/story/tech/2021/04/29/amazon-books-conspiracy-theories-white-nationalism-qanon-recommendation-algorithms/4878894001/},
	abstract = {Amazon recommends QAnon conspiracy theories, vaccine disinformation and white nationalism to people browsing extremist books, new report says.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {USA TODAY},
	author = {Guynn, Jessica},
}

@article{wong_how_2021,
	chapter = {Technology},
	title = {How {Facebook} let fake engagement distort global politics: a whistleblower's account},
	issn = {0261-3077},
	shorttitle = {How {Facebook} let fake engagement distort global politics},
	url = {https://www.theguardian.com/technology/2021/apr/12/facebook-fake-engagement-whistleblower-sophie-zhang},
	abstract = {The inside story of Sophie Zhang’s battle to combat rampant manipulation as executives delayed and deflected},
	language = {en-GB},
	urldate = {2021-08-09},
	journal = {The Guardian},
	author = {Wong, Julia Carrie},
	month = apr,
	year = {2021},
}

@article{hagey_googles_2021,
	chapter = {Tech},
	title = {Google’s {Secret} ‘{Project} {Bernanke}’ {Revealed} in {Texas} {Antitrust} {Case}},
	issn = {0099-9660},
	url = {https://www.wsj.com/articles/googles-secret-project-bernanke-revealed-in-texas-antitrust-case-11618097760},
	abstract = {The program used past bid data to boost the tech company’s win rate in advertising auctions, according to a court filing.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wall Street Journal},
	author = {Hagey, Jeff Horwitz {and} Keach},
	month = apr,
	year = {2021},
}

@misc{noauthor_facebook_nodate-2,
	title = {Facebook {Algorithm} {Shows} {Gender} {Bias} in {Job} {Ads}, {Study} {Finds} - {WSJ}},
	url = {https://www.wsj.com/articles/facebook-shows-men-and-women-different-job-ads-study-finds-11617969600},
	urldate = {2021-08-09},
}

@misc{welle_wwwdwcom_como_nodate,
	title = {Como o {Google} contribui para perpetuar estereótipos sexistas {\textbar} {DW} {\textbar} 08.03.2021},
	url = {https://www.dw.com/pt-br/como-o-google-contribui-para-perpetuar-estere%C3%B3tipos-sexistas/a-56789034},
	abstract = {A julgar por buscador de imagens, brasileiras são sexy e exibicionistas, e ucranianas estão loucas para se casar. Levantamento da DW mostra como a ferramenta reproduz clichês sobre mulheres de certas nacionalidades.},
	language = {pt\_BR},
	urldate = {2021-08-09},
	journal = {DW.COM},
	author = {Welle (www.dw.com), Deutsche},
}

@misc{noauthor_youtube_2021,
	title = {{YouTube} ficará infestado de violações se não for possível punir quem burla diretrizes, diz advogado},
	url = {https://www1.folha.uol.com.br/mundo/2021/04/youtube-ficara-infestado-de-violacoes-se-nao-for-possivel-punir-quem-burla-diretrizes-diz-advogado.shtml},
	abstract = {Guilherme Sanchez, responsável por questões jurídicas da plataforma, nega censura a canal bolsonarista},
	language = {pt-BR},
	urldate = {2021-08-09},
	journal = {Folha de S.Paulo},
	month = apr,
	year = {2021},
	note = {Section: Mundo},
}

@article{goode_i_nodate,
	title = {I {Called} {Off} {My} {Wedding}. {The} {Internet} {Will} {Never} {Forget}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/weddings-social-media-apps-photos-memories-miscarriage-problem/},
	abstract = {In 2019, I made a painful decision. But to the algorithms that drive Facebook, Pinterest, and a million other apps, I'm forever getting married.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wired},
	author = {Goode, Lauren},
	note = {Section: tags},
}

@misc{noauthor_google_nodate,
	title = {Google {Has} a {Secret} {Blocklist} that {Hides} {YouTube} {Hate} {Videos} from {Advertisers}—{But} {It}’s {Full} of {Holes} – {The} {Markup}},
	url = {https://themarkup.org/google-the-giant/2021/04/08/google-youtube-hate-videos-ad-keywords-blocklist-failures},
	abstract = {Many well-known White supremacist and White nationalist terms and slogans were not blocked},
	language = {en},
	urldate = {2021-08-09},
	note = {Section: Google the Giant},
}

@misc{noauthor_google_nodate-1,
	title = {Google {Blocks} {Advertisers} from {Targeting} {Black} {Lives} {Matter} {YouTube} {Videos} – {The} {Markup}},
	url = {https://themarkup.org/google-the-giant/2021/04/09/google-blocks-advertisers-from-targeting-black-lives-matter-youtube-videos},
	abstract = {“Black power” and “Black Lives Matter” can't be used to find videos for ads, but “White power” and “White lives matter” were just fine},
	language = {en},
	urldate = {2021-08-09},
	note = {Section: Google the Giant},
}

@misc{noauthor_how_nodate,
	title = {How {Facebook} got addicted to spreading misinformation},
	url = {https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/},
	abstract = {The company’s AI algorithms gave it an insatiable habit for lies and hate speech. Now the man who built them can't fix the problem.},
	language = {en},
	urldate = {2021-08-09},
	journal = {MIT Technology Review},
}

@article{diresta_how_nodate,
	title = {How to {Stop} {Misinformation} {Before} {It} {Gets} {Shared}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/how-to-stop-misinformation-before-it-gets-shared/},
	abstract = {It's never been easier for mistruths to go viral, and content moderation is inadequate. What social media needs is some old-fashioned friction.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wired},
	author = {DiResta, Renee},
	note = {Section: tags},
}

@misc{noauthor_relatorio_2021,
	title = {Relatório acusa {Facebook} de permitir desinformação durante eleição nos {EUA}},
	url = {https://www1.folha.uol.com.br/mundo/2021/03/relatorio-acusa-facebook-de-permitir-desinformacao-durante-eleicao-nos-eua.shtml},
	abstract = {Empresa diz ter agido para coibir compartilhamento de fake news, mas entidade aponta demora em tomar providências},
	language = {pt-BR},
	urldate = {2021-08-09},
	journal = {Folha de S.Paulo},
	month = mar,
	year = {2021},
	note = {Section: Mundo},
}

@article{technica_negligence_nodate,
	title = {Negligence, {Not} {Politics}, {Drives} {Most} {Misinformation} {Sharing}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/negligence-most-misinformation-sharing/},
	abstract = {Researchers found that social media users are generally adept at identifying fake news. But that doesn’t always affect their decision to repost it.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wired},
	author = {Technica, Ars, John Timmer},
	note = {Section: tags},
}

@article{danastasio_blood_nodate,
	title = {Blood, {Poop}, and {Violence}: {YouTube} {Has} a {Creepy} {Minecraft} {Problem}},
	issn = {1059-1028},
	shorttitle = {Blood, {Poop}, and {Violence}},
	url = {https://www.wired.com/story/youtube-minecraft-among-us-disturbing-videos/},
	abstract = {A WIRED investigation has found dozens of kid-focused videos with disturbing thumbnails that the platform serves up on the Topic pages of popular games.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wired},
	author = {D'Anastasio, Cecilia},
	note = {Section: tags},
}

@article{hickey_tiktok_nodate,
	title = {{TikTok} {Played} a {Key} {Role} in {MAGA} {Radicalization}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/opinion-tiktok-played-a-key-role-in-maga-radicalization/},
	abstract = {The platform's absorbing endless scroll and karaoke features have built an overlooked disinformation machine.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wired},
	author = {Hickey, Cameron},
	note = {Section: tags},
}

@article{edelman_fake_nodate,
	title = {Fake {News} {Gets} {More} {Engagement} on {Facebook}—{But} {Only} {If} {It}'s {Right}-{Wing}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/right-wing-fake-news-more-engagement-facebook/},
	abstract = {Far-right pages that publish misinformation get the most interactions by far compared to other news sources, new research shows.},
	language = {en-US},
	urldate = {2021-08-09},
	journal = {Wired},
	author = {Edelman, Gilad},
	note = {Section: tags},
}

@misc{offentlichkeitsarbeit_information_nodate,
	title = {Information for the {Media} - {Georg}-{August}-{Universität} {Göttingen}},
	url = {https://www.uni-goettingen.de/en/3240.html?id=6154},
	abstract = {Webseiten der Georg-August-Universität Göttingen},
	language = {de},
	urldate = {2021-08-09},
	author = {Öffentlichkeitsarbeit, Georg-August-Universität Göttingen-},
}

@misc{noauthor_can_nodate,
	title = {Can {Auditing} {Eliminate} {Bias} from {Algorithms}? – {The} {Markup}},
	shorttitle = {Can {Auditing} {Eliminate} {Bias} from {Algorithms}?},
	url = {https://themarkup.org/ask-the-markup/2021/02/23/can-auditing-eliminate-bias-from-algorithms},
	abstract = {A growing industry wants to scrutinize the algorithms that govern our lives—but it needs teeth},
	language = {en},
	urldate = {2021-08-09},
	note = {Section: Ask The Markup},
}

@misc{savage_fact-finding_nodate,
	title = {Fact-{Finding} {Mission}},
	url = {https://cacm.acm.org/magazines/2021/3/250696-fact-finding-mission/fulltext},
	abstract = {Artificial intelligence provides automatic fact-checking and fake news detection, but with limits.},
	language = {en},
	urldate = {2021-08-09},
	author = {Savage, Neil},
}

@misc{le_nguyen_hoang_science4all_stats_2021,
	type = {Tweet},
	title = {The stats of my {French} video that criticizes {Google}'s ethics seem suspicious to me. {Having} {\textgreater}10\% of views from external sources is extremely unusual, as more views should also trigger by more recommendations by the {YouTube} algorithm. {Did} {Google} manually dis-recommend the video?},
	url = {https://mobile.twitter.com/le_science4all/status/1367364299182776321},
	language = {en},
	urldate = {2021-08-09},
	journal = {@le\_science4all},
	author = {{Lê Nguyên Hoang (Science4All)}},
	month = mar,
	year = {2021},
}

@inproceedings{sun_are_2020,
	address = {New York, NY, USA},
	series = {{RecSys} '20},
	title = {Are {We} {Evaluating} {Rigorously}? {Benchmarking} {Recommendation} for {Reproducible} {Evaluation} and {Fair} {Comparison}},
	isbn = {978-1-4503-7583-2},
	shorttitle = {Are {We} {Evaluating} {Rigorously}?},
	url = {https://doi.org/10.1145/3383313.3412489},
	doi = {10.1145/3383313.3412489},
	abstract = {With tremendous amount of recommendation algorithms proposed every year, one critical issue has attracted a considerable amount of attention: there are no effective benchmarks for evaluation, which leads to two major concerns, i.e., unreproducible evaluation and unfair comparison. This paper aims to conduct rigorous (i.e., reproducible and fair) evaluation for implicit-feedback based top-N recommendation algorithms. We first systematically review 85 recommendation papers published at eight top-tier conferences (e.g., RecSys, SIGIR) to summarize important evaluation factors, e.g., data splitting and parameter tuning strategies, etc. Through a holistic empirical study, the impacts of different factors on recommendation performance are then analyzed in-depth. Following that, we create benchmarks with standardized procedures and provide the performance of seven well-tuned state-of-the-arts across six metrics on six widely-used datasets as a reference for later study. Additionally, we release a user-friendly Python toolkit, which differs from existing ones in addressing the broad scope of rigorous evaluation for recommendation. Overall, our work sheds light on the issues in recommendation evaluation and lays the foundation for further investigation. Our code and datasets are available at GitHub (https://github.com/AmazingDD/daisyRec).},
	urldate = {2021-08-09},
	booktitle = {Fourteenth {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Sun, Zhu and Yu, Di and Fang, Hui and Yang, Jie and Qu, Xinghua and Zhang, Jie and Geng, Cong},
	month = sep,
	year = {2020},
	keywords = {Recommender Systems, Benchmarks, Reproducible Evaluation},
	pages = {23--32},
	file = {Sun et al. - 2020 - Are We Evaluating Rigorously Benchmarking Recomme.pdf:/Users/clente/Zotero/storage/H539R7IS/Sun et al. - 2020 - Are We Evaluating Rigorously Benchmarking Recomme.pdf:application/pdf},
}

@article{edelman_facebook_nodate,
	title = {Facebook {Quietly} {Makes} a {Big} {Admission}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/facebook-quietly-makes-big-admission-political-content/},
	abstract = {The company’s new approach to political content acknowledges that engagement isn’t always the best way to measure what users value.},
	language = {en-US},
	urldate = {2021-09-04},
	journal = {Wired},
	author = {Edelman, Gilad},
	note = {Section: tags},
	keywords = {Social Networks, Recommender Systems},
}

@article{huszar_algorithmic_2021,
	title = {Algorithmic {Amplification} of {Politics} on {Twitter}},
	url = {http://arxiv.org/abs/2110.11010},
	abstract = {Content on Twitter's home timeline is selected and ordered by personalization algorithms. By consistently ranking certain content higher, these algorithms may amplify some messages while reducing the visibility of others. There's been intense public and scholarly debate about the possibility that some political groups benefit more from algorithmic amplification than others. We provide quantitative evidence from a long-running, massive-scale randomized experiment on the Twitter platform that committed a randomized control group including nearly 2M daily active accounts to a reverse-chronological content feed free of algorithmic personalization. We present two sets of findings. First, we studied Tweets by elected legislators from major political parties in 7 countries. Our results reveal a remarkably consistent trend: In 6 out of 7 countries studied, the mainstream political right enjoys higher algorithmic amplification than the mainstream political left. Consistent with this overall trend, our second set of findings studying the U.S. media landscape revealed that algorithmic amplification favours right-leaning news sources. We further looked at whether algorithms amplify far-left and far-right political groups more than moderate ones: contrary to prevailing public belief, we did not find evidence to support this hypothesis. We hope our findings will contribute to an evidence-based debate on the role personalization algorithms play in shaping political content consumption.},
	urldate = {2021-11-09},
	journal = {arXiv:2110.11010 [cs]},
	author = {Huszár, Ferenc and Ktena, Sofia Ira and O'Brien, Conor and Belli, Luca and Schlaikjer, Andrew and Hardt, Moritz},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.11010},
	keywords = {Social Networks, Bias, Recommender Systems, Polarization},
	file = {Huszár et al. - 2021 - Algorithmic Amplification of Politics on Twitter.pdf:/Users/clente/Zotero/storage/N42AI6WE/Huszár et al. - 2021 - Algorithmic Amplification of Politics on Twitter.pdf:application/pdf},
}

@misc{faife_facebook_nodate,
	title = {Facebook {Isn}’t {Telling} {You} {How} {Popular} {Right}-{Wing} {Content} {Is} on the {Platform} – {The} {Markup}},
	url = {https://themarkup.org/citizen-browser/2021/11/18/facebook-isnt-telling-you-how-popular-right-wing-content-is-on-the-platform},
	abstract = {Facebook insists that mainstream news sites perform the best on its platform. But by other measures, sensationalist, partisan content reigns},
	language = {en},
	urldate = {2021-11-22},
	author = {Faife, Corin},
	note = {Section: Citizen Browser},
	keywords = {Social Networks, Bias, Facebook},
}

@misc{communication_artificial_2021,
	title = {Artificial intelligence favours white men under 40},
	url = {https://science.ku.dk/english/press/news/2021/artificial-intelligence-favours-white-men-under-40/},
	abstract = {Publicly available language models of the sort used for everything from Google and Siri, to insurance and legal casework systematically favour the language of young white men. At the same time, they discriminate in particular against young, non-white men. This, according to a University of Copenhagen study. According to one of the researchers, now is the time to begin training language models better – or the problem will grow.},
	language = {en},
	urldate = {2021-11-22},
	author = {Communication, SCIENCE},
	month = nov,
	year = {2021},
	note = {Publisher: University of Copenhagen},
	keywords = {Bias, Model, Homophily},
}

@misc{noauthor_no_2021,
	title = {No {Facebook}, poucos usuários concentram muito engajamento},
	url = {https://www.nucleo.jor.br/reportagem/2021-11-25-concentracao-usuarios-facebook/},
	abstract = {\#FacebookPapers mostram o que pesquisadores alertam plataforma há anos sobre tema},
	language = {pt},
	urldate = {2021-11-29},
	journal = {Núcleo Jornalismo},
	month = nov,
	year = {2021},
	keywords = {Facebook, Content Diversity},
}

@misc{silver_computer_2022,
	title = {Computer {Model} {Seeks} to {Explain} the {Spread} of {Misinformation}, and {Suggest} {Counter} {Measures}},
	url = {https://now.tufts.edu/news-releases/computer-model-seeks-explain-spread-misinformation-and-suggest-counter-measures},
	abstract = {It starts with a superspreader, and winds its way through a network of interactions, eventually leaving no one untouched. Those who have been exposed previously may experience little effect when exposed to a different variant. No, it’s not a virus. It’s the contagious spread of misinformation and disinformation— misinformation that’s fully intended to deceive. Now Tufts University researchers have come up with a computer model that remarkably mirrors the way misinformation spreads in real life.},
	language = {en},
	urldate = {2022-01-24},
	journal = {Tufts Now},
	author = {Silver, Mike},
	month = jan,
	year = {2022},
	keywords = {Social Networks, Bias, Model, Filter Bubble, Fake News},
}

@article{smith_how_2021,
	chapter = {Business},
	title = {How {TikTok} {Reads} {Your} {Mind}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2021/12/05/business/media/tiktok-algorithm.html},
	abstract = {It’s the most successful video app in the world. Our columnist has obtained an internal company document that offers a new level of detail about how the algorithm works.},
	language = {en-US},
	urldate = {2022-01-24},
	journal = {The New York Times},
	author = {Smith, Ben},
	month = dec,
	year = {2021},
	keywords = {Social Networks, Recommender Systems},
}

@misc{kullman_computing_2021,
	title = {Computing scenarios for defusing polarized politics},
	url = {https://news.asu.edu/20211207-solutions-computing-scenarios-defusing-polarized-politics},
	abstract = {Arizona State University computer scientists Stephanie Forrest and Joshua Daymude teamed with a political scientist to analyze the emergence of political polarization and explore ways to diminish its destabilizing impacts on democracy.},
	language = {en},
	urldate = {2022-01-24},
	journal = {ASU News},
	author = {Kullman, Joe},
	month = dec,
	year = {2021},
	keywords = {Social Networks, Bias, Opinion Polarization, Filter Bubble},
}

@article{cummins_creepy_nodate,
	title = {The {Creepy} {TikTok} {Algorithm} {Doesn}’t {Know} {You}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/tiktok-algorithm-mental-health-psychology/},
	abstract = {The uncanny, addictive AI has turned math into a mystical force—and flattened humanity into a series of codes.},
	language = {en-US},
	urldate = {2022-01-24},
	journal = {Wired},
	author = {Cummins, Eleanor},
	note = {Section: tags},
	keywords = {Social Networks, Recommender Systems},
}

@article{smith_former_2022,
	chapter = {Business},
	title = {A {Former} {Facebook} {Executive} {Pushes} to {Open} {Social} {Media}’s ‘{Black} {Boxes}’},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2022/01/02/business/media/crowdtangle-facebook-brandon-silverman.html},
	abstract = {The co-founder of CrowdTangle has been working with Congress on legislation to make tech companies disclose their inner workings.},
	language = {en-US},
	urldate = {2022-01-24},
	journal = {The New York Times},
	author = {Smith, Ben},
	month = jan,
	year = {2022},
	keywords = {Social Networks, Recommender Systems, Politics},
}

@misc{lecher_one_nodate,
	title = {One {Year} {After} the {Capitol} {Riot}, {Americans} {Still} {See} {Two} {Very} {Different} {Facebooks} – {The} {Markup}},
	url = {https://themarkup.org/citizen-browser/2022/01/06/one-year-after-the-capitol-riot-americans-still-see-two-very-different-facebooks},
	abstract = {Data from The Markup’s Citizen Browser shows the platform’s partisan divide continues},
	language = {en},
	urldate = {2022-01-24},
	author = {Lecher, Colin and Yin, Leon},
	note = {Section: Citizen Browser},
	keywords = {Social Networks, Bias, Recommender Systems, Politics, Polarization, Facebook},
}

@misc{noauthor_plataforma_nodate,
	title = {Plataforma web detecta fake news em português de forma automática},
	url = {https://agencia.fapesp.br/plataforma-web-detecta-ifake-news-i-em-portugues-de-forma-automatica/38004/},
	abstract = {Resultados preliminares indicam que o sistema, criado por pesquisadores ligados ao Centro de Ciências Matemáticas Aplicadas à Indústria da USP, é capaz de identificar notícias falsas com 96\% de precisão},
	language = {pt},
	urldate = {2022-03-17},
	journal = {AGÊNCIA FAPESP},
	keywords = {Social Networks},
}

@misc{noauthor_youtubes_nodate,
	title = {On {YouTube}’s recommendation system},
	url = {https://blog.youtube/inside-youtube/on-youtubes-recommendation-system/},
	abstract = {A deeper look into how YouTube’s recommendation system works.},
	language = {en-us},
	urldate = {2022-03-22},
	journal = {blog.youtube},
	keywords = {Recommender Systems, Extremism},
}

@misc{noauthor_youtube_nodate,
	title = {{YouTube} for {Press}},
	url = {https://blog.youtube/press/},
	abstract = {{\textless}p data-block-key="m0h91"{\textgreater}Quickly find the stats, photos and videos you’re looking for, along with guidelines for crediting and broadcasting them.{\textless}/p{\textgreater}{\textless}p data-block-key="qvr2q"{\textgreater}For any additional press inquiries, contact {\textless}a href="mailto:press@google.com"{\textgreater}press@google.com{\textless}/a{\textgreater}{\textless}/p{\textgreater}},
	language = {en-us},
	urldate = {2023-02-15},
	journal = {blog.youtube},
}

@inproceedings{dash_network-centric_2019,
	title = {A {Network}-centric {Framework} for {Auditing} {Recommendation} {Systems}},
	doi = {10.1109/INFOCOM.2019.8737486},
	abstract = {To improve the experience of consumers, all social media, commerce and entertainment sites deploy Recommendation Systems (RSs) that aim to help users locate interesting content. These RSs are black-boxes - the way a chunk of information is filtered out and served to a user from a large information base is mostly opaque. No one except the parent company generally has access to the entire information required for auditing these systems - neither the details of the algorithm nor the user-item interactions are ever made publicly available for third-party auditors. Hence auditing RSs remains an important challenge, especially with the recent concerns about how RSs are affecting the views of the society at large with new technical jargons like “echo chambers”, “confirmation biases”, “filter bubbles” etc. in place. Many prior works have evaluated different properties of RSs such as diversity, novelty, etc. However, most of these have focused on evaluating static snapshots of RSs. Today, auditors are not only interested in these static evaluations on a snapshot of the system, but also interested in how these systems are affecting the society in course of time. In this work, we propose a novel network-centric framework which is not only able to quantify various static properties of RSs, but also is able to quantify dynamic properties such as how likely RSs are to lead to polarization or segregation of information among their users. We apply the framework to several popular movie RSs to demonstrate its utility.},
	booktitle = {{IEEE} {INFOCOM} 2019 - {IEEE} {Conference} on {Computer} {Communications}},
	author = {Dash, Abhisek and Mukherjee, Animesh and Ghosh, Saptarshi},
	month = apr,
	year = {2019},
	note = {ISSN: 2641-9874},
	keywords = {Social Networks, Recommender Systems, Polarization, Networks},
	pages = {1990--1998},
	file = {Submitted Version:/Users/clente/Zotero/storage/WFV7IMLJ/Dash et al. - 2019 - A Network-centric Framework for Auditing Recommend.pdf:application/pdf},
}

@misc{noauthor_mozilla_2021,
	title = {Mozilla {Investigation}: {YouTube} {Algorithm} {Recommends} {Videos} that {Violate} the {Platform}’s {Very} {Own} {Policies}},
	shorttitle = {Mozilla {Investigation}},
	url = {https://foundation.mozilla.org/en/blog/mozilla-investigation-youtube-algorithm-recommends-videos-that-violate-the-platforms-very-own-policies/},
	abstract = {Conducted using data donated by thousands of YouTube users, research reveals the algorithm is recommending videos with misinformation, violent content, …},
	language = {en},
	urldate = {2022-07-20},
	journal = {Mozilla Foundation},
	month = jul,
	year = {2021},
	note = {Section: Advocacy},
	file = {Mozilla_YouTube_Regrets_Report.pdf:/Users/clente/Zotero/storage/VTAQATRS/Mozilla_YouTube_Regrets_Report.pdf:application/pdf},
}

@article{cadwalladr_revealed_2018,
	chapter = {News},
	title = {Revealed: 50 million {Facebook} profiles harvested for {Cambridge} {Analytica} in major data breach},
	issn = {0261-3077},
	shorttitle = {Revealed},
	url = {https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election},
	abstract = {Whistleblower describes how firm linked to former Trump adviser Steve Bannon compiled user data to target American voters},
	language = {en-GB},
	urldate = {2022-11-24},
	journal = {The Guardian},
	author = {Cadwalladr, Carole and Graham-Harrison, Emma},
	month = mar,
	year = {2018},
	keywords = {Politics, Facebook, Brexit, Cambridge Analytica, Data protection, Donald Trump, Steve Bannon, Technology, UK news, US news, World news},
}

@article{kramer_experimental_2014,
	title = {Experimental evidence of massive-scale emotional contagion through social networks},
	volume = {111},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.1320040111},
	doi = {10.1073/pnas.1320040111},
	abstract = {Emotional states can be transferred to others via emotional contagion, leading people to experience the same emotions without their awareness. Emotional contagion is well established in laboratory experiments, with people transferring positive and negative emotions to others. Data from a large real-world social network, collected over a 20-y period suggests that longer-lasting moods (e.g., depression, happiness) can be transferred through networks [Fowler JH, Christakis NA (2008) BMJ 337:a2338], although the results are controversial. In an experiment with people who use Facebook, we test whether emotional contagion occurs outside of in-person interaction between individuals by reducing the amount of emotional content in the News Feed. When positive expressions were reduced, people produced fewer positive posts and more negative posts; when negative expressions were reduced, the opposite pattern occurred. These results indicate that emotions expressed by others on Facebook influence our own emotions, constituting experimental evidence for massive-scale contagion via social networks. This work also suggests that, in contrast to prevailing assumptions, in-person interaction and nonverbal cues are not strictly necessary for emotional contagion, and that the observation of others’ positive experiences constitutes a positive experience for people.},
	number = {24},
	urldate = {2022-11-24},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kramer, Adam D. I. and Guillory, Jamie E. and Hancock, Jeffrey T.},
	month = jun,
	year = {2014},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {8788--8790},
}

@article{dredge_youtubes_2016,
	chapter = {Technology},
	title = {{YouTube}'s latest hit: neon superheroes, giant ducks and plenty of lycra},
	issn = {0261-3077},
	shorttitle = {{YouTube}'s latest hit},
	url = {https://www.theguardian.com/technology/2016/jun/29/youtube-superheroes-children-webs-tiaras},
	abstract = {In just two months, Webs \& Tiaras has become the third most popular channel on YouTube, even if it’s one of the strangest success stories yet on the service},
	language = {en-GB},
	urldate = {2022-11-24},
	journal = {The Guardian},
	author = {Dredge, Stuart},
	month = jun,
	year = {2016},
	keywords = {Technology, Children's tech, Digital media, Internet, Media, Online TV, YouTube},
}

@misc{varol_online_2017,
	title = {Online {Human}-{Bot} {Interactions}: {Detection}, {Estimation}, and {Characterization}},
	shorttitle = {Online {Human}-{Bot} {Interactions}},
	url = {http://arxiv.org/abs/1703.03107},
	doi = {10.48550/arXiv.1703.03107},
	abstract = {Increasing evidence suggests that a growing amount of social media content is generated by autonomous entities known as social bots. In this work we present a framework to detect such entities on Twitter. We leverage more than a thousand features extracted from public data and meta-data about users: friends, tweet content and sentiment, network patterns, and activity time series. We benchmark the classification framework by using a publicly available dataset of Twitter bots. This training data is enriched by a manually annotated collection of active Twitter users that include both humans and bots of varying sophistication. Our models yield high accuracy and agreement with each other and can detect bots of different nature. Our estimates suggest that between 9\% and 15\% of active Twitter accounts are bots. Characterizing ties among accounts, we observe that simple bots tend to interact with bots that exhibit more human-like behaviors. Analysis of content flows reveals retweet and mention strategies adopted by bots to interact with different target groups. Using clustering analysis, we characterize several subclasses of accounts, including spammers, self promoters, and accounts that post content from connected applications.},
	urldate = {2022-11-24},
	publisher = {arXiv},
	author = {Varol, Onur and Ferrara, Emilio and Davis, Clayton A. and Menczer, Filippo and Flammini, Alessandro},
	month = mar,
	year = {2017},
	note = {arXiv:1703.03107 [cs]},
	keywords = {Computer Science - Social and Information Networks},
}

@misc{noauthor_biggest_nodate,
	title = {Biggest social media platforms 2022},
	url = {https://www.statista.com/statistics/272014/global-social-networks-ranked-by-number-of-users/},
	abstract = {Facebook, YouTube, and WhatsApp are the most popular social networks worldwide, each with at least two billion active users.},
	language = {en},
	urldate = {2022-11-24},
	journal = {Statista},
}

@inproceedings{anonymous_improving_2022,
	title = {Improving {Relevance} {Prediction} with {Transfer} {Learning} in {Large}-scale {Retrieval} {Systems}},
	url = {https://openreview.net/forum?id=SJxPVcSonN},
	abstract = {Machine learned large-scale retrieval systems require a large amount of training data representing query-item relevance. However, collecting users' explicit feedback is costly. In this paper, we propose to leverage user logs and implicit feedback as auxiliary objectives to improve relevance modeling in retrieval systems. Specifically, we adopt a two-tower neural net architecture to model query-item relevance given both collaborative and content information. By introducing auxiliary tasks trained with much richer implicit user feedback data, we improve the quality and resolution for the learned representations of queries and items. Applying these learned representations to an industrial retrieval system has delivered significant improvements.},
	language = {en},
	urldate = {2022-11-24},
	author = {Anonymous},
	month = jul,
	year = {2022},
}

@misc{noauthor_mozilla_2021-1,
	title = {Mozilla {Explains}: {Why} {Does} {YouTube} {Recommend} {Conspiracy} {Theory} {Videos}?},
	shorttitle = {Mozilla {Explains}},
	url = {https://foundation.mozilla.org/en/blog/mozilla-explains-why-does-youtube-recommend-conspiracy-theory-videos/},
	abstract = {The more YouTube you watch, the more ad money the site makes. What happens when that profit model goes unchecked?},
	language = {en},
	urldate = {2022-11-24},
	journal = {Mozilla Foundation},
	month = jun,
	year = {2021},
	note = {Section: Mozilla Explains},
}

@article{boyd_social_2007,
	title = {Social {Network} {Sites}: {Definition}, {History}, and {Scholarship}},
	volume = {13},
	issn = {1083-6101},
	shorttitle = {Social {Network} {Sites}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1083-6101.2007.00393.x},
	doi = {10.1111/j.1083-6101.2007.00393.x},
	abstract = {Social network sites (SNSs) are increasingly attracting the attention of academic and industry researchers intrigued by their affordances and reach. This special theme section of the Journal of Computer-Mediated Communication brings together scholarship on these emergent phenomena. In this introductory article, we describe features of SNSs and propose a comprehensive definition. We then present one perspective on the history of such sites, discussing key changes and developments. After briefly summarizing existing scholarship concerning SNSs, we discuss the articles in this special section and conclude with considerations for future research.},
	language = {en},
	number = {1},
	urldate = {2022-11-24},
	journal = {Journal of Computer-Mediated Communication},
	author = {Boyd, Danah M. and Ellison, Nicole B.},
	year = {2007},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1083-6101.2007.00393.x},
	pages = {210--230},
}

@misc{noauthor_mozilla_nodate,
	title = {{YouTube} {Regrets}},
	url = {https://foundation.mozilla.org/en/youtube/findings/},
	abstract = {Mozilla and 37,380 YouTube users conducted a study to better understand harmful YouTube recommendations. This is what we learned.},
	language = {en},
	urldate = {2022-11-24},
	journal = {Mozilla Foundation},
}

@misc{noauthor_congratulations_2020,
	title = {Congratulations, {YouTube}... {Now} {Show} {Your} {Work}},
	url = {https://foundation.mozilla.org/en/blog/congratulations-youtube-now-show-your-work/},
	abstract = {Earlier this week, YouTube finally acknowledged their recommendation engine suggests harmful content. It’s a small step in the right direction, but YouTube still has a long history of dismissing independent researchers. We created a timeline to prove it.},
	language = {en},
	urldate = {2022-11-24},
	journal = {Mozilla Foundation},
	month = jul,
	year = {2020},
	note = {Section: Advocacy},
}

@misc{noauthor_tensorflow_nodate-1,
	title = {{TensorFlow}: {A} {System} for {Large}-{Scale} {Machine} {Learning} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
	urldate = {2022-11-24},
}

@misc{noauthor_recommending_nodate,
	title = {Recommending movies: ranking {\textbar} {TensorFlow} {Recommenders}},
	shorttitle = {Recommending movies},
	url = {https://www.tensorflow.org/recommenders/examples/basic_ranking},
	language = {en},
	urldate = {2022-11-24},
}

@inproceedings{wang_deep_2017,
	address = {New York, NY, USA},
	series = {{ADKDD}'17},
	title = {Deep \& {Cross} {Network} for {Ad} {Click} {Predictions}},
	isbn = {978-1-4503-5194-2},
	url = {https://doi.org/10.1145/3124749.3124754},
	doi = {10.1145/3124749.3124754},
	abstract = {Feature engineering has been the key to the success of many prediction models. However, the process is nontrivial and often requires manual feature engineering or exhaustive searching. DNNs are able to automatically learn feature interactions; however, they generate all the interactions implicitly, and are not necessarily efficient in learning all types of cross features. In this paper, we propose the Deep \& Cross Network (DCN) which keeps the benefits of a DNN model, and beyond that, it introduces a novel cross network that is more efficient in learning certain bounded-degree feature interactions. In particular, DCN explicitly applies feature crossing at each layer, requires no manual feature engineering, and adds negligible extra complexity to the DNN model. Our experimental results have demonstrated its superiority over the state-of-art algorithms on the CTR prediction dataset and dense classification dataset, in terms of both model accuracy and memory usage.},
	urldate = {2022-11-23},
	booktitle = {Proceedings of the {ADKDD}'17},
	publisher = {Association for Computing Machinery},
	author = {Wang, Ruoxi and Fu, Bin and Fu, Gang and Wang, Mingliang},
	month = aug,
	year = {2017},
	keywords = {Deep Learning, CTR Prediction, Feature Crossing, Neural Networks},
	pages = {1--7},
}

@book{borda_fundamentals_2011,
	address = {Berlin, Heidelberg},
	title = {Fundamentals in {Information} {Theory} and {Coding}},
	isbn = {978-3-642-20346-6},
	url = {http://link.springer.com/10.1007/978-3-642-20347-3},
	language = {en},
	urldate = {2022-11-24},
	publisher = {Springer},
	author = {Borda, Monica},
	year = {2011},
	doi = {10.1007/978-3-642-20347-3},
	keywords = {Channel Coding, Cryptography, Information transmission systems, ITS Cryptography, Source Coding},
}

@article{roscher_explainable_2020,
	title = {Explainable {Machine} {Learning} for {Scientific} {Insights} and {Discoveries}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2976199},
	abstract = {Machine learning methods have been remarkably successful for a wide range of application areas in the extraction of essential information from data. An exciting and relatively recent development is the uptake of machine learning in the natural sciences, where the major goal is to obtain novel scientific insights and discoveries from observational or simulated data. A prerequisite for obtaining a scientific outcome is domain knowledge, which is needed to gain explainability, but also to enhance scientific consistency. In this article, we review explainable machine learning in view of applications in the natural sciences and discuss three core elements that we identified as relevant in this context: transparency, interpretability, and explainability. With respect to these core elements, we provide a survey of recent scientific works that incorporate machine learning and the way that explainable machine learning is used in combination with domain knowledge from the application areas.},
	journal = {IEEE Access},
	author = {Roscher, Ribana and Bohn, Bastian and Duarte, Marco F. and Garcke, Jochen},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Approximation algorithms, Biological system modeling, Data mining, Data models, Explainable machine learning, informed machine learning, interpretability, Kernel, Machine learning, Mathematical model, scientific consistency, transparency},
	pages = {42200--42216},
}

@misc{raunak_curious_2021,
	title = {The {Curious} {Case} of {Hallucinations} in {Neural} {Machine} {Translation}},
	url = {http://arxiv.org/abs/2104.06683},
	doi = {10.48550/arXiv.2104.06683},
	abstract = {In this work, we study hallucinations in Neural Machine Translation (NMT), which lie at an extreme end on the spectrum of NMT pathologies. Firstly, we connect the phenomenon of hallucinations under source perturbation to the Long-Tail theory of Feldman (2020), and present an empirically validated hypothesis that explains hallucinations under source perturbation. Secondly, we consider hallucinations under corpus-level noise (without any source perturbation) and demonstrate that two prominent types of natural hallucinations (detached and oscillatory outputs) could be generated and explained through specific corpus-level noise patterns. Finally, we elucidate the phenomenon of hallucination amplification in popular data-generation processes such as Backtranslation and sequence-level Knowledge Distillation.},
	urldate = {2022-11-24},
	publisher = {arXiv},
	author = {Raunak, Vikas and Menezes, Arul and Junczys-Dowmunt, Marcin},
	month = apr,
	year = {2021},
	note = {arXiv:2104.06683 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{weisstein_degenerate_nodate,
	type = {Text},
	title = {Degenerate},
	copyright = {Copyright 1999-2022 Wolfram Research, Inc.  See https://mathworld.wolfram.com/about/terms.html for a full terms of use statement.},
	url = {https://mathworld.wolfram.com/},
	abstract = {A limiting case in which a class of object changes its nature so as to belong to another, usually simpler, class. For example, the point is a degenerate case of the circle as the radius approaches 0, and the circle is a degenerate form of an ellipse as the eccentricity approaches 0. Another example is the two identical roots of the second-order polynomial (x-1){\textasciicircum}2. Since the n roots of an nth degree polynomial are usually distinct, roots which coincide are said to be degenerate. Degenerate...},
	language = {en},
	urldate = {2022-11-24},
	author = {Weisstein, Eric W.},
	note = {Publisher: Wolfram Research, Inc.},
}

@article{benson_small_nodate,
	title = {The {Small} but {Mighty} {Danger} of {Echo} {Chamber} {Extremism}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/media-echo-chamber-extremism/},
	abstract = {Research shows that relatively few people exist in perfectly sealed-off media bubbles—but they’re still having an outsize impact on US politics.},
	language = {en-US},
	urldate = {2023-01-31},
	journal = {Wired},
	author = {Benson, Thor},
	note = {Section: tags},
	keywords = {disinformation, media, politics, social media},
}

@article{afsar_reinforcement_2022,
	title = {Reinforcement {Learning} based {Recommender} {Systems}: {A} {Survey}},
	volume = {55},
	issn = {0360-0300},
	shorttitle = {Reinforcement {Learning} based {Recommender} {Systems}},
	url = {https://doi.org/10.1145/3543846},
	doi = {10.1145/3543846},
	abstract = {Recommender systems (RSs) have become an inseparable part of our everyday lives. They help us find our favorite items to purchase, our friends on social networks, and our favorite movies to watch. Traditionally, the recommendation problem was considered to be a classification or prediction problem, but it is now widely agreed that formulating it as a sequential decision problem can better reflect the user-system interaction. Therefore, it can be formulated as a Markov decision process (MDP) and be solved by reinforcement learning (RL) algorithms. Unlike traditional recommendation methods, including collaborative filtering and content-based filtering, RL is able to handle the sequential, dynamic user-system interaction and to take into account the long-term user engagement. Although the idea of using RL for recommendation is not new and has been around for about two decades, it was not very practical, mainly because of scalability problems of traditional RL algorithms. However, a new trend has emerged in the field since the introduction of deep reinforcement learning (DRL), which made it possible to apply RL to the recommendation problem with large state and action spaces. In this paper, a survey on reinforcement learning based recommender systems (RLRSs) is presented. Our aim is to present an outlook on the field and to provide the reader with a fairly complete knowledge of key concepts of the field. We first recognize and illustrate that RLRSs can be generally classified into RL- and DRL-based methods. Then, we propose an RLRS framework with four components, i.e., state representation, policy optimization, reward formulation, and environment building, and survey RLRS algorithms accordingly. We highlight emerging topics and depict important trends using various graphs and tables. Finally, we discuss important aspects and challenges that can be addressed in the future.},
	number = {7},
	urldate = {2023-02-15},
	journal = {ACM Computing Surveys},
	author = {Afsar, M. Mehdi and Crump, Trafford and Far, Behrouz},
	month = dec,
	year = {2022},
	keywords = {Recommender systems, reinforcement learning},
	pages = {145:1--145:38},
}

@article{ko_survey_2022,
	title = {A {Survey} of {Recommendation} {Systems}: {Recommendation} {Models}, {Techniques}, and {Application} {Fields}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	shorttitle = {A {Survey} of {Recommendation} {Systems}},
	url = {https://www.mdpi.com/2079-9292/11/1/141},
	doi = {10.3390/electronics11010141},
	abstract = {This paper reviews the research trends that link the advanced technical aspects of recommendation systems that are used in various service areas and the business aspects of these services. First, for a reliable analysis of recommendation models for recommendation systems, data mining technology, and related research by application service, more than 135 top-ranking articles and top-tier conferences published in Google Scholar between 2010 and 2021 were collected and reviewed. Based on this, studies on recommendation system models and the technology used in recommendation systems were systematized, and research trends by year were analyzed. In addition, the application service fields where recommendation systems were used were classified, and research on the recommendation system model and recommendation technique used in each field was analyzed. Furthermore, vast amounts of application service-related data used by recommendation systems were collected from 2010 to 2021 without taking the journal ranking into consideration and reviewed along with various recommendation system studies, as well as applied service field industry data. As a result of this study, it was found that the flow and quantitative growth of various detailed studies of recommendation systems interact with the business growth of the actual applied service field. While providing a comprehensive summary of recommendation systems, this study provides insight to many researchers interested in recommendation systems through the analysis of its various technologies and trends in the service field to which recommendation systems are applied.},
	language = {en},
	number = {1},
	urldate = {2023-02-15},
	journal = {Electronics},
	author = {Ko, Hyeyoung and Lee, Suyeon and Park, Yoonseo and Choi, Anna},
	month = jan,
	year = {2022},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {collaborative filtering, content-based filtering, hybrid system, recommendation algorithm, recommendation system, recommendation technique, recommender system},
	pages = {141},
}

@article{budzinski_data_2022,
	title = {Data (r)evolution: the economics of algorithmic search and recommender services},
	shorttitle = {Data (r)evolution},
	url = {https://www.elgaronline.com/display/edcoll/9781839107184/9781839107184.00031.xml},
	abstract = {This chapter analyzes the economics behind algorithmic search and recommender services (SRS), which are based on personalized user data. Such services play a paramount role in digital business ecosystems (DBE), such as marketplaces (e.g. Amazon), audio streaming (e.g. Spotify), video streaming (e.g. Netflix, YouTube), app stores, social networks (e.g. Instagram, TikTok, Facebook, Twitter) and many more. We start with a systematic analysis of SRS as a commercial good, highlighting the changes because of digitization. Then we discuss benefits and risk for welfare that arise from the widespread employment of algorithmic search and recommendation systems. In doing so, we summarize the existing economics literature and go beyond its insights, highlighting further research agendas. Eventually, we explain the role of SRS within the DBE and managerial implications.},
	language = {en\_US},
	urldate = {2023-02-15},
	journal = {Handbook on Digital Business Ecosystems},
	author = {Budzinski, Oliver and Gaenssle, Sophia and Lindstädt-Dreusicke, Nadine},
	month = apr,
	year = {2022},
	note = {ISBN: 9781839107191
Publisher: Edward Elgar Publishing
Section: Handbook on Digital Business Ecosystems},
	pages = {349--366},
}

@misc{yu_self-supervised_2022,
	title = {Self-{Supervised} {Learning} for {Recommender} {Systems}: {A} {Survey}},
	shorttitle = {Self-{Supervised} {Learning} for {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2203.15876},
	doi = {10.48550/arXiv.2203.15876},
	abstract = {Neural architecture-based recommender systems have achieved tremendous success in recent years. However, when dealing with highly sparse data, they still fall short of expectation. Self-supervised learning (SSL), as an emerging technique to learn with unlabeled data, recently has drawn considerable attention in many fields. There is also a growing body of research proceeding towards applying SSL to recommendation for mitigating the data sparsity issue. In this survey, a timely and systematical review of the research efforts on self-supervised recommendation (SSR) is presented. Specifically, we propose an exclusive definition of SSR, on top of which we build a comprehensive taxonomy to divide existing SSR methods into four categories: contrastive, generative, predictive, and hybrid. For each category, the narrative unfolds along its concept and formulation, the involved methods, and its pros and cons. Meanwhile, to facilitate the development and evaluation of SSR models, we release an open-source library SELFRec, which incorporates multiple benchmark datasets and evaluation metrics, and has implemented a number of state-of-the-art SSR models for empirical comparison. Finally, we shed light on the limitations in the current research and outline the future research directions.},
	urldate = {2023-02-15},
	publisher = {arXiv},
	author = {Yu, Junliang and Yin, Hongzhi and Xia, Xin and Chen, Tong and Li, Jundong and Huang, Zi},
	month = mar,
	year = {2022},
	note = {arXiv:2203.15876 [cs]},
	keywords = {Computer Science - Information Retrieval},
}

@misc{deldjoo_fairness_2022,
	title = {Fairness in {Recommender} {Systems}: {Research} {Landscape} and {Future} {Directions}},
	shorttitle = {Fairness in {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2205.11127},
	doi = {10.48550/arXiv.2205.11127},
	abstract = {Recommender systems can strongly influence which information we see online, e.g., on social media, and thus impact our beliefs, decisions, and actions. At the same time, these systems can create substantial business value for different stakeholders. Given the growing potential impact of such AI-based systems on individuals, organizations, and society, questions of fairness have gained increased attention in recent years. However, research on fairness in recommender systems is still a developing area. In this survey, we first review the fundamental concepts and notions of fairness that were put forward in the area in the recent past. Afterward, through a review of more than 150 scholarly publications, we present an overview of how research in this field is currently operationalized, e.g., in terms of general research methodology, fairness measures, and algorithmic approaches. Overall, our analysis of recent works points to specific research gaps. In particular, we find that in many research works in computer science, very abstract problem operationalizations are prevalent, and questions of the underlying normative claims and what represents a fair recommendation in the context of a given application are often not discussed in depth. These observations call for more interdisciplinary research to address fairness in recommendation in a more comprehensive and impactful manner.},
	urldate = {2023-02-15},
	publisher = {arXiv},
	author = {Deldjoo, Yashar and Jannach, Dietmar and Bellogin, Alejandro and Difonzo, Alessandro and Zanzonelli, Dario},
	month = dec,
	year = {2022},
	note = {arXiv:2205.11127 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval},
}

@article{wang_survey_2023,
	title = {A {Survey} on the {Fairness} of {Recommender} {Systems}},
	volume = {41},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3547333},
	doi = {10.1145/3547333},
	abstract = {Recommender systems are an essential tool to relieve the information overload challenge and play an important role in people’s daily lives. Since recommendations involve allocations of social resources (e.g., job recommendation), an important issue is whether recommendations are fair. Unfair recommendations are not only unethical but also harm the long-term interests of the recommender system itself. As a result, fairness issues in recommender systems have recently attracted increasing attention. However, due to multiple complex resource allocation processes and various fairness definitions, the research on fairness in recommendation is scattered. To fill this gap, we review over 60 papers published in top conferences/journals, including TOIS, SIGIR, and WWW. First, we summarize fairness definitions in the recommendation and provide several views to classify fairness issues. Then, we review recommendation datasets and measurements in fairness studies and provide an elaborate taxonomy of fairness methods in the recommendation. Finally, we conclude this survey by outlining some promising future directions.},
	number = {3},
	urldate = {2023-02-15},
	journal = {ACM Transactions on Information Systems},
	author = {Wang, Yifan and Ma, Weizhi and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
	month = feb,
	year = {2023},
	keywords = {fairness, Recommendation, survey},
	pages = {52:1--52:43},
}

@misc{li_fairness_2022,
	title = {Fairness in {Recommendation}: {A} {Survey}},
	shorttitle = {Fairness in {Recommendation}},
	url = {http://arxiv.org/abs/2205.13619},
	doi = {10.48550/arXiv.2205.13619},
	abstract = {As one of the most pervasive applications of machine learning, recommender systems are playing an important role on assisting human decision making. The satisfaction of users and the interests of platforms are closely related to the quality of the generated recommendation results. However, as a highly data-driven system, recommender system could be affected by data or algorithmic bias and thus generate unfair results, which could weaken the reliance of the systems. As a result, it is crucial to address the potential unfairness problems in recommendation settings. Recently, there has been growing attention on fairness considerations in recommender systems with more and more literature on approaches to promote fairness in recommendation. However, the studies are rather fragmented and lack a systematic organization, thus making it difficult to penetrate for new researchers to the domain. This motivates us to provide a systematic survey of existing works on fairness in recommendation. This survey focuses on the foundations for fairness in recommendation literature. It first presents a brief introduction about fairness in basic machine learning tasks such as classification and ranking in order to provide a general overview of fairness research, as well as introduce the more complex situations and challenges that need to be considered when studying fairness in recommender systems. After that, the survey will introduce fairness in recommendation with a focus on the taxonomies of current fairness definitions, the typical techniques for improving fairness, as well as the datasets for fairness studies in recommendation. The survey also talks about the challenges and opportunities in fairness research with the hope of promoting the fair recommendation research area and beyond.},
	urldate = {2023-02-15},
	publisher = {arXiv},
	author = {Li, Yunqi and Chen, Hanxiong and Xu, Shuyuan and Ge, Yingqiang and Tan, Juntao and Liu, Shuchang and Zhang, Yongfeng},
	month = jun,
	year = {2022},
	note = {arXiv:2205.13619 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@article{liu_dual_2022,
	title = {Dual constraints and adversarial learning for fair recommenders},
	volume = {239},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705121011424},
	doi = {10.1016/j.knosys.2021.108058},
	abstract = {Recommender systems, which are consist of common artificial intelligence technology, have a profound impact on the lifestyles of people. However, recent studies have demonstrated that recommender systems have fairness problems which means that some people with certain attributes are treated unfairly. A fair recommender means that users with different attributes achieve the same recommender accuracy. In particular, the recommender systems completely rely on users’ behavior data for preferences learning, which leads to a high probability of unfair problems because that the behavior data usually contains sensitive information of users. Unfortunately, there are a few studies exploring unfair problem in recommender systems. To alleviate this problem, we present a novel fairness-aware recommender with dual fairness constraints (FRFC) to improve fairness in recommendations and protect the user’s sensitive information from being exposed. This model has several advantages: one advantage is that an adversarial-based graph neural network (GNN) is proposed to prevent the target user being infected by sensitive features of neighbor users; another advantage is that two fairness constraints are proposed to solve the problems of adversarial classifier failures in whole data and unfair ranking losses. With this design, the FRFC model can effectively filter out users’ sensitive information and give users of different attributes the same training opportunities, which is helpful for making a fair recommendation. Finally, extensive experiments demonstrate that the proposed model can significantly improve the fairness of recommendation results.},
	language = {en},
	urldate = {2023-02-15},
	journal = {Knowledge-Based Systems},
	author = {Liu, Haifeng and Zhao, Nan and Zhang, Xiaokun and Lin, Hongfei and Yang, Liang and Xu, Bo and Lin, Yuan and Fan, Wenqi},
	month = mar,
	year = {2022},
	keywords = {Adversarial learning, Fair recommendation, Graph neural network, Recommender systems},
	pages = {108058},
}

@misc{wang_trustworthy_2022,
	title = {Trustworthy {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2208.06265},
	doi = {10.48550/arXiv.2208.06265},
	abstract = {Recommender systems (RSs) aim to help users to effectively retrieve items of their interests from a large catalogue. For a quite long period of time, researchers and practitioners have been focusing on developing accurate RSs. Recent years have witnessed an increasing number of threats to RSs, coming from attacks, system and user generated noise, system bias. As a result, it has become clear that a strict focus on RS accuracy is limited and the research must consider other important factors, e.g., trustworthiness. For end users, a trustworthy RS (TRS) should not only be accurate, but also transparent, unbiased and fair as well as robust to noise or attacks. These observations actually led to a paradigm shift of the research on RSs: from accuracy-oriented RSs to TRSs. However, researchers lack a systematic overview and discussion of the literature in this novel and fast developing field of TRSs. To this end, in this paper, we provide an overview of TRSs, including a discussion of the motivation and basic concepts of TRSs, a presentation of the challenges in building TRSs, and a perspective on the future directions in this area. We also provide a novel conceptual framework to support the construction of TRSs.},
	urldate = {2023-02-15},
	publisher = {arXiv},
	author = {Wang, Shoujin and Zhang, Xiuzhen and Wang, Yan and Liu, Huan and Ricci, Francesco},
	month = aug,
	year = {2022},
	note = {arXiv:2208.06265 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@inproceedings{naghiaei_cpfair_2022,
	address = {New York, NY, USA},
	series = {{SIGIR} '22},
	title = {{CPFair}: {Personalized} {Consumer} and {Producer} {Fairness} {Re}-ranking for {Recommender} {Systems}},
	isbn = {978-1-4503-8732-3},
	shorttitle = {{CPFair}},
	url = {https://doi.org/10.1145/3477495.3531959},
	doi = {10.1145/3477495.3531959},
	abstract = {Recently, there has been a rising awareness that when machine learning (ML) algorithms are used to automate choices, they may treat/affect individuals unfairly, with legal, ethical, or economic consequences. Recommender systems are prominent examples of such ML systems that assist users in making high-stakes judgments. A common trend in the previous literature research on fairness in recommender systems is that the majority of works treat user and item fairness concerns separately, ignoring the fact that recommender systems operate in a two-sided marketplace. In this work, we present an optimization-based re-ranking approach that seamlessly integrates fairness constraints from both the consumer and producer-side in a joint objective framework. We demonstrate through large-scale experiments on 8 datasets that our proposed method is capable of improving both consumer and producer fairness without reducing overall recommendation quality, demonstrating the role algorithms may play in minimizing data biases.},
	urldate = {2023-02-15},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Naghiaei, Mohammadmehdi and Rahmani, Hossein A. and Deldjoo, Yashar},
	month = jul,
	year = {2022},
	keywords = {fair re-ranking, recommendation system, two-sided fairness},
	pages = {770--779},
}

@inproceedings{ovaisi_rgrecsys_2022,
	address = {New York, NY, USA},
	series = {{WSDM} '22},
	title = {{RGRecSys}: {A} {Toolkit} for {Robustness} {Evaluation} of {Recommender} {Systems}},
	isbn = {978-1-4503-9132-0},
	shorttitle = {{RGRecSys}},
	url = {https://doi.org/10.1145/3488560.3502192},
	doi = {10.1145/3488560.3502192},
	abstract = {Robust machine learning is an increasingly important topic that focuses on developing models resilient to various forms of imperfect data. Due to the pervasiveness of recommender systems in online technologies, researchers have carried out several robustness studies focusing on data sparsity and profile injection attacks. Instead, we propose a more holistic view of robustness for recommender systems that encompasses multiple dimensions - robustness with respect to sub-populations, transformations, distributional disparity, attack, and data sparsity. While there are several libraries that allow users to compare different recommender system models, there is no software library for comprehensive robustness evaluation of recommender system models under different scenarios. As our main contribution, we present a robustness evaluation toolkit, Robustness Gym for RecSys (RGRecSys), that allows us to quickly and uniformly evaluate the robustness of recommender system models.},
	urldate = {2023-02-15},
	booktitle = {Proceedings of the {Fifteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Ovaisi, Zohreh and Heinecke, Shelby and Li, Jia and Zhang, Yongfeng and Zheleva, Elena and Xiong, Caiming},
	month = feb,
	year = {2022},
	keywords = {recommender systems, robustness},
	pages = {1597--1600},
}

@article{gao_fair_2022,
	title = {{FAIR}: {Fairness}-aware information retrieval evaluation},
	volume = {73},
	issn = {2330-1643},
	shorttitle = {{FAIR}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.24648},
	doi = {10.1002/asi.24648},
	abstract = {With the emerging needs of creating fairness-aware solutions for search and recommendation systems, a daunting challenge exists of evaluating such solutions. While many of the traditional information retrieval (IR) metrics can capture the relevance, diversity, and novelty for the utility with respect to users, they are not suitable for inferring whether the presented results are fair from the perspective of responsible information exposure. On the other hand, existing fairness metrics do not account for user utility or do not measure it adequately. To address this problem, we propose a new metric called FAIR. By unifying standard IR metrics and fairness measures into an integrated metric, this metric offers a new perspective for evaluating fairness-aware ranking results. Based on this metric, we developed an effective ranking algorithm that jointly optimized user utility and fairness. The experimental results showed that our FAIR metric could highlight results with good user utility and fair information exposure. We showed how FAIR related to a set of existing utility and fairness metrics and demonstrated the effectiveness of our FAIR-based algorithm. We believe our work opens up a new direction of pursuing a metric for evaluating and implementing the FAIR systems.},
	language = {en},
	number = {10},
	urldate = {2023-02-15},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Gao, Ruoyuan and Ge, Yingqiang and Shah, Chirag},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24648},
	pages = {1461--1473},
}

@inproceedings{patro_fair_2022,
	address = {New York, NY, USA},
	series = {{FAccT} '22},
	title = {Fair ranking: a critical review, challenges, and future directions},
	isbn = {978-1-4503-9352-2},
	shorttitle = {Fair ranking},
	url = {https://doi.org/10.1145/3531146.3533238},
	doi = {10.1145/3531146.3533238},
	abstract = {Ranking, recommendation, and retrieval systems are widely used in online platforms and other societal systems, including e-commerce, media-streaming, admissions, gig platforms, and hiring. In the recent past, a large “fair ranking” research literature has been developed around making these systems fair to the individuals, providers, or content that are being ranked. Most of this literature defines fairness for a single instance of retrieval, or as a simple additive notion for multiple instances of retrievals over time. This work provides a critical overview of this literature, detailing the often context-specific concerns that such approaches miss: the gap between high ranking placements and true provider utility, spillovers and compounding effects over time, induced strategic incentives, and the effect of statistical uncertainty. We then provide a path forward for a more holistic and impact-oriented fair ranking research agenda, including methodological lessons from other fields and the role of the broader stakeholder community in overcoming data bottlenecks and designing effective regulatory environments.},
	urldate = {2023-02-15},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Patro, Gourab K. and Porcaro, Lorenzo and Mitchell, Laura and Zhang, Qiuyue and Zehlike, Meike and Garg, Nikhil},
	month = jun,
	year = {2022},
	keywords = {Algorithmic Impact Assessment, Exposure, Fairness, Ranking, Recommendation, Strategic Behaviour},
	pages = {1929--1942},
}

@inproceedings{ge_explainable_2022,
	address = {New York, NY, USA},
	series = {{SIGIR} '22},
	title = {Explainable {Fairness} in {Recommendation}},
	isbn = {978-1-4503-8732-3},
	url = {https://doi.org/10.1145/3477495.3531973},
	doi = {10.1145/3477495.3531973},
	abstract = {Existing research on fairness-aware recommendation has mainly focused on the quantification of fairness and the development of fair recommendation models, neither of which studies a more substantial problem--identifying the underlying reason of model disparity in recommendation. This information is critical for recommender system designers to understand the intrinsic recommendation mechanism and provides insights on how to improve model fairness to decision makers. Fortunately, with the rapid development of Explainable AI, we can use model explainability to gain insights into model (un)fairness. In this paper, we study the problem ofexplainable fairness, which helps to gain insights about why a system is fair or unfair, and guides the design of fair recommender systems with a more informed and unified methodology. Particularly, we focus on a common setting with feature-aware recommendation and exposure unfairness, but the proposed explainable fairness framework is general and can be applied to other recommendation settings and fairness definitions. We propose a Counterfactual Explainable Fairness framework, called CEF, which generates explanations about model fairness that can improve the fairness without significantly hurting the performance. The CEF framework formulates an optimization problem to learn the "minimal'' change of the input features that changes the recommendation results to a certain level of fairness. Based on the counterfactual recommendation result of each feature, we calculate an explainability score in terms of the fairness-utility trade-off to rank all the feature-based explanations, and select the top ones as fairness explanations. Experimental results on several real-world datasets validate that our method is able to effectively provide explanations to the model disparities and these explanations can achieve better fairness-utility trade-off when using them for recommendation than all the baselines.},
	urldate = {2023-02-15},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Ge, Yingqiang and Tan, Juntao and Zhu, Yan and Xia, Yinglong and Luo, Jiebo and Liu, Shuchang and Fu, Zuohui and Geng, Shijie and Li, Zelong and Zhang, Yongfeng},
	month = jul,
	year = {2022},
	keywords = {counterfactual reasoning, explainable fairness, explainable recommendation, fairness in ai, recommender systems},
	pages = {681--691},
}

@inproceedings{wang_humans_2022,
	address = {New York, NY, USA},
	series = {{IUI} '22},
	title = {Do {Humans} {Prefer} {Debiased} {AI} {Algorithms}? {A} {Case} {Study} in {Career} {Recommendation}},
	isbn = {978-1-4503-9144-3},
	shorttitle = {Do {Humans} {Prefer} {Debiased} {AI} {Algorithms}?},
	url = {https://doi.org/10.1145/3490099.3511108},
	doi = {10.1145/3490099.3511108},
	abstract = {Currently, there is a surge of interest in fair Artificial Intelligence (AI) and Machine Learning (ML) research which aims to mitigate discriminatory bias in AI algorithms, e.g. along lines of gender, age, and race. While most research in this domain focuses on developing fair AI algorithms, in this work, we examine the challenges which arise when human- fair-AI interact. Our results show that due to an apparent conflict between human preferences and fairness, a fair AI algorithm on its own may be insufficient to achieve its intended results in the real world. Using college major recommendation as a case study, we build a fair AI recommender by employing gender debiasing machine learning techniques. Our offline evaluation showed that the debiased recommender makes fairer and more accurate college major recommendations. Nevertheless, an online user study of more than 200 college students revealed that participants on average prefer the original biased system over the debiased system. Specifically, we found that the perceived gender disparity associated with a college major is a determining factor for the acceptance of a recommendation. In other words, our results demonstrate we cannot fully address the gender bias issue in AI recommendations without addressing the gender bias in humans. They also highlight the urgent need to extend the current scope of fair AI research from narrowly focusing on debiasing AI algorithms to including new persuasion and bias explanation technologies in order to achieve intended societal impacts.},
	urldate = {2023-02-15},
	booktitle = {27th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Clarice and Wang, Kathryn and Bian, Andrew and Islam, Rashidul and Keya, Kamrun Naher and Foulds, James and Pan, Shimei},
	month = mar,
	year = {2022},
	pages = {134--147},
}

@article{benson_small_nodate-1,
	title = {The {Small} but {Mighty} {Danger} of {Echo} {Chamber} {Extremism}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/media-echo-chamber-extremism/},
	abstract = {Research shows that relatively few people exist in perfectly sealed-off media bubbles—but they’re still having an outsize impact on US politics.},
	language = {en-US},
	urldate = {2023-02-15},
	journal = {Wired},
	author = {Benson, Thor},
	note = {Section: tags},
	keywords = {disinformation, media, politics, social media},
}

@article{ceylan_sharing_2023,
	title = {Sharing of misinformation is habitual, not just lazy or biased},
	volume = {120},
	url = {https://www.pnas.org/doi/10.1073/pnas.2216614120},
	doi = {10.1073/pnas.2216614120},
	abstract = {Why do people share misinformation on social media? In this research (N = 2,476), we show that the structure of online sharing built into social platforms is more important than individual deficits in critical reasoning and partisan bias—commonly cited drivers of misinformation. Due to the reward-based learning systems on social media, users form habits of sharing information that attracts others' attention. Once habits form, information sharing is automatically activated by cues on the platform without users considering response outcomes such as spreading misinformation. As a result of user habits, 30 to 40\% of the false news shared in our research was due to the 15\% most habitual news sharers. Suggesting that sharing of false news is part of a broader response pattern established by social media platforms, habitual users also shared information that challenged their own political beliefs. Finally, we show that sharing of false news is not an inevitable consequence of user habits: Social media sites could be restructured to build habits to share accurate information.},
	number = {4},
	urldate = {2023-02-15},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ceylan, Gizem and Anderson, Ian A. and Wood, Wendy},
	month = jan,
	year = {2023},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2216614120},
}

@Manual{rcore_stats_2022,
	title = {R: A Language and Environment for Statistical Computing},
	author = {{R Core Team}},
	organization = {R Foundation for Statistical Computing},
	address = {Vienna, Austria},
	year = {2022},
	url = {https://www.R-project.org/},
}

@article{moral_half-normal_2017,
	title = {Half-{Normal} {Plots} and {Overdispersed} {Models} in {R}: {The} hnp {Package}},
	volume = {81},
	copyright = {Copyright (c) 2017 Rafael A Moral, John Hinde, Clarice G B Demétrio},
	issn = {1548-7660},
	shorttitle = {Half-{Normal} {Plots} and {Overdispersed} {Models} in {R}},
	url = {https://doi.org/10.18637/jss.v081.i10},
	doi = {10.18637/jss.v081.i10},
	abstract = {Count and proportion data may present overdispersion, i.e., greater variability than expected by the Poisson and binomial models, respectively. Different extended generalized linear models that allow for overdispersion may be used to analyze this type of data, such as models that use a generalized variance function, random-effects models, zero-inflated models and compound distribution models. Assessing goodness-of-fit and verifying assumptions of these models is not an easy task and the use of half-normal plots with a simulated envelope is a possible solution for this problem. These plots are a useful indicator of goodness-of-fit that may be used with any generalized linear model and extensions. For GLIM users, functions that generated these plots were widely used, however, in the open-source software R, these functions were not yet available on the Comprehensive R Archive Network (CRAN). We describe a new package in R, hnp, that may be used to generate the half-normal plot with a simulated envelope for residuals from different types of models. The function hnp() can be used together with a range of different model fitting packages in R that extend the basic generalized linear model fitting in glm() and is written so that it is relatively easy to extend it to new model classes and different diagnostics. We illustrate its use on a range of examples, including continuous and discrete responses, and show how it can be used to inform model selection and diagnose overdispersion.},
	language = {en},
	urldate = {2023-02-15},
	journal = {Journal of Statistical Software},
	author = {Moral, Rafael A. and Hinde, John and Demétrio, Clarice G. B.},
	month = nov,
	year = {2017},
	keywords = {generalized linear models, goodness-of-fit, mixed models, R},
	pages = {1--23},
}

@book{venables_modern_2002,
	address = {New York, NY},
	series = {Statistics and {Computing}},
	title = {Modern {Applied} {Statistics} with {S}},
	isbn = {978-1-4419-3008-8},
	url = {http://link.springer.com/10.1007/978-0-387-21706-2},
	urldate = {2023-02-15},
	publisher = {Springer},
	author = {Venables, W. N. and Ripley, B. D.},
	editor = {Chambers, J. and Eddy, W. and Härdle, W. and Sheather, S. and Tierney, L.},
	year = {2002},
	doi = {10.1007/978-0-387-21706-2},
	keywords = {best fit, Bootstrapping, classification, Cluster analysis, data analysis, Estimator, Factor analysis, Fitting, Generalized linear model, linear regression, STATISTICA, Survival analysis, Time series},
}

@article{brooks_glmmtmb_2017,
	title = {{glmmTMB} {Balances} {Speed} and {Flexibility} {Among} {Packages} for {Zero}-inflated {Generalized} {Linear} {Mixed} {Modeling}},
	volume = {9},
	issn = {2073-4859},
	url = {https://journal.r-project.org/archive/2017/RJ-2017-066/index.html},
	language = {en},
	number = {2},
	urldate = {2023-02-15},
	journal = {The R Journal},
	author = {Brooks, Mollie E. and Kristensen, Kasper and Benthem, Koen J. van and Magnusson, Arni and Berg, Casper W. and Nielsen, Anders and Skaug, Hans J. and Mächler, Martin and Bolker, Benjamin M.},
	year = {2017},
	pages = {378--400},
}

@Manual{florian_dharma_2022,
	title = {DHARMa: Residual Diagnostics for Hierarchical (Multi-Level / Mixed) Regression Models},
	author = {Hartig, Florian},
	year = {2022},
	note = {R package version 0.4.6},
	url = {https://CRAN.R-project.org/package=DHARMa},
}
