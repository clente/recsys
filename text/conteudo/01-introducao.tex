%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo Ã© parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101/183146

%% ------------------------------------------------------------------------- %%
\chapter{Introduction}
\label{cap:introduction}

Social networks have all but taken over contemporary daily life. From the
eponymous socializing, to reading news, to expressing ourselves, social media
has creeped into every corner of society. Most of its side-effects, it could be
argued, are positive (shortening distances, political accountability, social
organizing), but they are not perfect institutions.

Social media companies already face significant backlash for their questionable
business model and ethics. Cambridge Analytica's election meddling, Facebook's
subliminal experiments, YouTube's problem with disturbing content marketed at
kids, and Twitter's bot infestation are just a few recent scandals that have put
the societal role of social media into question.

One particular controversy that has taken over public discourse around social
networks is the role that their algorithms might have in radicalizing users,
specially younger ones. The aforementioned experiments conducted by Facebook to
influence people's emotions and the proliferation of more than questionable
videos aimed at children on YouTube are instances that seem to corroborate the
notion that there is something fundamentally wrong with these companies'
algorithms.

News organizations, in general, have been skeptical of social networks.
Journalists and specialists alike argue that social media's algorithms
(specially recommender algorithms) are tuned to peddle conspiracy theories,
extremist views, and false information. This would be the source cause for a
plethora of what they consider contemporary evils: religious extremism,
anti-democratic leaders, widespread depression among teenagers, anti-science
movements, etc.

This narrative, of course, has been questioned for a variety of reasons. Some
say that it is self serving: traditional news organizations are being displaced
by social media and it would be convenient for them to mine the public's trust
in them. Others claim that these recommender algorithms are not to blame for
political polarization and that social networks even have a tendency to favor
more left-wing viewpoints.

The debate around the role of recommender systems in social media radicalization
is still, unfortunately, too recent and based in anecdotes. Since its impacts
are all but universal, more quality research is vital to inform both the public
and opinion makers about if and how much recommendation algorithms influence
social media users.

This dissertation aims to further such research. The rest of Chapter 1 is
dedicated to core concepts covered in the rest of the work, ending in subsection
1.4, which tackles the main hypothesis of this dissertation. Chapter 2 contains
the literature review, Chapter 3 explains the experiments already conducted and
their results, and Chapter 4 is about next steps.

\section{Social Networks}
\label{sec:social_networks}

Social networking services, also referred to as social networks and social
media, are notoriously difficult to define. Some definitions might be too narrow
(excluding instant messaging services), while some might be too broad (including
technologies such as telephone networks). Most definitions include some common
features:

\begin{itemize}
  \item Internet-based
  \item Focus on user-generated content
  \item Users have profiles
  \item Users can connect
\end{itemize}

While social-networking-like applications already existed in Usenet, Geocities,
launched in 1994, is usually regarded as the first major social network.
Friendster and Myspace followed in 2003, with Orkut and Facebook slightly
lagging behind in 2004. Each hit their peak at different moments and different
countries, but Facebook overtook all of them in 2009 when it became the most
popular social networking service in the world, still maintaining the title over
11 years latter at the moment of writing.

Even though all aforementioned social networks are multimedia, that is, users
can post text, photos and videos, some of the most popular services focus on a
specific type of media. For instance, YouTube (2009) centers around videos,
WhatsApp (2009) and WeChat (2011) were originally designed for text-based
communication, and Instagram's (2010) main focus is photos.

Some social media services, very much in agreement with McLuhan's teachings,
have what could be considered a ``style''. Instagram's content, for example,
tends toward more personal (i.e. egoic) photos and videos. As of November 28th,
2020, six of the top 20 most-liked posts on Instagram are from american
socialite Kylie Jenner, consisting of four photos of her daughter and two of her
ex-boyfriend. Even though there are many different niches inside Instagram,
personal posts seam to have an edge over other kinds of content.

Twitter, unlike most other social networks, allows for asymmetrical connections,
meaning users can follow profiles without being followed back. This enables the
emergence of Twitter communities (e.g. Fintwit, Black Twitter) that can be
largely self referential and/or organized around certain subjects. Facebook
users, on the other hand, can belong to groups, user-moderated profiles that
might revolve around any particular topics of interest; there are groups that
organize pet owners and groups that organize neonazis.

Parallel to all other features and idiosyncrasies, there lay the recommendation
algorithms. While a few social networking services (e.g. WhatsApp) do not
recommend any content or profiles to the user, most do and, according to recent
studies, these recommendations have become the main drivers of interactions.

\section{Recommender Systems}
\label{sec:recommender_systems}

Recommender systems (sometimes called recommendation systems or recomender
algorithms) first appeared in 1992 under the name ``collaborative filtering'',
even though that term nowadays refers to a subclass of recommender systems. The
aim of such an algorithm is providing users with personalized product or service
recommendations, an essential task when considering the ever increasing number
of possible videos to watch, music to listen, products to buy.

The input of a recommender system is usually information about the preferences
(ratings, likes/dislikes, watch time, etc.) of consumers for a set of items.
Preference information can be gathered from explicit behaviors (e.g. rating a
product in a scale ranging from 0 to 5 stars) or from implicit behaviors (e.g.
how much time the user lingers on a product's page). These data can be combined
with information about the user (age, political leaning, etc.) in order to
create the best possible representation of the user's preferences.

The output of these systems can come in the form of a prediction or a list of
recommended items. In the first case, the goal of the algorithm is approximating
the rating a user would attribute to a yet unrated item, while the second type
of output involves gathering the items that most likely would interest the user.
Simple recommender systems that suggest items similar to the one being queried
do not necessarily involve rating predictions, but it is common to have the list
of rcommended items based on the ratings the algorithms estimated the user would
give to those items.

Most recommender systems follow into one of four categories according to the
filtering algorithm they use, that it, the strategy for generating predictions
or selecting the top-N items: content-based filtering, demographic filtering,
collaborative filtering, and hybrid filtering.

Content-based filtering leverages characteristics of the content in order to
generate the recommendations. One such algorithm might use the genres of watched
movies in order to recommend new ones, while another might analyse the sound
signature of a song to recommend similar ones, but, either way, all
content-based systems establish a similarity between items as a basis for
recommendations. Analogously, demographic filtering uses demographic data to
establish a similarity between users and recommend items positively rated by
similar people.

Collaborative filtering algorithms also recommend items that similar users
liked, but, in this case, the similarity between users is based on past ratings
and not demographic information. Hybrid filtering usually mix collaborative
methods with either content-based or demographic filtering.

As with other knowledge-based systems, recommendation algorithms have quickly
incorporated neural networks and other machine learning techniques over the past
few years. Even though the implementation of YouTube's recommendation algorithm
is a trade secret, it is known to gather enormous amounts of data about the
user's interaction with the website and to require Google's own TPUs in order to
be trained. It also involves two distinct steps: candidate generation (when the
billions of videos available on the platform are quickly narrowed down to a few
hundreds that might be relevant) and ranking (when the algorithm actually
attempts to predict the score a user would implicitly give to the candidate
videos).

Another relevant aspect of recommender systems that is well-exemplified by
YouTube is the use of balancing factors such as novelty, dispersity, and
stability. In the case of Google's video giant, there is a baked-in bias for
recency, strongly favoring newer videos in detriment of older content.

\section{Radicalization}
\label{sec:radicalization}

Opinion polarization is far from a recent phenomenon, and social media is only
the most recent communication medium where it can be detected and studied. An
important question is whether it facilitates or attenuates polarization:
anecdotal evidence might suggest that social network structures incentivize
users to gather into antagonistic communities, but this could be a result of
people simply being more likely to express their preferences online, not of some
intrinsic property of social media.

One possible byproduct of polarization is radicalization. Despite not being
entirely different phenomena, these concepts deserve distinct levels of
attention. While polarization can be considered a natural part of democratic
discourse, radicalization only happens when certain conditions are met. UNESCO
defines radicalization as:

\begin{itemize}
  \item The individual person's search for fundamental meaning, origin and
        return to a root ideology;
  \item The individual as part of a group's adoption of a violent form of
        expansion of root ideologies and related oppositionist objectives;
  \item The polarization of the social space and the collective construction of
        a threatened ideal 'us' against 'them,' where the others are dehumanized
        by a process of scapegoating.
\end{itemize}

The third point is of special importance to the distinction between polarization
and radicalization. The first might be a simple consequence of democratic
disagreements between opposing parties, but the latter involves a dehumanization
of the opposition, which can lead to extremism: radicalism so intense that the
only effective strategy is physically exterminating the opposition.

Understanding how polarization might lead to radicalization (and, ultimately, to
extremism) is, therefore, of paramount significance to cultivate healthy
democracies, specially in the digital age. Since most social networks, as of
this writing, are still poorly moderated, they allow users to be exposed to a
plethora of viewpoints, from benign to insidious, possibly configuring a
``pipeline of radicalization'' through which regular users end up radicalized by
coming into contact with extreme content.

Of course this argument is still very much open for debate. Researchers have
found evidences both for and against the pipeline hypothesis and even proposed
other means though which social media might help radicalize users (e.g. the supply
and demand hypothesis). Despite all disagreements, one common point addressed by
most research is the role of recommendation algorithms in serving users with
radicalizing content.

Proponents of the pipeline hypothesis, for instance, argue that recommendation
systems, aiming to maximize content consumption, suggest items that reinforce
preconceived notions of the user and that play on fear and paranoia. This second
point is of note: content that appears urgent and leaves the user fearful (for
their live, their community, or their identity) is more engaging and, therefore,
more susceptible to being considered as relevant by the algorithm.

Even if the pipeline hypothesis is correct, specifics of how much algorithms are
to blame for radicalization are still unknown and hard to pin down. Most
research about the subject focuses on specific platforms (like Twitter and
YouTube) and have severe limitations with regards to how much data those
companies make available, not to mention the constant changes made to the
algorithms over the years that might alter their radicalization properties.
Definitive evidence for one theory or another must, therefore, apply to
recommender systems in general and be predictive of how they work both in
controlled and real life scenarios.

\section{Hypothesis}
\label{sec:hypothesis}

As explained in the previous sections, social networks' recommendation
algorithms might play a significant role in radicalizing users. This could, at
least in part, explain the recent surge in popularity that far-right ideologies
have enjoyed over the last few years. If true, this is an existential threat to
modern democracies that should be addressed as soon as possible.

This dissertation aims to explore the radicalization pipeline hypothesis and,
more specifically, understand the mechanisms through which recommender systems
can end up suggesting extreme content to regular users. The research developed
here revolves around the dynamical properties of recommender systems (i.e. the
sequence of items suggested to an arbitrary user over time) and how they might
lead to ``fixed points'' in an algorithm's phase space.

In short, the main goal is to test the pipeline hypothesis in a setting where
recommendation algorithms are modeled as dynamical systems. This will allow for
a better understanding of how these systems behave in the wild, possibly taking
the user in a radicalizing ``trip'' through the space of all possible items.
