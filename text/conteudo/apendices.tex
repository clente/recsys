%!TeX root=../tese.tex
%("dica" para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101/183146

% Os apêndices podem ser inseridos diretamente aqui ou "puxados" de outros
% arquivos.
% Em alguns (raros) casos, pode ser interessante usar \include ao
% invés de \input: https://tex.stackexchange.com/a/32058/183146
%\input{conteudo/apendice-pseudocodigo}

\chapter{Movie Lens Model}
\label{apx:model}

Below is the full code for the Movie Lens Model described in
Chapter~\ref{cap:dynamic}. The rest of the code necessary for this work is available online at
\href{https://github.com/clente/recsys/tree/main/code}{https://github.com/clente/recsys/tree/main/code}.

\begin{verbatim}
from google.colab import drive
drive.mount('/content/drive')

file_ratings = "drive/MyDrive/ratings3.csv"
dir_model = "drive/MyDrive/model3"

import os
import pprint
import tempfile

from typing import Dict, Text

import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_recommenders as tfrs

ratings = tf.data.experimental.make_csv_dataset(
    file_ratings, batch_size=1000,
    column_defaults=[tf.string,tf.string,tf.int32,tf.string]).unbatch()

ratings = ratings.map(lambda x: {
  "movie_title": x["movie_title"],
  "user_id": x["user_id"],
  "user_rating": x["user_rating"]
})

tf.random.set_seed(42)
shuffled = ratings.shuffle(1_000_000, seed=42, reshuffle_each_iteration=False)

train = shuffled.take(800_000)
test = shuffled.skip(800_000).take(200_000)

unique_movie_titles = np.load(
  "drive/MyDrive/unique_movie_titles_1m.npy",
  allow_pickle=True
)
unique_user_ids = np.load(
  "drive/MyDrive/unique_user_ids_1m.npy",
  allow_pickle=True
)

class RankingModel(tf.keras.Model):

  def __init__(self):
    super().__init__()
    embedding_dimension = 32

    self.user_embeddings = tf.keras.Sequential([
      tf.keras.layers.StringLookup(
        vocabulary=unique_user_ids, mask_token=None),
      tf.keras.layers.Embedding(
        len(unique_user_ids) + 1,
        embedding_dimension
      )
    ])

    self.movie_embeddings = tf.keras.Sequential([
      tf.keras.layers.StringLookup(
        vocabulary=unique_movie_titles, mask_token=None),
      tf.keras.layers.Embedding(
        len(unique_movie_titles) + 1,
        embedding_dimension
      )
    ])

    self.ratings = tf.keras.Sequential([
      tf.keras.layers.Dense(256, activation="relu"),
      tf.keras.layers.Dense(64, activation="relu"),
      tf.keras.layers.Dense(1)
  ])

  def call(self, inputs):

    user_id, movie_title = inputs

    user_embedding = self.user_embeddings(user_id)
    movie_embedding = self.movie_embeddings(movie_title)

    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))

RankingModel()((["42"], ["One Flew Over the Cuckoo's Nest (1975)"]))

task = tfrs.tasks.Ranking(
  loss = tf.keras.losses.MeanSquaredError(),
  metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

class MovielensModel(tfrs.models.Model):

  def __init__(self):
    super().__init__()
    self.ranking_model: tf.keras.Model = RankingModel()
    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(
      loss = tf.keras.losses.MeanSquaredError(),
      metrics=[tf.keras.metrics.RootMeanSquaredError()]
    )

  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:
    return self.ranking_model(
        (features["user_id"], features["movie_title"]))

  def compute_loss(self, features: Dict[Text,tf.Tensor], training=False) -> tf.Tensor:
    labels = features.pop("user_rating")

    rating_predictions = self(features)

    return self.task(labels=labels, predictions=rating_predictions)

model = MovielensModel()
model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))

cached_train = train.shuffle(1_000_000).batch(8192).cache()
cached_test = test.batch(4096).cache()

model.fit(cached_train, epochs=3)

model.evaluate(cached_test, return_dict=True)

test_ratings = {}
test_movie_titles = ["M*A*S*H (1970)", "Dances with Wolves (1990)", "Speed (1994)"]
for movie_title in test_movie_titles:
  test_ratings[movie_title] = model({
      "user_id": np.array(["42"]),
      "movie_title": np.array([movie_title])
  })

print("Ratings:")
for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):
  print(f"{title}: {score}")

tf.saved_model.save(model, dir_model)

loaded = tf.saved_model.load(dir_model)

loaded({"user_id": np.array(["42"]), "movie_title": ["Speed (1994)"]}).numpy()
\end{verbatim}

\chapter{Movie Popularity}
\label{apx:pop}

Below is the full table with the most recommended movies by each generation of
the model described in Chapter~\ref{cap:dynamic}.

\begin{longtable}{ |r|l|r| }
  \hline

  \multicolumn{3}{ |c| }{Original data} \\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline
  ID & Title & Popularity\\
  \hline
  2762 & Sixth Sense, The (1999) & 256\\
  \hline
  2987 & Who Framed Roger Rabbit? (1988) & 244\\
  \hline
  3793 & X-Men (2000) & 210\\
  \hline
  3578 & Gladiator (2000) & 208\\
  \hline
  2396 & Shakespeare in Love (1998) & 202\\
  \hline
  2858 & American Beauty (1999) & 198\\
  \hline
  3176 & Talented Mr. Ripley, The (1999) & 197\\
  \hline
  608 & Fargo (1996) & 175\\
  \hline
  1580 & Men in Black (1997) & 174\\
  \hline
  2628 & Star Wars: Episode I - The Phantom Menace (1999) & 165\\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline

  \multicolumn{3}{ |c| }{Generation 1} \\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline
  ID & Title & Popularity\\
  \hline
  50 & Usual Suspects, The (1995) & 715\\
  \hline
  318 & Shawshank Redemption, The (1994) & 705\\
  \hline
  858 & Godfather, The (1972) & 669\\
  \hline
  745 & Close Shave, A (1995) & 664\\
  \hline
  527 & Schindler's List (1993) & 663\\
  \hline
  2019 & Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954) & 652\\
  \hline
  904 & Rear Window (1954) & 644\\
  \hline
  1148 & Wrong Trousers, The (1993) & 629\\
  \hline
  922 & Sunset Blvd. (a.k.a. Sunset Boulevard) (1950) & 601\\
  \hline
  1198 & Raiders of the Lost Ark (1981) & 520\\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline

  \multicolumn{3}{ |c| }{Generation 2} \\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline
  ID & Title & Popularity\\
  \hline
  318 & Shawshank Redemption, The (1994) & 1296\\
  \hline
  50 & Usual Suspects, The (1995) & 1292\\
  \hline
  2019 & Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954) & 1276\\
  \hline
  858 & Godfather, The (1972) & 1261\\
  \hline
  745 & Close Shave, A (1995) & 1252\\
  \hline
  904 & Rear Window (1954) & 1252\\
  \hline
  1148 & Wrong Trousers, The (1993) & 1217\\
  \hline
  922 & Sunset Blvd. (a.k.a. Sunset Boulevard) (1950) & 1191\\
  \hline
  260 & Star Wars: Episode IV - A New Hope (1977) & 772\\
  \hline
  527 & Schindler's List (1993) & 657\\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline

  \multicolumn{3}{ |c| }{Generation 3} \\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline
  ID & Title & Popularity\\
  \hline
  318 & Shawshank Redemption, The (1994) & 1908\\
  \hline
  50 & Usual Suspects, The (1995) & 1898\\
  \hline
  2019 & Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954) & 1881\\
  \hline
  858 & Godfather, The (1972) & 1861\\
  \hline
  745 & Close Shave, A (1995) & 1810\\
  \hline
  1148 & Wrong Trousers, The (1993) & 1808\\
  \hline
  922 & Sunset Blvd. (a.k.a. Sunset Boulevard) (1950) & 1786\\
  \hline
  527 & Schindler's List (1993) & 1256\\
  \hline
  904 & Rear Window (1954) & 1243\\
  \hline
  1212 & Third Man, The (1949) & 1172\\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline

  \multicolumn{3}{ |c| }{Generation 4} \\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
  \hline
  ID & Title & Popularity\\
  \hline
  2019 & Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954) & 2496\\
  \hline
  318 & Shawshank Redemption, The (1994) & 2468\\
  \hline
  745 & Close Shave, A (1995) & 2436\\
  \hline
  1148 & Wrong Trousers, The (1993) & 2432\\
  \hline
  858 & Godfather, The (1972) & 2422\\
  \hline
  922 & Sunset Blvd. (a.k.a. Sunset Boulevard) (1950) & 2385\\
  \hline
  50 & Usual Suspects, The (1995) & 1888\\
  \hline
  527 & Schindler's List (1993) & 1822\\
  \hline
  904 & Rear Window (1954) & 1814\\
  \hline
  1198 & Raiders of the Lost Ark (1981) & 1718\\
  \hline
  \multicolumn{3}{c}{} \\ [-0.9ex]
\end{longtable}
